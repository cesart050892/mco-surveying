{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fac8ac6-951c-4edd-b42a-66848bc0646a",
   "metadata": {},
   "source": [
    "### Explicación de Métodos Matriciales en el Ajuste por Mínimos Cuadrados\n",
    "\n",
    "En la imagen proporcionada, se explica cómo se puede formular un problema de ajuste por mínimos cuadrados usando matrices, lo cual es especialmente útil para sistemas con múltiples observaciones y parámetros.\n",
    "\n",
    "#### **1. Representación Matricial del Problema**\n",
    "\n",
    "El problema de ajuste por mínimos cuadrados se puede representar en forma matricial como:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}[m,n] \\mathbf{X}[n,1] = \\mathbf{L}[m,1] + \\mathbf{V}[m,1]\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- **$\\mathbf{A}$** es la matriz de los coeficientes de las incógnitas, de tamaño $m \\times n$.\n",
    "- **$\\mathbf{X}$** es el vector de incógnitas (parámetros) que queremos estimar, de tamaño $n \\times 1$.\n",
    "- **$\\mathbf{L}$** es el vector de observaciones, de tamaño $m \\times 1$.\n",
    "- **$\\mathbf{V}$** es el vector de residuos o errores, de tamaño $m \\times 1$.\n",
    "\n",
    "La ecuación matricial expresa que las observaciones $\\mathbf{L}$ son una combinación lineal de las incógnitas $\\mathbf{X}$ más los errores $\\mathbf{V}$.\n",
    "\n",
    "#### **2. Ecuaciones Normales**\n",
    "\n",
    "Para resolver el problema y encontrar el vector $\\mathbf{X}$ que minimiza la suma de los cuadrados de los residuos, se utilizan las ecuaciones normales, que se obtienen al multiplicar ambos lados de la ecuación original por la transpuesta de la matriz $\\mathbf{A}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{A} \\mathbf{X} = \\mathbf{A}^T \\mathbf{L}\n",
    "$$\n",
    "\n",
    "Estas ecuaciones normales son un sistema de ecuaciones lineales que se puede resolver para obtener el vector de incógnitas $\\mathbf{X}$.\n",
    "\n",
    "#### **3. Solución del Sistema**\n",
    "\n",
    "La solución para $\\mathbf{X}$ se obtiene al multiplicar ambos lados de la ecuación por la inversa de $\\mathbf{A}^T \\mathbf{A}$:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = (\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{L}\n",
    "$$\n",
    "\n",
    "Esta ecuación da la solución de mínimos cuadrados para las incógnitas $\\mathbf{X}$, lo que representa los valores más probables de las incógnitas dadas las observaciones.\n",
    "\n",
    "#### **4. Observaciones Ponderadas**\n",
    "\n",
    "En caso de que las observaciones tengan pesos diferentes (no igualmente ponderadas), se introduce una matriz de pesos **$\\mathbf{W}$**, que es una matriz diagonal donde cada elemento $w_i$ representa el peso de la $i$-ésima observación:\n",
    "\n",
    "$$\n",
    "\\mathbf{W} = \\begin{pmatrix}\n",
    "w_1 & 0 & \\cdots & 0 \\\\\n",
    "0 & w_2 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\cdots & w_m\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "En este caso, la ecuación normal ajustada para observaciones ponderadas se convierte en:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = (\\mathbf{A}^T \\mathbf{W} \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{W} \\mathbf{L}\n",
    "$$\n",
    "\n",
    "Esta fórmula generaliza la solución del ajuste por mínimos cuadrados, tomando en cuenta que diferentes observaciones pueden tener diferentes niveles de confianza (pesos).\n",
    "\n",
    "### **Resumen**\n",
    "\n",
    "Este método matricial proporciona una forma sistemática y eficiente de resolver problemas de ajuste por mínimos cuadrados, especialmente en situaciones con muchas observaciones y parámetros. Al usar matrices y vectores, se facilita la manipulación algebraica y la resolución computacional del problema, lo que es crucial para aplicaciones prácticas en topografía, geodesia, y otras disciplinas que requieren alta precisión en las mediciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3757421-e38a-4c17-9acc-a35b9c12a711",
   "metadata": {},
   "source": [
    "### Desarrollo del Ejemplo 3 Usando Métodos Matriciales con Explicación Detallada\n",
    "\n",
    "#### **1. Contexto del Problema**\n",
    "\n",
    "Queremos ajustar las mediciones de las distancias entre los puntos A, B, y C para minimizar los errores de medición, utilizando un enfoque matricial. Las ecuaciones que tenemos son:\n",
    "\n",
    "- $x + y = 393.65$ pies (distancia total entre A y C)\n",
    "- $x = 190.40$ pies (distancia entre A y B)\n",
    "- $y = 203.16$ pies (distancia entre B y C)\n",
    "\n",
    "Dado que estas ecuaciones representan relaciones entre las mediciones y las distancias, podemos organizar el problema en forma matricial para aplicar el método de mínimos cuadrados.\n",
    "\n",
    "#### **2. Construcción de la Matriz $ \\mathbf{A} $**\n",
    "\n",
    "La matriz $ \\mathbf{A} $ se construye a partir de las ecuaciones de observación. Cada fila de la matriz representa una ecuación, y cada columna representa un coeficiente que multiplica una incógnita (en este caso, $ x $ o $ y $).\n",
    "\n",
    "Veamos cómo se derivan las filas de la matriz $ \\mathbf{A} $:\n",
    "\n",
    "1. **Primera ecuación**: $ x + y = 393.65 $\n",
    "   - Coeficiente de $ x $: 1\n",
    "   - Coeficiente de $ y $: 1\n",
    "   - Esto da la primera fila de la matriz $ \\mathbf{A} $ como $ [1 \\ 1] $.\n",
    "\n",
    "2. **Segunda ecuación**: $ x = 190.40 $\n",
    "   - Coeficiente de $ x $: 1\n",
    "   - Coeficiente de $ y $: 0 (ya que $ y $ no aparece en esta ecuación)\n",
    "   - Esto da la segunda fila de la matriz $ \\mathbf{A} $ como $ [1 \\ 0] $.\n",
    "\n",
    "3. **Tercera ecuación**: $ y = 203.16 $\n",
    "   - Coeficiente de $ x $: 0 (ya que $ x $ no aparece en esta ecuación)\n",
    "   - Coeficiente de $ y $: 1\n",
    "   - Esto da la tercera fila de la matriz $ \\mathbf{A} $ como $ [0 \\ 1] $.\n",
    "\n",
    "Así, la matriz $ \\mathbf{A} $ queda construida como:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "#### **3. Sistema de Ecuaciones para Construir $ \\mathbf{A} $**\n",
    "\n",
    "El sistema de ecuaciones a partir del cual se construye $ \\mathbf{A} $ es:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "1x + 1y = 393.65 \\quad \\text{(Primera fila de $ \\mathbf{A} $)} \\\\\n",
    "1x + 0y = 190.40 \\quad \\text{(Segunda fila de $ \\mathbf{A} $)} \\\\\n",
    "0x + 1y = 203.16 \\quad \\text{(Tercera fila de $ \\mathbf{A} $)}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Aquí:\n",
    "- Cada fila del sistema de ecuaciones se convierte en una fila de la matriz $ \\mathbf{A} $.\n",
    "- Las incógnitas $ x $ y $ y $ corresponden a las columnas de la matriz $ \\mathbf{A} $.\n",
    "\n",
    "#### **4. Expresión Matricial del Problema**\n",
    "\n",
    "Con la matriz $ \\mathbf{A} $ construida, podemos ahora expresar el problema de forma matricial como:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{X} = \\mathbf{L} + \\mathbf{V}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $ \\mathbf{A} $ es la matriz de coeficientes de tamaño $ 3 \\times 2 $.\n",
    "- $ \\mathbf{X} = \\begin{bmatrix} x \\\\ y \\end{bmatrix} $ es el vector de incógnitas.\n",
    "- $ \\mathbf{L} = \\begin{bmatrix} 393.65 \\\\ 190.40 \\\\ 203.16 \\end{bmatrix} $ es el vector de observaciones.\n",
    "- $ \\mathbf{V} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{bmatrix} $ es el vector de residuos.\n",
    "\n",
    "#### **5. Resolución del Sistema**\n",
    "\n",
    "Para resolver el sistema de ecuaciones usando mínimos cuadrados, primero calculamos las ecuaciones normales:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{A} \\mathbf{X} = \\mathbf{A}^T \\mathbf{L}\n",
    "$$\n",
    "\n",
    "Luego, resolvemos para $ \\mathbf{X} $ (los valores ajustados de $ x $ y $ y $):\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = (\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{L}\n",
    "$$\n",
    "\n",
    "Al calcular:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{A} = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}, \\quad \\mathbf{A}^T \\mathbf{L} = \\begin{bmatrix} 584.05 \\\\ 393.56 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Finalmente, encontramos los valores ajustados de $ x $ y $ y $:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\begin{bmatrix} 190.43 \\\\ 203.19 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Este enfoque sistemático utilizando matrices no solo facilita la resolución de problemas de ajuste por mínimos cuadrados con múltiples observaciones, sino que también proporciona una base sólida para la implementación computacional de estos métodos. Con la matriz $ \\mathbf{A} $ adecuadamente construida, podemos resolver eficientemente sistemas más grandes y complejos, minimizando los errores de medición y ajustando las observaciones de manera óptima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0686d8ff-9093-4c57-adcf-df9062a68dd1",
   "metadata": {},
   "source": [
    "### Ajuste por Mínimos Cuadrados Ponderado\n",
    "\n",
    "Para ajustar las distancias $ x $ y $ y $ utilizando un enfoque ponderado, vamos a aplicar una desviación estándar a cada una de las mediciones, y usaremos la matriz de pesos $ \\mathbf{W} $ en el cálculo.\n",
    "\n",
    "#### **1. Determinación de la Matriz de Pesos $ \\mathbf{W} $**\n",
    "\n",
    "Dado que la desviación estándar de las mediciones es $ \\sigma = 0.11811 $ pies, podemos calcular los pesos correspondientes:\n",
    "\n",
    "$$\n",
    "w_i = \\frac{1}{\\sigma^2} = \\frac{1}{(0.11811)^2} \\approx 71.696\n",
    "$$\n",
    "\n",
    "Entonces, la matriz de pesos $ \\mathbf{W} $ es una matriz diagonal en la que cada elemento diagonal es igual a $ w_i $:\n",
    "\n",
    "$$\n",
    "\\mathbf{W} = \\begin{pmatrix}\n",
    "71.696 & 0 & 0 \\\\\n",
    "0 & 71.696 & 0 \\\\\n",
    "0 & 0 & 71.696\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### **2. Aplicación del Método de Mínimos Cuadrados Ponderado**\n",
    "\n",
    "El ajuste por mínimos cuadrados ponderado se realiza utilizando la siguiente ecuación:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = (\\mathbf{A}^T \\mathbf{W} \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{W} \\mathbf{L}\n",
    "$$\n",
    "\n",
    "#### **3. Cálculo de las Matrices Involucradas**\n",
    "\n",
    "Primero, calculamos $ \\mathbf{A}^T \\mathbf{W} \\mathbf{A} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{A} = \\begin{pmatrix}\n",
    "1 & 1 & 0 \\\\\n",
    "1 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "71.696 & 0 & 0 \\\\\n",
    "0 & 71.696 & 0 \\\\\n",
    "0 & 0 & 71.696\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Calculando esto paso a paso:\n",
    "\n",
    "1. Multiplicamos $ \\mathbf{W} $ por $ \\mathbf{A} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{W} \\mathbf{A} = \\begin{pmatrix}\n",
    "71.696 & 71.696 \\\\\n",
    "71.696 & 0 \\\\\n",
    "0 & 71.696\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. Ahora multiplicamos $ \\mathbf{A}^T $ por $ \\mathbf{W} \\mathbf{A} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{A} = \\begin{pmatrix}\n",
    "143.392 & 71.696 \\\\\n",
    "71.696 & 143.392\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Luego, calculamos $ \\mathbf{A}^T \\mathbf{W} \\mathbf{L} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{L} = \\begin{pmatrix}\n",
    "1 & 1 & 0 \\\\\n",
    "1 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "71.696 & 0 & 0 \\\\\n",
    "0 & 71.696 & 0 \\\\\n",
    "0 & 0 & 71.696\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "393.65 \\\\\n",
    "190.40 \\\\\n",
    "203.16\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Calculando esto:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{L} = \\begin{pmatrix}\n",
    "584.05 \\times 71.696 \\\\\n",
    "393.56 \\times 71.696\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "41902.81 \\\\\n",
    "28223.91\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### **4. Solución para $ \\mathbf{X} $**\n",
    "\n",
    "Finalmente, calculamos la inversa de $ \\mathbf{A}^T \\mathbf{W} \\mathbf{A} $ y multiplicamos para obtener $ \\mathbf{X} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = (\\mathbf{A}^T \\mathbf{W} \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{W} \\mathbf{L}\n",
    "$$\n",
    "\n",
    "Primero, calculamos la inversa:\n",
    "\n",
    "$$\n",
    "(\\mathbf{A}^T \\mathbf{W} \\mathbf{A})^{-1} = \\frac{1}{(143.392 \\times 143.392) - (71.696 \\times 71.696)} \\begin{pmatrix}\n",
    "143.392 & -71.696 \\\\\n",
    "-71.696 & 143.392\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "La determinante de la matriz es:\n",
    "\n",
    "$$\n",
    "\\text{Determinante} = (143.392 \\times 143.392) - (71.696 \\times 71.696) = 14339.2\n",
    "$$\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$$\n",
    "(\\mathbf{A}^T \\mathbf{W} \\mathbf{A})^{-1} = \\frac{1}{14339.2} \\begin{pmatrix}\n",
    "143.392 & -71.696 \\\\\n",
    "-71.696 & 143.392\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Finalmente, calculamos $ \\mathbf{X} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\frac{1}{14339.2} \\begin{pmatrix}\n",
    "143.392 & -71.696 \\\\\n",
    "-71.696 & 143.392\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "41902.81 \\\\\n",
    "28223.91\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "190.43 \\\\\n",
    "203.19\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Con el ajuste ponderado, obtenemos que los valores ajustados de $ x $ y $ y $ son prácticamente los mismos que en el ajuste sin ponderar, dado que la desviación estándar y los pesos son uniformes para todas las mediciones. Sin embargo, el uso de la matriz de pesos es crucial en situaciones donde las observaciones tienen diferentes precisiones, permitiendo que las observaciones más precisas tengan un mayor impacto en el ajuste final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4163c6a3-487c-4417-9cb4-5770d43f358c",
   "metadata": {},
   "source": [
    "Vamos a corregir el ajuste ponderado considerando que la primera observación tiene una desviación estándar diferente. Específicamente, la primera observación tiene una desviación estándar de $0.196850$ pies, mientras que las otras dos mantienen una desviación estándar de $0.11811$ pies.\n",
    "\n",
    "### 1. Determinación de la Matriz de Pesos $ \\mathbf{W} $\n",
    "\n",
    "Dado que la desviación estándar de las observaciones es diferente para la primera medición, calculamos los pesos correspondientes para cada observación:\n",
    "\n",
    "1. **Primer peso**:\n",
    "   $$\n",
    "   w_1 = \\frac{1}{\\sigma_1^2} = \\frac{1}{(0.196850)^2} \\approx 25.826\n",
    "   $$\n",
    "\n",
    "2. **Segundo y tercer peso**:\n",
    "   $$\n",
    "   w_2 = w_3 = \\frac{1}{\\sigma_2^2} = \\frac{1}{(0.11811)^2} \\approx 71.696\n",
    "   $$\n",
    "\n",
    "La matriz de pesos $ \\mathbf{W} $ se representa entonces como:\n",
    "\n",
    "$$\n",
    "\\mathbf{W} = \\begin{pmatrix}\n",
    "25.826 & 0 & 0 \\\\\n",
    "0 & 71.696 & 0 \\\\\n",
    "0 & 0 & 71.696\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### 2. Aplicación del Método de Mínimos Cuadrados Ponderado\n",
    "\n",
    "La ecuación para el ajuste por mínimos cuadrados ponderado es:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = (\\mathbf{A}^T \\mathbf{W} \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{W} \\mathbf{L}\n",
    "$$\n",
    "\n",
    "### 3. Cálculo de las Matrices Involucradas\n",
    "\n",
    "Primero, calculamos $ \\mathbf{A}^T \\mathbf{W} \\mathbf{A} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{A} = \\begin{pmatrix}\n",
    "1 & 1 & 0 \\\\\n",
    "1 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "25.826 & 0 & 0 \\\\\n",
    "0 & 71.696 & 0 \\\\\n",
    "0 & 0 & 71.696\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1 & 1 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Realizando las multiplicaciones:\n",
    "\n",
    "1. Multiplicamos $ \\mathbf{W} $ por $ \\mathbf{A} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{W} \\mathbf{A} = \\begin{pmatrix}\n",
    "25.826 & 25.826 \\\\\n",
    "71.696 & 0 \\\\\n",
    "0 & 71.696\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "2. Ahora, multiplicamos $ \\mathbf{A}^T $ por $ \\mathbf{W} \\mathbf{A} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{A} = \\begin{pmatrix}\n",
    "97.522 & 25.826 \\\\\n",
    "25.826 & 143.392\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Luego, calculamos $ \\mathbf{A}^T \\mathbf{W} \\mathbf{L} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{L} = \\begin{pmatrix}\n",
    "1 & 1 & 0 \\\\\n",
    "1 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "25.826 & 0 & 0 \\\\\n",
    "0 & 71.696 & 0 \\\\\n",
    "0 & 0 & 71.696\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "393.65 \\\\\n",
    "190.40 \\\\\n",
    "203.16\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Realizando esta operación:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{L} = \\begin{pmatrix}\n",
    "393.65 \\times 25.826 + 190.40 \\times 71.696 \\\\\n",
    "393.65 \\times 25.826 + 203.16 \\times 71.696\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "23004.87 \\\\\n",
    "28655.94\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### 4. Solución para $ \\mathbf{X} $\n",
    "\n",
    "Finalmente, calculamos la inversa de $ \\mathbf{A}^T \\mathbf{W} \\mathbf{A} $ y multiplicamos para obtener $ \\mathbf{X} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = (\\mathbf{A}^T \\mathbf{W} \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{W} \\mathbf{L}\n",
    "$$\n",
    "\n",
    "Primero, calculamos la inversa de $ \\mathbf{A}^T \\mathbf{W} \\mathbf{A} $:\n",
    "\n",
    "$$\n",
    "(\\mathbf{A}^T \\mathbf{W} \\mathbf{A})^{-1} = \\frac{1}{97.522 \\times 143.392 - 25.826 \\times 25.826} \\begin{pmatrix}\n",
    "143.392 & -25.826 \\\\\n",
    "-25.826 & 97.522\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "La determinante de la matriz es:\n",
    "\n",
    "$$\n",
    "\\text{Determinante} = 14069.63\n",
    "$$\n",
    "\n",
    "Entonces, la inversa es:\n",
    "\n",
    "$$\n",
    "(\\mathbf{A}^T \\mathbf{W} \\mathbf{A})^{-1} = \\frac{1}{14069.63} \\begin{pmatrix}\n",
    "143.392 & -25.826 \\\\\n",
    "-25.826 & 97.522\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Finalmente, calculamos $ \\mathbf{X} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\frac{1}{14069.63} \\begin{pmatrix}\n",
    "143.392 & -25.826 \\\\\n",
    "-25.826 & 97.522\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "23004.87 \\\\\n",
    "28655.94\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "190.43 \\\\\n",
    "203.19\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Incluso con la aplicación de pesos ponderados con diferentes desviaciones estándar, los valores ajustados de $ x $ y $ y $ se mantienen prácticamente iguales a los resultados anteriores. Este resultado refleja la influencia relativamente uniforme de las mediciones con las desviaciones estándar especificadas. En un contexto práctico, ajustar utilizando pesos ponderados asegura que las observaciones más precisas (con menor desviación estándar) tengan una mayor influencia en el resultado final, lo que es crucial para obtener una solución más confiable en presencia de mediciones con distintas precisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b600059-ea35-44a6-848e-61604501eb98",
   "metadata": {},
   "source": [
    "La imagen que has compartido muestra la fórmula para calcular la **desviación estándar a posteriori** ($ \\sigma_0 $) en un ajuste por mínimos cuadrados ponderado. Esta desviación estándar proporciona una medida de la calidad del ajuste, considerando tanto los residuos como los pesos asignados a las observaciones.\n",
    "\n",
    "### Fórmula para $ \\sigma_0 $\n",
    "\n",
    "La fórmula es:\n",
    "\n",
    "$$\n",
    "\\sigma_0 = \\sqrt{\\frac{\\mathbf{v}^T \\mathbf{W} \\mathbf{v}}{r}}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $ \\mathbf{v} $ es el vector de residuos (o errores).\n",
    "- $ \\mathbf{W} $ es la matriz de pesos (diagonal) aplicada a las observaciones.\n",
    "- $ r = m - n $ es el número de grados de libertad, donde $ m $ es el número de observaciones y $ n $ es el número de incógnitas.\n",
    "\n",
    "### Aplicación al Ejemplo Anterior\n",
    "\n",
    "Para aplicar esta fórmula al ejemplo desarrollado previamente, sigamos los pasos siguientes:\n",
    "\n",
    "#### 1. **Vector de Residuos $ \\mathbf{v} $**\n",
    "\n",
    "Primero, debemos calcular los residuos $ \\mathbf{v} $ utilizando las distancias ajustadas $ x = 190.43 $ pies y $ y = 203.19 $ pies:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "v_1 &= (x + y) - 393.65 = (190.43 + 203.19) - 393.65 = -0.03 \\text{ pies} \\\\\n",
    "v_2 &= x - 190.40 = 190.43 - 190.40 = 0.03 \\text{ pies} \\\\\n",
    "v_3 &= y - 203.16 = 203.19 - 203.16 = 0.03 \\text{ pies}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Entonces, el vector de residuos es:\n",
    "\n",
    "$$\n",
    "\\mathbf{v} = \\begin{pmatrix} -0.03 \\\\ 0.03 \\\\ 0.03 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### 2. **Matriz de Pesos $ \\mathbf{W} $**\n",
    "\n",
    "Ya hemos calculado la matriz de pesos $ \\mathbf{W} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{W} = \\begin{pmatrix}\n",
    "25.826 & 0 & 0 \\\\\n",
    "0 & 71.696 & 0 \\\\\n",
    "0 & 0 & 71.696\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "#### 3. **Cálculo de $ \\mathbf{v}^T \\mathbf{W} \\mathbf{v} $**\n",
    "\n",
    "Multiplicamos el vector de residuos por la matriz de pesos:\n",
    "\n",
    "$$\n",
    "\\mathbf{W} \\mathbf{v} = \\begin{pmatrix}\n",
    "25.826 & 0 & 0 \\\\\n",
    "0 & 71.696 & 0 \\\\\n",
    "0 & 0 & 71.696\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix} -0.03 \\\\ 0.03 \\\\ 0.03 \\end{pmatrix} = \\begin{pmatrix} -0.77478 \\\\ 2.15088 \\\\ 2.15088 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Luego, calculamos $ \\mathbf{v}^T \\mathbf{W} \\mathbf{v} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}^T \\mathbf{W} \\mathbf{v} = \\begin{pmatrix} -0.03 & 0.03 & 0.03 \\end{pmatrix} \\begin{pmatrix} -0.77478 \\\\ 2.15088 \\\\ 2.15088 \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Esto nos da:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}^T \\mathbf{W} \\mathbf{v} = (-0.03)(-0.77478) + (0.03)(2.15088) + (0.03)(2.15088) = 0.02324 + 0.06453 + 0.06453 = 0.1523\n",
    "$$\n",
    "\n",
    "#### 4. **Cálculo del Grado de Libertad $ r $**\n",
    "\n",
    "El grado de libertad $ r $ es:\n",
    "\n",
    "$$\n",
    "r = m - n = 3 - 2 = 1\n",
    "$$\n",
    "\n",
    "#### 5. **Cálculo de $ \\sigma_0 $**\n",
    "\n",
    "Finalmente, calculamos $ \\sigma_0 $:\n",
    "\n",
    "$$\n",
    "\\sigma_0 = \\sqrt{\\frac{0.1523}{1}} = \\sqrt{0.1523} \\approx 0.3902 \\text{ pies}\n",
    "$$\n",
    "\n",
    "### Interpretación\n",
    "\n",
    "La desviación estándar a posteriori ($ \\sigma_0 $) de $ 0.3902 $ pies es una medida de la precisión del ajuste realizado. Esta cifra nos indica cuánto se desvían, en promedio, los valores ajustados respecto a las observaciones originales, considerando los pesos asignados a cada medición.\n",
    "\n",
    "En un contexto práctico, un valor menor de $ \\sigma_0 $ indica un mejor ajuste y mayor precisión en las mediciones, mientras que un valor mayor sugiere un ajuste menos preciso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d980692-c2e7-4789-bf05-9390241e1b02",
   "metadata": {},
   "source": [
    "Vamos a corregir el ejemplo considerando que solo se quieren ajustar las elevaciones de los puntos $A $ y $B $. Esto simplificará el sistema, manteniendo solo las incógnitas $A $ y $B $ en el ajuste por mínimos cuadrados ponderado.\n",
    "\n",
    "### 1. **Ecuaciones de Observación**\n",
    "\n",
    "Dado que estamos interesados únicamente en $A $ y $B $, las ecuaciones se pueden simplificar. Considerando las diferencias de elevación y manteniendo las observaciones relacionadas con $A $ y $B $:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A - \\text{PC1} &= 796.229 + v_1, \\\\\n",
    "A - \\text{PC2} &= 796.241 + v_2, \\\\\n",
    "B - A &= 3.532 + v_3, \\\\\n",
    "B - \\text{PC3} &= 799.739 + v_4, \\\\\n",
    "B - \\text{PC4} &= 799.728 + v_5.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Reemplazamos las ecuaciones donde aparecen $\\text{PC1} $, $\\text{PC2} $, $\\text{PC3} $, y $\\text{PC4} $ con las elevaciones conocidas o las eliminamos si no son necesarias para obtener $A $ y $B $.\n",
    "\n",
    "### 2. **Matrices Asociadas al Problema**\n",
    "\n",
    "Para simplificar las ecuaciones para $A $ y $B $, tenemos:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A &= 796.229 + v_1 + \\text{PC1}, \\\\\n",
    "A &= 796.241 + v_2 + \\text{PC2}, \\\\\n",
    "B - A &= 3.532 + v_3, \\\\\n",
    "B &= 799.739 + v_4 + \\text{PC3}, \\\\\n",
    "B &= 799.728 + v_5 + \\text{PC4}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Ahora, eliminamos las observaciones innecesarias que no afectan directamente el cálculo de $A $ y $B $:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "1A + 0B &= 796.229 + v_1, \\\\\n",
    "1A + 0B &= 796.241 + v_2, \\\\\n",
    "-1A + 1B &= 3.532 + v_3, \\\\\n",
    "0A + 1B &= 799.739 + v_4, \\\\\n",
    "0A + 1B &= 799.728 + v_5.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### 3. **Matrices $\\mathbf{A} $, $\\mathbf{X} $, $\\mathbf{L} $**\n",
    "\n",
    "Las matrices se simplifican para incluir solo las incógnitas $A $ y $B $:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "-1 & 1 \\\\\n",
    "0 & 1 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}, \\quad\n",
    "\\mathbf{X} = \\begin{pmatrix}\n",
    "A \\\\\n",
    "B\n",
    "\\end{pmatrix}, \\quad\n",
    "\\mathbf{L} = \\begin{pmatrix}\n",
    "796.229 \\\\\n",
    "796.241 \\\\\n",
    "3.532 \\\\\n",
    "799.739 \\\\\n",
    "799.728\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### 4. **Matriz de Pesos $\\mathbf{W} $**\n",
    "\n",
    "La matriz de pesos $\\mathbf{W} $ sigue igual, ajustada a las observaciones ponderadas:\n",
    "\n",
    "$$\n",
    "\\mathbf{W} = \\begin{pmatrix}\n",
    "0.5 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0.5 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 2 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### 5. **Cálculo de $\\mathbf{A}^T \\mathbf{W} \\mathbf{A} $ y Solución**\n",
    "\n",
    "Primero, calculamos $\\mathbf{A}^T \\mathbf{W} \\mathbf{A} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{A} = \\begin{pmatrix}\n",
    "1 & 1 & -1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 1 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "0.5 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0.5 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 2 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "-1 & 1 \\\\\n",
    "0 & 1 \\\\\n",
    "0 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{A} = \\begin{pmatrix}\n",
    "0.5 + 0.5 + 2 & -2 \\\\\n",
    "-2 & 2 + 1 + 1\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "3 & -2 \\\\\n",
    "-2 & 4\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Ahora calculamos $\\mathbf{A}^T \\mathbf{W} \\mathbf{L} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{L} = \\begin{pmatrix}\n",
    "1 & 1 & -1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 1 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "0.5 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0.5 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 2 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "796.229 \\\\\n",
    "796.241 \\\\\n",
    "3.532 \\\\\n",
    "799.739 \\\\\n",
    "799.728\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{L} = \\begin{pmatrix}\n",
    "3 & -2 \\\\\n",
    "-2 & 4\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "796.229 + 796.241 - 3.532 \\\\\n",
    "3.532 + 799.739 + 799.728\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "1588.938 \\\\\n",
    "1603.828\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### 6. **Solución para $\\mathbf{X} $ (Elevaciones Ajustadas)**\n",
    "\n",
    "Finalmente, obtenemos las elevaciones ajustadas para $A $ y $B $ resolviendo:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = (\\mathbf{A}^T \\mathbf{W} \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{W} \\mathbf{L}\n",
    "$$\n",
    "\n",
    "Invirtiendo la matriz $\\mathbf{A}^T \\mathbf{W} \\mathbf{A} $ y multiplicando por $\\mathbf{A}^T \\mathbf{W} \\mathbf{L} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\frac{1}{\\text{Determinante}} \\begin{pmatrix}\n",
    "4 & 2 \\\\\n",
    "2 & 3\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "1588.938 \\\\\n",
    "1603.828\n",
    "\\end{pmatrix} = \\text{Elevaciones Ajustadas para } A \\text{ y } B\n",
    "$$\n",
    "\n",
    "### **Conclusión**\n",
    "\n",
    "Este ajuste de mínimos cuadrados ponderado permite obtener las elevaciones ajustadas de los puntos $A $ y $B $ basándose en las observaciones ponderadas. El uso de la matriz de pesos garantiza que las observaciones más precisas tengan mayor influencia en el resultado final, asegurando un ajuste óptimo de la red de nivelación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1684626-857b-42d4-ba41-baed35ad3026",
   "metadata": {},
   "source": [
    "Para devolver la matriz $ \\mathbf{Q}_{xx} $, que es esencial para evaluar las precisiones de las incógnitas ajustadas (en este caso, las elevaciones ajustadas $ A $ y $ B $), primero debemos calcular la inversa de la matriz $ \\mathbf{A}^T \\mathbf{W} \\mathbf{A} $.\n",
    "\n",
    "### Recapitulación de la Matriz $ \\mathbf{A}^T \\mathbf{W} \\mathbf{A} $\n",
    "\n",
    "Ya habíamos calculado $ \\mathbf{A}^T \\mathbf{W} \\mathbf{A} $ como:\n",
    "\n",
    "$$\n",
    "\\mathbf{A}^T \\mathbf{W} \\mathbf{A} = \\begin{pmatrix}\n",
    "3 & -2 \\\\\n",
    "-2 & 4\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### Inversa de $ \\mathbf{A}^T \\mathbf{W} \\mathbf{A} $\n",
    "\n",
    "La matriz $ \\mathbf{Q}_{xx} $ es la inversa de $ \\mathbf{A}^T \\mathbf{W} \\mathbf{A} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{Q}_{xx} = (\\mathbf{A}^T \\mathbf{W} \\mathbf{A})^{-1}\n",
    "$$\n",
    "\n",
    "Para calcular la inversa de una matriz $ 2 \\times 2 $:\n",
    "\n",
    "$$\n",
    "\\mathbf{Q}_{xx} = \\frac{1}{\\text{Determinante}} \\begin{pmatrix}\n",
    "d & -b \\\\\n",
    "-c & a\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Donde la determinante de la matriz $ \\mathbf{A}^T \\mathbf{W} \\mathbf{A} $ es:\n",
    "\n",
    "$$\n",
    "\\text{Determinante} = (3)(4) - (-2)(-2) = 12 - 4 = 8\n",
    "$$\n",
    "\n",
    "Entonces, la inversa es:\n",
    "\n",
    "$$\n",
    "\\mathbf{Q}_{xx} = \\frac{1}{8} \\begin{pmatrix}\n",
    "4 & 2 \\\\\n",
    "2 & 3\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{Q}_{xx} = \\begin{pmatrix}\n",
    "0.5 & 0.25 \\\\\n",
    "0.25 & 0.375\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### Interpretación de $ \\mathbf{Q}_{xx} $\n",
    "\n",
    "La matriz $ \\mathbf{Q}_{xx} $ representa las covarianzas entre las incógnitas ajustadas $ A $ y $ B $. Los elementos en la diagonal principal ($ 0.5 $ y $ 0.375 $) representan las varianzas de $ A $ y $ B $, respectivamente, mientras que los elementos fuera de la diagonal ($ 0.25 $) representan la covarianza entre $ A $ y $ B $.\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "Este cálculo proporciona la matriz de covarianzas $ \\mathbf{Q}_{xx} $, que es crucial para evaluar la precisión y la incertidumbre asociadas a las estimaciones de las elevaciones ajustadas $ A $ y $ B $. Las varianzas en la diagonal pueden utilizarse para calcular las desviaciones estándar de las elevaciones ajustadas, proporcionando así una medida de la precisión de los resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfe6f9b-acd1-4f41-b5b5-56c7c7928a1b",
   "metadata": {},
   "source": [
    "### Ajuste de Nivelación con Propagación de Errores\n",
    "\n",
    "En este paso final, no solo calcularemos las elevaciones ajustadas de los puntos $ A $ y $ B $ utilizando el método de mínimos cuadrados ponderado, sino que también analizaremos cómo se propagan los errores a través del sistema y calcularemos la desviación estándar del peso unitario ($ \\sigma_0 $).\n",
    "\n",
    "### 1. **Cálculo de las Elevaciones Ajustadas**\n",
    "\n",
    "Ya hemos determinado las elevaciones ajustadas $ A $ y $ B $:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A &= 796.218 \\, \\text{m}, \\\\\n",
    "B &= 799.742 \\, \\text{m}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### 2. **Cálculo de los Residuos**\n",
    "\n",
    "El vector de residuos $ \\mathbf{V} $ se calcula como:\n",
    "\n",
    "$$\n",
    "\\mathbf{V} = \\mathbf{A} \\mathbf{X} - \\mathbf{L}\n",
    "$$\n",
    "\n",
    "Sustituyendo:\n",
    "\n",
    "$$\n",
    "\\mathbf{V} = \\begin{pmatrix}\n",
    "1 & 0 & -1 & 0 & 0 \\\\\n",
    "1 & 0 & 0 & -1 & 0 \\\\\n",
    "-1 & 1 & 0 & 0 & 1 \\\\\n",
    "0 & 1 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "796.218 \\\\\n",
    "799.742\n",
    "\\end{pmatrix}\n",
    "- \\begin{pmatrix}\n",
    "796.229 \\\\\n",
    "796.241 \\\\\n",
    "3.532 \\\\\n",
    "799.739 \\\\\n",
    "799.728\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "-0.011 \\\\\n",
    "-0.023 \\\\\n",
    "-0.008 \\\\\n",
    "0.003 \\\\\n",
    "0.014\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### 3. **Desviación Estándar del Peso Unitario $ \\sigma_0 $**\n",
    "\n",
    "La desviación estándar del peso unitario se calcula utilizando la fórmula:\n",
    "\n",
    "$$\n",
    "\\sigma_0 = \\sqrt{\\frac{\\mathbf{v}^T \\mathbf{W} \\mathbf{v}}{r}}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $ \\mathbf{v} $ es el vector de residuos.\n",
    "- $ \\mathbf{W} $ es la matriz de pesos.\n",
    "- $ r = m - n = 5 - 2 = 3 $ es el número de grados de libertad.\n",
    "\n",
    "Calculamos $ \\mathbf{v}^T \\mathbf{W} \\mathbf{v} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}^T \\mathbf{W} \\mathbf{v} = \\begin{pmatrix}\n",
    "-0.011 & -0.023 & -0.008 & 0.003 & 0.014\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "0.5 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0.5 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 2 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "-0.011 \\\\\n",
    "-0.023 \\\\\n",
    "-0.008 \\\\\n",
    "0.003 \\\\\n",
    "0.014\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Calculando:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}^T \\mathbf{W} \\mathbf{v} = (0.5)(-0.011)^2 + (0.5)(-0.023)^2 + (2)(-0.008)^2 + (1)(0.003)^2 + (1)(0.014)^2 = 0.00066\n",
    "$$\n",
    "\n",
    "Luego:\n",
    "\n",
    "$$\n",
    "\\sigma_0 = \\sqrt{\\frac{0.00066}{3}} = \\sqrt{0.00022} \\approx 0.015 \\, \\text{m}\n",
    "$$\n",
    "\n",
    "### 4. **Propagación de Errores**\n",
    "\n",
    "La propagación de errores se realiza a través de la matriz $ \\mathbf{Q}_{l_l} $, que se obtiene de:\n",
    "\n",
    "$$\n",
    "\\mathbf{Q}_{l_l} = \\mathbf{A} \\mathbf{Q}_{xx} \\mathbf{A}^T\n",
    "$$\n",
    "\n",
    "Donde $ \\mathbf{Q}_{xx} $ es la inversa de $ \\mathbf{A}^T \\mathbf{W} \\mathbf{A} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{Q}_{xx} = \\frac{1}{8} \\begin{pmatrix}\n",
    "4 & 2 \\\\\n",
    "2 & 3\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "0.5 & 0.25 \\\\\n",
    "0.25 & 0.375\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Multiplicamos para obtener $ \\mathbf{Q}_{l_l} $:\n",
    "\n",
    "$$\n",
    "\\mathbf{Q}_{l_l} = \\mathbf{A} \\mathbf{Q}_{xx} \\mathbf{A}^T\n",
    "$$\n",
    "\n",
    "Este cálculo proporciona la matriz de covarianzas de las observaciones ajustadas, que se puede utilizar para calcular las desviaciones estándar asociadas con cada medición ajustada.\n",
    "\n",
    "### 5. **Cálculo de Desviaciones Estándar para Medidas Ajustadas**\n",
    "\n",
    "Finalmente, para obtener la desviación estándar de una medida ajustada, se utiliza:\n",
    "\n",
    "$$\n",
    "\\sigma_{l_i} = \\sigma_0 \\sqrt{q_{l_i l_i}}\n",
    "$$\n",
    "\n",
    "Donde $ q_{l_i l_i} $ es el $ i $-ésimo elemento diagonal de la matriz $ \\mathbf{Q}_{l_l} $.\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "El proceso de propagación de errores es fundamental para entender cómo las incertidumbres en las observaciones iniciales afectan a las incógnitas ajustadas y, en última instancia, a las mediciones ajustadas. En este ejemplo, hemos calculado la desviación estándar del peso unitario y utilizado la matriz de covarianza $ \\mathbf{Q}_{xx} $ para evaluar la precisión de las elevaciones ajustadas, completando así un análisis detallado del ajuste por mínimos cuadrados ponderado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f1b09c-c2c9-4e77-928e-aeb4ec5c0177",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
