{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcfba3a8-bea6-40e9-bc21-8b95e4c80342",
   "metadata": {},
   "source": [
    "### 5 Ajuste Paramétrico de Mínimos Cuadrados\n",
    "\n",
    "#### Formulación del Modelo\n",
    "\n",
    "### 5.1 Formulación de la Ecuación del Modelo Paramétrico\n",
    "\n",
    "El modelo paramétrico es un modelo que relaciona algunas observaciones ajustadas ($\\hat{\\ell}$) con algunos parámetros desconocidos (ajustados) ($\\hat{x}$). Esto se puede representar simbólicamente como $\\hat{\\ell} = f(\\hat{x})$. En este tipo de modelo, cada una de las mediciones producirá una ecuación que involucra algunos o todos los parámetros especificados sin que haya otras observaciones involucradas en la ecuación. Por ejemplo, 10 mediciones producirán 10 ecuaciones independientes con la observación (el sujeto) apareciendo solo una vez en cada ecuación. Las ecuaciones paramétricas se formulan de manera que, cuando se sustituyen valores aproximados de los parámetros desconocidos en las ecuaciones, se obtienen las observaciones derivadas o calculadas; las diferencias entre las observaciones originales y estas observaciones derivadas son los errores de cierre. La redundancia de las ecuaciones del modelo paramétrico o el número de grados de libertad de un ajuste se determina como el número de ecuaciones del modelo menos el número de parámetros desconocidos involucrados en las ecuaciones. Dado que el número de ecuaciones del modelo paramétrico siempre es el mismo que el número de observaciones, el número de grados de libertad también se puede determinar como el número de observaciones menos el número de parámetros desconocidos. Las cantidades típicas medidas (las observables) en el levantamiento son la pendiente (o las distancias horizontales), las direcciones horizontales (o ángulos), los ángulos verticales (o ángulos cenitales), los acimutes (o rumbos), las diferencias de elevación, las coordenadas (en Sistemas Globales de Navegación por Satélite [GNSS]), que están interrelacionadas con las observaciones en forma de modelos paramétricos. Tenga en cuenta lo siguiente al formular ecuaciones de modelo paramétrico:\n",
    "\n",
    "1. Los elementos importantes a manipular en las ecuaciones son los parámetros ($x$) y las observaciones ($\\ell$). Identifique qué constituye los parámetros ($x$) y qué constituye las observaciones ($\\ell$) desde el principio. Use símbolos adecuados para representar cada una de las observaciones y los parámetros, y formule las ecuaciones usando estos símbolos.\n",
    "2. Ordene aquellos elementos que representan los parámetros ($x$) y las observaciones ($\\ell$) en las ecuaciones ($\\hat{\\ell} = f(\\hat{x})$) de manera que cada observación se convierta en un sujeto de una ecuación que involucre solo parámetros y valores constantes posibles. Cada uno de los parámetros y observaciones ya identificados debe representarse, por ahora, en símbolos mientras se aplaza el uso de sus valores numéricos hasta que las ecuaciones estén siendo resueltas.\n",
    "\n",
    "A continuación, se muestra cómo las observables y los parámetros (es decir, las coordenadas) están vinculados matemáticamente. Las ecuaciones formuladas para distancia, acimut y dirección total (horizontal) observables se dan con respecto a la Figura 5.1.\n",
    "\n",
    "#### 5.1.1 Distancia Observable\n",
    "\n",
    "Para una distancia de pendiente EDM medida ($s_{ij}$) (desde la estación $i$ hasta la estación $j$ en la Figura 5.1) después de que se hayan aplicado las correcciones meteorológicas e instrumentales, la ecuación de observación (paramétrica) de la distancia puede darse como\n",
    "\n",
    "$$ s_{ij} = \\sqrt{(x_j - x_i)^2 + (y_j - y_i)^2 + (z_j - z_i)^2} \\quad \\text{(5.1)} $$\n",
    "\n",
    "donde ($x_i, y_i, z_i$) y ($x_j, y_j, z_j$) son las coordenadas tridimensionales de la estación $i$ y la estación $j$, respectivamente. Para el sistema de coordenadas bidimensional, se descartarán los componentes $z$.\n",
    "\n",
    "#### 5.1.2 Acimut y Direcciones Horizontales (Total Station)\n",
    "\n",
    "Para el acimut crudo medido ($a_{ij}$) (por estrella o por el uso del equipo de giroscopio en la línea $i$ a $j$ en la Figura 5.1) reducido al sistema de coordenadas de proyección de mapas ($a_{ij}$), la ecuación paramétrica puede darse como\n",
    "\n",
    "$$ a_{ij} = \\text{atan} \\left( \\frac{y_j - y_i}{x_j - x_i} \\right) + \\text{[Quadrant analysis]} \\quad \\text{(5.2)} $$\n",
    "\n",
    "donde $\\text{atan}() $ se usa para representar la función arcotangente o tangente inversa trigonométrica. El análisis de cuadrante se ilustra usando la Figura 5.2. En la figura, la cuadrícula positiva es $X$, y la cuadrícula positiva al norte es $Y$ con cuatro cuadrantes posibles (cuadrante 1, cuadrante 2, cuadrante 3, y cuadrante 4). Suponiendo que los acimutes medidos 0–1, 0–2, 0–3 y 0–4 están ubicados en los cuatro cuadrantes diferentes como se muestra en la Figura 5.2; las ecuaciones paramétricas de los rumbos medidos pueden formularse como sigue.\n",
    "\n",
    "En las ecuaciones formuladas a continuación, $\\text{atan}() $ representa arcotangente o Tangente inversa de; este símbolo se usa principalmente en este libro. Usando $\\text{atan}() $ se obtendrán los ángulos $a_1, a_2, a_3, a_4 $ mostrados en la Figura 5.2 dependiendo del cambio en la coordenada este ($dx = x_j - x_0$) desde el punto 0 y el cambio en la coordenada norte ($dy = y_j - y_0$) desde el punto 0 con $i$ representando la estación vista (tal como $i = 1, 2, 3, 4$). Estos ángulos se pueden determinar usando $\\text{atan}() $ como sigue:\n",
    "\n",
    "1. Si $dx$ es positivo y $dy$ es positivo, ubicando la línea 0–1 en el cuadrante 1 (dando ángulo positivo $a_1$: rumbo 0–1 ($\\beta_{0-1}$ es el mismo que $a_1$):\n",
    "\n",
    "$$ a_1 = \\text{atan} \\left( \\frac{dx}{dy} \\right) \\quad \\text{(5.3)} $$\n",
    "$$ \\beta_{0-1} = a_1 \\quad \\text{(5.4)} $$\n",
    "\n",
    "2. Si $dx$ es positivo y $dy$ es negativo, ubicando la línea 0–2 en el cuadrante 2 (dando ángulo negativo $a_2$: rumbo 0–2 ($\\beta_{0-2}$ es el mismo que $a_2 + 180$):\n",
    "\n",
    "$$ a_2 = \\text{atan} \\left( \\frac{dx}{dy} \\right) \\quad \\text{(5.5)} $$\n",
    "$$ \\beta_{0-2} = a_2 + 180 \\quad \\text{(5.6)} $$\n",
    "\n",
    "3. Si $dx$ es negativo y $dy$ es negativo, ubicando la línea 0–3 en el cuadrante 3 (dando ángulo positivo $a_3$: rumbo 0–3 ($\\beta_{0-3}$ es el mismo que $a_3 + 180$):\n",
    "\n",
    "$$ a_3 = \\text{atan} \\left( \\frac{dx}{dy} \\right) \\quad \\text{(5.7)} $$\n",
    "$$ \\beta_{0-3} = a_3 + 180 \\quad \\text{(5.8)} $$\n",
    "\n",
    "4. Si $dx$ es negativo y $dy$ es positivo, ubicando la línea 0–4 en el cuadrante 4 (dando ángulo negativo $a_4$: rumbo 0–4 ($\\beta_{0-4}$ es el mismo que $a_4 + 360$):\n",
    "\n",
    "$$ a_4 = \\text{atan} \\left( \\frac{dx}{dy} \\right) \\quad \\text{(5.9)} $$\n",
    "$$ \\beta_{0-4} = a_4 + 360 \\quad \\text{(5.10)} $$\n",
    "\n",
    "Para las observaciones de dirección horizontal cruda (dirección total) medidas ($d_{ij}$) reducidas al sistema de coordenadas de proyección de mapas y medidas en relación con el “cero” del círculo horizontal, la ecuación paramétrica puede darse como\n",
    "\n",
    "$$ d_{ij} = \\text{atan} \\left( \\frac{y_j - y_i}{x_j - x_i} \\right) - \\gamma_{1+} [Quadrant analysis] \\quad \\text{(5.11)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048bc240-4ba1-4786-8f38-075188f3dc00",
   "metadata": {},
   "source": [
    "#### 5.1.2 Acimut y Direcciones Horizontales (continuación)\n",
    "\n",
    "donde $\\gamma_i$ es la orientación desconocida (parámetro) en la estación $i$. El término del parámetro de orientación en la Ecuación (5.11) necesita un poco más de énfasis para que las mediciones de acimut (rumbo) y dirección no se malinterpreten como significando lo mismo. Las direcciones del instrumento total (o teodolito) son solo lecturas de dirección arbitrarias dadas por el instrumento con respecto a la lectura cero del instrumento; no son lo mismo que los acimutes (o rumbos), que se dan con respecto a la dirección del norte (la dirección del norte siendo su punto de referencia cero). La diferencia entre la lectura cero del instrumento total y el punto cero para la medición de acimut (o rumbo) es el parámetro de orientación desconocido. Este parámetro de orientación desconocido para la lectura de dirección del instrumento total en una línea es la cantidad de ángulo por la cual la medición de dirección del instrumento total en esa línea debe ajustarse para hacer que esa lectura de dirección del instrumento total sea idéntica al acimut o rumbo de esa línea. Este valor no se determina directamente en una configuración, pero se considera como un parámetro de orientación desconocido ($\\gamma$), lo que lo convierte en un parámetro a determinar en un ajuste. Dado que nadie está interesado en conocer el valor numérico de un parámetro de orientación, el parámetro de orientación se denomina de otra manera como parámetro de molestia. Se requiere en las ecuaciones del modelo para obtener ecuaciones correctas, pero no se requiere el conocimiento de su valor. Tenga en cuenta que siempre habrá un parámetro de orientación desconocido por estación de configuración por instrumento para todas las direcciones que tengan una lectura de punto cero común del instrumento total; si el punto cero del instrumento total en el espacio cambia (como resultado de nivelación y reconfiguración del instrumento) a otro punto o sobre la misma estación (P), cada configuración del instrumento total involucrando lecturas direccionales tendrá un parámetro de orientación desconocido por cada estación de configuración. Por ejemplo, si las direcciones del instrumento total se realizan en cuatro estaciones de configuración (o si el punto cero del instrumento se restablece cuatro veces en una estación), habrá cuatro parámetros de orientación desconocidos para los cuatro conjuntos de direcciones realizados en las cuatro estaciones (o en la misma estación). Tenga en cuenta que los parámetros de orientación no se implican cuando se miden los ángulos entre dos líneas, como se discutió en la Sección 5.1.3.\n",
    "\n",
    "El propósito principal de relacionar la dirección del instrumento total con el acimut (o rumbo) es porque no hay una ecuación directa para la medición de dirección del instrumento total; esto, por lo tanto, requiere que la ecuación correspondiente de acimut (o rumbo) de la línea se derive indirectamente con el parámetro de orientación introducido para reducir el acimut a la medición de dirección del instrumento total. Por ejemplo, la dirección del instrumento total de una línea es igual al acimut de esa línea menos el parámetro de orientación desconocido para esa configuración, como se da en la Ecuación (5.11). Tenga en cuenta que al elegir el parámetro de orientación desconocido, uno no necesita visualizar primero cómo el valor se relacionará con el acimut; todo lo que se requerirá es elegir un símbolo arbitrario para el parámetro. Además, la consistencia en la aplicación del parámetro de orientación en las ecuaciones del modelo es importante. El concepto del parámetro de orientación desconocido se ilustra en los Ejemplos 5.5 y 5.6.\n",
    "\n",
    "### 5.1.3 Ángulo Horizontal Observable\n",
    "\n",
    "El ángulo horizontal medido ($\\theta_{ijk}$) se puede dar como la diferencia entre dos mediciones de dirección ($d_{ik}$ y $d_{ij}$) como se muestra en la Figura 5.3.\n",
    "\n",
    "Para el ángulo medido ($\\theta_{ijk}$) reducido al sistema de coordenadas de proyección de mapas, la ecuación paramétrica se puede dar como\n",
    "\n",
    "$$ \\theta_{ijk} = \\text{atan} \\left( \\frac{x_k - x_i}{y_k - y_i} \\right) - \\text{atan} \\left( \\frac{x_j - x_i}{y_j - y_i} \\right) \\quad \\text{(5.12)} $$\n",
    "\n",
    "donde el punto $i$ es la estación del instrumento y los puntos $j$ y $k$ son los puntos objetivo. Se puede ver en la Ecuación (5.12) que el parámetro de orientación ($\\gamma$) no está involucrado en las mediciones de ángulo.\n",
    "\n",
    "### 5.1.4 Ángulo Cenital Observable\n",
    "\n",
    "Para el ángulo cenital crudo medido ($Z_{ij}$) reducido al plano local para la línea $i$ a $j$ en la Figura 5.3, la ecuación paramétrica (en el caso tridimensional) se puede dar como\n",
    "\n",
    "$$ Z_{ij} = \\text{atan} \\left( \\frac{\\sqrt{(x_j - x_i)^2 + (y_j - y_i)^2}}{(z_j - z_i)} \\right) \\quad \\text{(5.13)} $$\n",
    "\n",
    "### 5.1.5 Diferencia de Coordenadas Observable\n",
    "\n",
    "Las diferencias de coordenadas GNSS (en coordenadas geocéntricas tridimensionales en el sistema de coordenadas geodésicas) para una línea base $i$ a $j$ en la Figura 5.3 producen las siguientes ecuaciones paramétricas:\n",
    "\n",
    "$$ \\Delta x_{ij} = x_j - x_i $$\n",
    "$$ \\Delta y_{ij} = y_j - y_i $$\n",
    "$$ \\Delta z_{ij} = z_j - z_i \\quad \\text{(5.14)} $$\n",
    "\n",
    "donde $\\Delta x_{ij}$, $\\Delta y_{ij}$ y $\\Delta z_{ij}$ son los vectores de línea base medidos entre los puntos $i$ y $j$.\n",
    "\n",
    "### 5.1.6 Diferencia de Elevación Observable\n",
    "\n",
    "La medición de la diferencia de elevación ($\\Delta h_{ij}$) entre los puntos $i$ y $j$ en la Figura 5.3 (basada en el procedimiento de nivelación diferencial) produce la siguiente ecuación paramétrica:\n",
    "\n",
    "$$ \\Delta h_{ij} = h_j - h_i \\quad \\text{(5.15)} $$\n",
    "\n",
    "donde $h_i$ y $h_j$ son las alturas de los puntos $i$ y $j$ sobre un datum dado, respectivamente. La diferencia de elevación ($\\Delta h_{ij}$) entre los puntos $i$ y $j$ en la Figura 5.3 (basada en el procedimiento de nivelación trigonométrica con equipo de estación total, asumiendo que la distancia inclinada entre los puntos $i$ y $j$ es corta e ignorando la curvatura terrestre y las correcciones de refracción atmosférica) no se mide directamente pero se calcula (como parámetro desconocido, $x$) de la siguiente manera:\n",
    "\n",
    "$$ \\Delta h_{ij} = HI - HT + s_{ij} \\cos z_{ij} \\quad \\text{(5.16)} $$\n",
    "\n",
    "donde $HI$ es la altura medida del instrumento de la estación total en el punto $i$, $HT$ es la altura medida del objetivo en el punto $j$, $s_{ij}$ es la distancia inclinada medida, y $z_{ij}$ es el ángulo cenital medido. Dado que las cantidades medidas en la Ecuación (5.16) son $t^T = [HI \\, HT \\, s_{ij} \\, z_{ij}]$ y el parámetro desconocido, $x = [\\Delta h_{ij}]$, entonces la Ecuación (5.16) es un caso especial de la ecuación general del modelo $x = f(\\hat{\\ell})$. Si la ecuación se reordena, forma la ecuación general del modelo $f(x, \\hat{\\ell}) = 0$, como sigue:\n",
    "\n",
    "$$ \\Delta h_{ij} - HI + HT - s_{ij} \\cos z_{ij} = 0 \\quad \\text{(5.17)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be775ff9-da13-4011-835b-9ec383e53c51",
   "metadata": {},
   "source": [
    "### 5.2 Ecuaciones de Modelo Paramétrico Típicas\n",
    "\n",
    "Se proporcionan ecuaciones de modelo paramétrico típicas en los ejemplos dados en esta sección.\n",
    "\n",
    "#### Ejemplo 5.1\n",
    "\n",
    "Dado el siguiente problema de transformación de dos parámetros que relaciona las coordenadas locales de la foto ($e, n$) con el sistema global de coordenadas fotogramétricas del modelo ($E, N$) y las coordenadas correspondientes de los puntos 1 y 2 (refiriéndose a la Tabla 5.1 y la Figura 5.4):\n",
    "\n",
    "$$ E_i = ae_i - bn_i \\quad \\text{(5.18)} $$\n",
    "$$ N_i = an_i + be_i \\quad \\text{(5.19)} $$\n",
    "\n",
    "Si las coordenadas ($E, N$) de los puntos 1 y 2 se consideran como mediciones, ($e, n$) las coordenadas de los puntos 1 y 2 son valores precisamente conocidos, y las cantidades $a$ y $b$ son las desconocidas a determinar, escriba el modelo matemático apropiado ($\\hat{\\ell} = f(\\hat{x})$) para el problema.\n",
    "\n",
    "#### Solución:\n",
    "\n",
    "El modelo paramétrico debe parecerse a $\\hat{\\ell} = f(\\hat{x})$. Tenga en cuenta que en este problema, las coordenadas ($e, n$) de los puntos 1 y 2 son valores precisamente conocidos (considerados como constantes). Se siguen los pasos dados en la Sección 5.1 para formular las ecuaciones paramétricas como sigue:\n",
    "\n",
    "1. Dado que las coordenadas ($E, N$) de los puntos 1 y 2 bajo el sistema global se consideran como las únicas mediciones con las otras coordenadas dadas como constantes, solo habrá cuatro observaciones. Los parámetros desconocidos ($x$) son la cuestión $a$ y $b$. En esta etapa, las observaciones se representan por los símbolos $\\ell = [E_1, N_1, E_2, N_2]^T$, donde $E_1$ y $N_1$ son las coordenadas este y norte (en el sistema global) para el punto 1.\n",
    "2. Al observar las Ecuaciones representativas (5.18) y (5.19), se puede ver que cada elemento del vector de observación ($\\ell$) es un sujeto independiente equacionado a una expresión que involucra los elementos ($a, b$) de los parámetros ($x$) con algunas cantidades constantes $e_i$ y $n_i$. Las ecuaciones ya están en el arreglo requerido $\\hat{\\ell} = f(\\hat{x})$ con cada punto asociado a dos ecuaciones (Ecuaciones (5.18) y (5.19)). Las ecuaciones finales del modelo paramétrico pueden escribirse para todos los puntos como:\n",
    "\n",
    "$$ \\hat{E}_1 = \\hat{a}e_1 - \\hat{b}n_1 \\quad \\text{(5.20)} $$\n",
    "$$ \\hat{N}_1 = \\hat{a}n_1 + \\hat{b}e_1 \\quad \\text{(5.21)} $$\n",
    "$$ \\hat{E}_2 = \\hat{a}e_2 - \\hat{b}n_2 \\quad \\text{(5.22)} $$\n",
    "$$ \\hat{N}_2 = \\hat{a}n_2 + \\hat{b}e_2 \\quad \\text{(5.23)} $$\n",
    "\n",
    "donde ($e_1, n_1$) y ($e_2, n_2$) son, respectivamente, las coordenadas precisamente conocidas de los puntos 1 y 2 que permanecerán sin ajustar (consideradas como cantidades constantes); ($\\hat{E}_1, \\hat{N}_1$) y ($\\hat{E}_2, \\hat{N}_2$) representan las coordenadas ajustadas del modelo de los puntos 1 y 2, respectivamente; y ($\\hat{a}, \\hat{b}$) representan los parámetros ajustados (desconocidos). Tenga en cuenta que ($e_1, n_1$) y ($e_2, n_2$) no tienen ningún sombrero agregado a ellos ya que son cantidades constantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f9b51-707c-4d71-afde-c6a18dda649d",
   "metadata": {},
   "source": [
    "### Ejemplo 5.2\n",
    "\n",
    "Las coordenadas horizontales ($x, y$) del punto PT2 deben determinarse en una encuesta de itinerario horizontal en la Figura 5.5. Las cantidades medidas son el acimut Az, las distancias $d_1$ y $d_2$, y el ángulo ($\\alpha$) en el punto PT2.\n",
    "\n",
    "Si las coordenadas de los puntos PT1 y PT3 están fijadas, formule las relaciones ($\\hat{\\ell} = f(\\hat{x})$) entre las observaciones y los parámetros desconocidos.\n",
    "\n",
    "#### Solución:\n",
    "\n",
    "El modelo paramétrico a formular debe parecerse a $\\hat{\\ell} = f(\\hat{x})$. Los parámetros desconocidos en este problema son $x$ y $y$ del punto PT2. Siguiendo los pasos dados en el Ejemplo 5.1 y el procedimiento de análisis de cuadrante en la Sección 5.1.2, el modelo paramétrico requerido se puede formular como sigue:\n",
    "\n",
    "1. Las cantidades medidas son el acimut Az, las distancias $d_1$ y $d_2$, y el ángulo $\\alpha$; constituyen las observaciones ($\\ell$), que son cuatro en número. En esta etapa, las observaciones están representadas por los símbolos $\\ell = [Az \\, d_1 \\, d_2 \\, \\alpha]^T$. Los parámetros son las coordenadas horizontales ($x, y$) del punto PT2 que deben determinarse. Las coordenadas de los puntos PT1 y PT3 están dadas, pero no deben ajustarse; por lo tanto, se consideran como cantidades constantes.\n",
    "2. A partir de la comprensión del tipo de modelo ($\\hat{\\ell} = f(\\hat{x})$) que se va a formular, cada elemento del vector de observación ($\\ell$) debe ser un sujeto independiente igualado a una expresión que involucre los parámetros ($x, y$) y algunas cantidades constantes (coordenadas de los puntos PT1 y PT3). Las ecuaciones formuladas son (5.24)-(5.27).\n",
    "\n",
    "Dado que hay cuatro observaciones, son posibles cuatro ecuaciones correspondientes, como sigue. Para el rumbo Az de la línea PT1–PT2, se puede ver en la Figura 5.5 que la línea está en el primer cuadrante (refiriéndose a la Figura 5.2). La ecuación correspondiente para Az se puede dar como\n",
    "\n",
    "$$ \\hat{Az} = \\text{atan} \\left( \\frac{\\hat{y} - 1000}{\\hat{x} - 1000} \\right) \\quad \\text{(5.24)} $$\n",
    "\n",
    "Para cada observación de distancia, el inverso de las dos coordenadas correspondientes usando el teorema de Pitágoras habitual se da como\n",
    "\n",
    "$$ \\hat{d}_1 = \\sqrt{(\\hat{x} - 1000)^2 + (\\hat{y} - 1000)^2} \\quad \\text{(5.25)} $$\n",
    "$$ \\hat{d}_2 = \\sqrt{(2050 - \\hat{x})^2 + (800 - \\hat{y})^2} \\quad \\text{(5.26)} $$\n",
    "\n",
    "Usando el concepto de que un ángulo es la diferencia entre dos rumbos, el ángulo medido $\\alpha$ será igual al rumbo de la línea PT2–PT3 menos el rumbo de la línea PT2–PT1 más 360° para hacer que el rumbo sea un valor positivo:\n",
    "\n",
    "$$ \\text{Rumbo de la línea PT2–PT1 (en el cuadrante 3)} = \\text{atan} \\left( \\frac{1000 - \\hat{x}}{1000 - \\hat{y}} \\right) + 180 $$\n",
    "\n",
    "$$ \\text{Rumbo de la línea PT2–PT3 (en el cuadrante 2)} = \\text{atan} \\left( \\frac{2050 - \\hat{x}}{800 - \\hat{y}} \\right) + 180 $$\n",
    "\n",
    "$$ \\hat{\\alpha} = \\text{atan} \\left( \\frac{2050 - \\hat{x}}{800 - \\hat{y}} \\right) - \\text{atan} \\left( \\frac{1000 - \\hat{x}}{1000 - \\hat{y}} \\right) + 360° \\quad \\text{(5.27)} $$\n",
    "\n",
    "donde ($\\hat{x}, \\hat{y}$) son las coordenadas ajustadas (parámetros) del punto PT2, ($\\hat{d}_1, \\hat{d}_2$) son las distancias ajustadas, $\\hat{Az}$ es el rumbo ajustado, y $\\hat{\\alpha}$ es el ángulo ajustado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5f3f48-ba0e-4313-8e67-47ad5c1d72e6",
   "metadata": {},
   "source": [
    "### Ejemplo 5.3\n",
    "\n",
    "Considere una red de nivelación mostrada en la Figura 5.6 con las direcciones de las flechas que indican las direcciones de los recorridos de nivelación. Los puntos A y B son los bancos de referencia dados cuyas elevaciones son bien conocidas como $H_A$ y $H_B$, respectivamente; las elevaciones $H_1$, $H_2$ y $H_3$ de los puntos 1, 2 y 3, respectivamente, deben determinarse. Las diferencias de altura niveladas y las distancias aproximadas entre los puntos correspondientes se miden y se dan como se muestra en la figura. Formule las ecuaciones del modelo paramétrico ($\\hat{\\ell} = f(\\hat{x})$) para este problema.\n",
    "\n",
    "#### Solución:\n",
    "\n",
    "Las ecuaciones del modelo paramétrico deben parecerse a $\\hat{\\ell} = f(\\hat{x})$. Usando los pasos dados en el Ejemplo 5.1, el modelo paramétrico requerido se puede formular como sigue:\n",
    "\n",
    "1. Las diferencias de altura niveladas y las distancias aproximadas entre los puntos correspondientes se miden. Dado que las distancias aproximadas no se usan directamente para derivar elevaciones de puntos en levantamientos de nivelación diferencial, las únicas observaciones ($\\ell$) que se considerarán son las diferencias de elevación medidas ($h_{1B}, h_{13}, h_{12}, h_{1A}, h_{32}$). Como de costumbre, las observaciones están representadas por los símbolos $\\ell = [h_{1B}, h_{13}, h_{12}, h_{1A}, h_{32}]^T$. Las elevaciones de los bancos de referencia dados ($H_A$ y $H_B$) se consideran como constantes ya que no van a cambiar de valor en un ajuste y no son parámetros ni observaciones. Las elevaciones $H_1$, $H_2$ y $H_3$ deben determinarse, por lo que son los parámetros ($x$).\n",
    "2. Al formular el modelo ($\\hat{\\ell} = f(\\hat{x})$), cada elemento del vector de observación ($\\ell$) debe ser un sujeto independiente igualado a una expresión que involucre las elevaciones ($H_1, H_2, H_3$) de los parámetros ($x$) y las elevaciones de los puntos A y B como cantidades constantes. Para cinco observaciones, las siguientes cinco ecuaciones paramétricas son posibles:\n",
    "\n",
    "$$ \\hat{h}_{1B} = H_B - \\hat{H}_1 \\quad \\text{(5.28)} $$\n",
    "$$ \\hat{h}_{13} = \\hat{H}_3 - \\hat{H}_1 \\quad \\text{(5.29)} $$\n",
    "$$ \\hat{h}_{12} = \\hat{H}_2 - \\hat{H}_1 \\quad \\text{(5.30)} $$\n",
    "$$ \\hat{h}_{1A} = H_A - \\hat{H}_1 \\quad \\text{(5.31)} $$\n",
    "$$ \\hat{h}_{32} = \\hat{H}_2 - \\hat{H}_3 \\quad \\text{(5.32)} $$\n",
    "\n",
    "Se puede ver en las Ecuaciones (5.28) y (5.31) que $H_A$ y $H_B$ no tienen sombreros ya que no son parámetros ni observaciones.\n",
    "\n",
    "### Ejemplo 5.4\n",
    "\n",
    "El ángulo $\\theta$ y la distancia $S_{AB}$ en la red de itinerarios mostrada en la Figura 5.7 fueron medidos. En el itinerario, los puntos A y C están fijados. Formule las ecuaciones del modelo paramétrico para determinar las coordenadas ($x, y$) del punto B.\n",
    "\n",
    "#### Solución:\n",
    "\n",
    "Las ecuaciones del modelo paramétrico deben parecerse a $\\hat{\\ell} = f(\\hat{x})$. Usando los pasos dados en el Ejemplo 5.2 y la relación de que el ángulo $\\theta$ es igual al rumbo de la línea AC menos el rumbo de la línea AB, se puede formular la Ecuación (5.33); se aplica el teorema de Pitágoras para obtener la Ecuación (5.34):\n",
    "\n",
    "$$ \\hat{\\theta} = \\text{atan} \\left( \\frac{1500 - 1000}{500 - 900} \\right) - \\text{atan} \\left( \\frac{\\hat{x} - 1000}{\\hat{y} - 900} \\right) + 180° \\quad \\text{(5.33)} $$\n",
    "\n",
    "$$ \\hat{S}_{AB} = \\sqrt{(\\hat{x} - 1000)^2 + (\\hat{y} - 900)^2} \\quad \\text{(5.34)} $$\n",
    "\n",
    "donde $\\hat{S}_{AB}$ es la distancia ajustada y ($\\hat{x}, \\hat{y}$) son las coordenadas ajustadas (parámetros) del punto B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7db95e4-ac64-4b36-ab05-f97b6905b82c",
   "metadata": {},
   "source": [
    "### Ejemplo 5.5\n",
    "\n",
    "El punto O ($x, y$) en la Figura 5.8 debe ser reubicado a partir de dos puntos de control dados A ($x_A, y_A$) y B ($x_B, y_B$). El acimut O–A se midió como $\\ell_1 = 40°$; y las direcciones de la estación total O–A y O–B se midieron como $\\ell_2 = 10°$ y $\\ell_3 = 65°$, respectivamente. Formule las ecuaciones del modelo paramétrico ($\\hat{\\ell} = f(\\hat{x})$) para este problema.\n",
    "\n",
    "#### Solución:\n",
    "\n",
    "Este ejemplo ilustra la diferencia entre acimut y direcciones de la estación total (el parámetro de orientación). Basado en el concepto de parámetros de orientación discutido en la Sección 5.1.2 y los pasos dados en el Ejemplo 5.1, el modelo paramétrico requerido ($\\hat{\\ell} = f(\\hat{x})$) se puede formular como sigue:\n",
    "\n",
    "1. A partir de la pregunta, se midió el acimut O–A (o $\\ell_1$) y las direcciones de la estación total O–A ($\\ell_2$) y O–B ($\\ell_3$), convirtiéndolos en las observaciones ($\\ell$) para este problema. Las observaciones están representadas por los símbolos $\\ell = [\\ell_1, \\ell_2, \\ell_3]^T$. Las coordenadas ($x, y$) del punto O son los principales parámetros a determinar. Dado que las direcciones de la estación total también se miden desde una sola configuración, hay un parámetro de orientación desconocido adicional ($\\gamma_0$) que debe incluirse para que la formulación del modelo esté completa. Los parámetros totales en este problema son $x = [x \\, y \\, \\gamma_0]^T$.\n",
    "\n",
    "2. Al formular las ecuaciones del modelo paramétrico ($\\hat{\\ell} = f(\\hat{x})$), cada elemento del vector de observación ($\\ell$) debe ser un sujeto independiente igualado a una expresión que involucre los elementos de los parámetros $x = [x \\, y \\, \\gamma_0]^T$ y las cantidades constantes (que pueden requerirse en el análisis de cuadrantes). Las ecuaciones paramétricas se formulan como sigue:\n",
    "\n",
    "Para la medición del acimut de la línea O–A (en el primer cuadrante):\n",
    "\n",
    "$$ \\hat{\\ell}_1 = \\text{atan} \\left( \\frac{y_A - \\hat{y}}{x_A - \\hat{x}} \\right) \\quad \\text{(5.35)} $$\n",
    "\n",
    "Para la medición de la dirección de la estación total de la línea O–A, que es igual al acimut de la línea O–A (que está en el primer cuadrante) menos el parámetro de orientación desconocido ($\\gamma_0$), se puede dar como:\n",
    "\n",
    "$$ \\hat{\\ell}_2 = \\text{atan} \\left( \\frac{y_A - \\hat{y}}{x_A - \\hat{x}} \\right) - \\hat{\\gamma}_0 \\quad \\text{(5.36)} $$\n",
    "\n",
    "De manera similar, para la medición de la dirección de la estación total de la línea O–B:\n",
    "\n",
    "$$ \\hat{\\ell}_3 = \\text{atan} \\left( \\frac{y_B - \\hat{y}}{x_B - \\hat{x}} \\right) - \\hat{\\gamma}_0 + 180° \\quad \\text{(5.37)} $$\n",
    "\n",
    "Como se puede ver en la Ecuación (5.36), si no se aplica el parámetro de orientación desconocido ($\\gamma_0$), la ecuación será exactamente la misma que la del rumbo ajustado ($\\hat{\\ell}_1$); esto no debería ser así ya que el rumbo de la línea dada es aproximadamente $\\ell_1 = 40°$ y la medición de la dirección de la estación total de la misma línea es $\\ell_2 = 10°$. Se puede ver que el parámetro de orientación desconocido ($\\gamma_0$) en este caso estará cerca de 30°. Es aconsejable mantener siempre el parámetro de orientación como desconocido en el ajuste de mínimos cuadrados para que se pueda determinar su mejor estimación como parte de los parámetros desconocidos. En el problema anterior, el número de observaciones es 3 (es decir, $\\ell_1, \\ell_2, \\ell_3$) y el número de parámetros desconocidos es 3 (es decir, $x, y, \\gamma_0$). Los pasos discutidos en este ejemplo deben seguirse al formular ecuaciones (o modelos) que involucren mediciones de direcciones de la estación total.\n",
    "\n",
    "### Ejemplo 5.6\n",
    "\n",
    "Los puntos 1 y 2 en la Figura 5.9 deben coordinarse por la intersección de dos puntos de control dados A ($x_A, y_A$) y B ($x_B, y_B$). Las direcciones de la estación total en A son $\\ell_1, \\ell_2, \\ell_3$; las direcciones de la estación total en B son $\\ell_4, \\ell_5, \\ell_6$; y las distancias medidas desde el punto B son $\\ell_7$ y $\\ell_{10}$ como se muestra en la figura. Formule las ecuaciones del modelo paramétrico ($\\hat{\\ell} = f(\\hat{x})$) para este problema.\n",
    "\n",
    "#### Solución:\n",
    "\n",
    "Este ejemplo es para explicar más cómo introducir parámetros de orientación desconocidos en las ecuaciones del modelo paramétrico. Usando los pasos dados en el Ejemplo 5.5, las siguientes ecuaciones del modelo paramétrico se pueden formular:\n",
    "\n",
    "1. A partir de la pregunta, las observaciones ($\\ell$) son las direcciones de la estación total en A ($\\ell_1, \\ell_2, \\ell_3$), las direcciones de la estación total en B ($\\ell_4, \\ell_5, \\ell_6$) y las distancias ($\\ell_7, \\ell_8, \\ell_9, \\ell_{10}$), que se pueden dar como $\\ell = [\\ell_1, \\ell_2, \\ell_3, \\ell_4, \\ell_5, \\ell_6, \\ell_7, \\ell_8, \\ell_9, \\ell_{10}]^T$. Los principales parámetros son las coordenadas ($x_A, y_A$) y ($x_B, y_B$) a determinarse directamente. Dado que hay dos puntos de configuración de la estación total (puntos A y B) donde se realizan mediciones direccionales, habrá dos parámetros de orientación desconocidos ($\\gamma_A$ y $\\gamma_B$) correspondientes a esos puntos de configuración. Los parámetros totales en este problema se pueden dar como $x^T = [x_A \\, y_A \\, x_B \\, y_B \\, \\gamma_A \\, \\gamma_B]^T$.\n",
    "\n",
    "2. Al formular las ecuaciones del modelo paramétrico ($\\hat{\\ell} = f(\\hat{x})$), cada elemento del vector de observación ($\\ell$) debe ser un sujeto independiente igualado a una expresión que involucre los elementos de los parámetros ($x$) y algunas cantidades constantes (que pueden requerirse en el análisis de cuadrantes). Dado que hay 10 observaciones, el número de ecuaciones de modelo paramétrico posibles es 10. Se formulan como sigue:\n",
    "\n",
    "- En el punto A, suponga que el cero del instrumento está en el lado izquierdo de la línea A-1. Use el concepto de que cada observación de una línea es igual al acimut de esa línea menos el parámetro de orientación en ese punto:\n",
    "\n",
    "$$ \\hat{\\ell}_1 = \\text{atan} \\left( \\frac{\\hat{y}_1 - y_A}{\\hat{x}_1 - x_A} \\right) + 360° - \\hat{\\gamma}_A \\quad \\text{(5.38)} $$\n",
    "$$ \\hat{\\ell}_2 = \\text{atan} \\left( \\frac{\\hat{y}_2 - y_A}{\\hat{x}_2 - x_A} \\right) + 360° - \\hat{\\gamma}_A \\quad \\text{(5.39)} $$\n",
    "$$ \\hat{\\ell}_3 = \\text{atan} \\left( \\frac{y_B - y_A}{x_B - x_A} \\right) + 360° - \\hat{\\gamma}_A \\quad \\text{(5.40)} $$\n",
    "\n",
    "- En el punto B, suponga que el cero del instrumento está en el lado izquierdo de la línea B-2. Use el concepto de que cada observación de una línea es igual al acimut de esa línea menos el parámetro de orientación en ese punto:\n",
    "\n",
    "$$ \\hat{\\ell}_4 = \\text{atan} \\left( \\frac{\\hat{y}_1 - y_B}{\\hat{x}_1 - x_B} \\right) + 180° - \\hat{\\gamma}_B \\quad \\text{(5.41)} $$\n",
    "$$ \\hat{\\ell}_5 = \\text{atan} \\left( \\frac{\\hat{y}_2 - y_B}{\\hat{x}_2 - x_B} \\right) + 180° - \\hat{\\gamma}_B \\quad \\text{(5.42)} $$\n",
    "$$ \\hat{\\ell}_6 = \\text{atan} \\left( \\frac{\\hat{y}_3 - y_B}{\\hat{x}_3 - x_B} \\right) + 180° - \\hat{\\gamma}_B \\quad \\text{(5.43)} $$\n",
    "\n",
    "- Use el teorema de Pitágoras para determinar las distancias desde las coordenadas correspondientes:\n",
    "\n",
    "$$ \\hat{\\ell}_7 = \\sqrt{(\\hat{x}_1 - x_A)^2 + (\\hat{y}_1 - y_A)^2} \\quad \\text{(5.44)} $$\n",
    "$$ \\hat{\\ell}_8 = \\sqrt{(\\hat{x}_2 - x_A)^2 + (\\hat{y}_2 - y_A)^2} \\quad \\text{(5.45)} $$\n",
    "$$ \\hat{\\ell}_9 = \\sqrt{(\\hat{x}_2 - x_B)^2 + (\\hat{y}_2 - y_B)^2} \\quad \\text{(5.46)} $$\n",
    "$$ \\hat{\\ell}_{10} = \\sqrt{(\\hat{x}_1 - x_B)^2 + (\\hat{y}_1 - y_B)^2} \\quad \\text{(5.47)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5619e930-46ac-4590-bc70-93badb0d406f",
   "metadata": {},
   "source": [
    "### 5.3 Formulación del Modelo de Ajuste Básico\n",
    "\n",
    "Las ecuaciones del modelo paramétrico se expresan simbólicamente como $\\hat{\\ell} = f(\\hat{x})$, lo que significa que una observación ajustada en un vector ($\\hat{\\ell}$) de observaciones ajustadas es funcionalmente igual a una combinación de parámetros ajustados ($\\hat{x}$). El modelo de mínimos cuadrados paramétrico también se conoce como el modelo Gauss-Markov o el modelo de ecuación de observación. Al derivar los pasos de ajuste del modelo paramétrico, las siguientes directrices pueden ser útiles:\n",
    "\n",
    "1. Todos los símbolos o variables utilizados en la formulación de una ecuación de modelo paramétrico particular deben ser únicos; ninguna de las dos variables debe representar la misma cantidad en el mismo modelo. En otras palabras, dos variables diferentes en un modelo no deben tener el mismo significado. Esto es necesario para evitar confundir los significados de los símbolos o variables utilizados en el mismo modelo.\n",
    "2. Cada símbolo o variable utilizado en un modelo debe estar claramente definido (generalmente después de que se hayan utilizado) para aumentar la claridad de los pasos que se están tomando.\n",
    "3. La derivación del modelo de ajuste debe fluir lógicamente de un paso a otro con una explicación breve y concisa de cada paso, incluida una explicación del propósito del paso y por qué el paso es necesario.\n",
    "4. Cada ecuación derivada debe estar numerada adecuadamente para que pueda ser citada más tarde usando ese número. La convención de numeración debe ser coherente con la convención utilizada en este libro.\n",
    "\n",
    "La formulación de los modelos de ajuste paramétrico de mínimos cuadrados consiste en los siguientes pasos generales, que se desarrollan más en las siguientes secciones:\n",
    "\n",
    "i) **Formular las ecuaciones del modelo paramétrico** ($\\hat{\\ell} = f(\\hat{x})$) como se discutió en las Secciones 5.1 y 5.2. Tenga en cuenta que las matrices de covarianza (o matrices de peso) declaradas con el modelo formulado son relevantes en la formulación de las funciones de variación más adelante.\n",
    "\n",
    "ii) **Linealizar las ecuaciones del modelo**. Dado que las ecuaciones del modelo pueden ser no lineales, deben linealizarse mediante la expansión de la serie de Taylor (consulte la Sección 5.4).\n",
    "\n",
    "iii) **Derivar un nuevo conjunto de ecuaciones conocido como función de variación**. Esto se hace incorporando las ecuaciones del modelo paramétrico linealizadas en el criterio de mínimos cuadrados (consulte la Sección 5.5).\n",
    "\n",
    "iv) **Derivar el sistema de ecuaciones normales**. Esto se hace determinando las derivadas parciales de la función de variación con respecto a las incógnitas en la función y estableciendo las derivadas parciales en cero para producir lo que comúnmente se conoce como un sistema de ecuaciones normales (consulte la Sección 5.6).\n",
    "\n",
    "v) **Resolver el sistema de ecuaciones normales**. La solución de las ecuaciones normales proporciona los valores ajustados para las cantidades desconocidas (consulte la Sección 5.7)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0aa4ab-580c-40ab-b699-3c9e41826c39",
   "metadata": {},
   "source": [
    "### 5.4 Linealización de Ecuaciones del Modelo Paramétrico\n",
    "\n",
    "La linealización de las ecuaciones del modelo paramétrico se basa en la expansión de la serie de Taylor discutida en el Capítulo 2. Consulte las Ecuaciones (E.22)–(E.29) para una revisión de las derivadas parciales de funciones relacionadas con matrices y vectores. En esta sección, el modelo paramétrico con y sin parámetros de molestia será linealizado. Recuerde también que la estimación de mínimos cuadrados es iterativa debido a la necesidad práctica de linealizar el modelo funcional mediante la expansión de la serie de Taylor. Esta solución iterativa es necesaria ya que los valores iniciales (aproximados) de los parámetros desconocidos rara vez se obtienen con un nivel de precisión suficiente para que la expansión de la serie sea válida. Después de que los valores iniciales de los parámetros se introducen en el primer ajuste, las soluciones iterativas subsiguientes se utilizan como nuevos valores iniciales, y el procedimiento de ajuste se repite hasta que una solución particular no sea significativamente diferente de la anterior; en este punto, se dice que el ajuste ha convergido a una solución final. Esta solución final se considera que contiene los valores finales de los parámetros desconocidos.\n",
    "\n",
    "### 5.4.1 Linealización del Modelo Paramétrico Sin Parámetro de Molestia\n",
    "\n",
    "Dado el siguiente modelo paramétrico, que no contiene parámetros de molestia (Ecuación 5.48),\n",
    "\n",
    "$$ \\hat{\\ell} = f(\\hat{x}) \\quad \\text{(5.48)} $$\n",
    "\n",
    "donde $f$ es un vector de modelos matemáticos, $\\hat{x}$ es un vector de parámetros desconocidos, $\\hat{\\ell}$ es un vector de observaciones, y $P$ es la matriz de peso de las observaciones. Se debe prestar especial atención a la matriz de peso $P$, que debe utilizarse explícitamente en cualquier derivación que involucre la función dada; esta es la principal importancia de declararla con la función. Deje que la Ecuación (5.48) se reescriba como\n",
    "\n",
    "$$ \\ell + \\nu = f(x^0 + \\delta) \\quad \\text{(5.49)} $$\n",
    "\n",
    "donde $\\nu$ es el vector de residuos de observación, $\\ell$ es un vector de observaciones originales, $x^0$ es un vector de valores aproximados de los parámetros, y $\\delta$ es un vector de correcciones a los parámetros aproximados. Al realizar la expansión de la serie de Taylor en la Ecuación (5.49), se obtiene la siguiente forma linealizada del modelo paramétrico:\n",
    "\n",
    "$$ \\nu = f(x^0) + \\frac{\\partial f}{\\partial x} \\delta - \\ell \\quad \\text{(5.50)} $$\n",
    "\n",
    "La Ecuación linealizada (5.50) se puede dar en términos más simples como sigue:\n",
    "\n",
    "$$ \\nu = w + A \\delta \\quad \\text{(5.51)} $$\n",
    "\n",
    "donde $w = f(x^0) - \\ell$ es el vector de cierre y $A = \\frac{\\partial f}{\\partial x}$ es la matriz Jacobiana, también conocida como la primera matriz de diseño. Es importante enfatizar que la Ecuación (5.51) se produce solo con el propósito de facilitar las operaciones adicionales en la Ecuación linealizada (5.50). Las derivadas parciales necesarias para la linealización de las observaciones típicas se dan en el Apéndice D de la siguiente manera: observación de acimut (Sección D.1), observación de estación total (Sección D.2), observación de ángulo horizontal (Sección D.3), observación de distancia (Sección D.4), y observación de ángulo cenital (Sección D.5). Los ejemplos de modelos linealizados se dan como sigue:\n",
    "\n",
    "#### Ejemplo 5.7\n",
    "\n",
    "Linealizar las Ecuaciones (5.20)–(5.23) en el Ejemplo 5.1 y presentarlas en la forma de la Ecuación (5.51).\n",
    "\n",
    "#### Solución:\n",
    "\n",
    "Para las Ecuaciones (5.20)–(5.23), el modelo linealizado se puede dar como la Ecuación (5.51), donde el vector de parámetros es $x = \\left[ \\begin{array}{c} a \\\\ b \\end{array} \\right]$; dado el vector de parámetros aproximados $x^0 = \\left[ \\begin{array}{c} a^0 \\\\ b^0 \\end{array} \\right]$, la primera matriz de diseño (evaluada en $x^0$) se puede dar como\n",
    "\n",
    "$$ A = \\left[ \\begin{array}{cc} \\frac{\\partial E_1}{\\partial a} & \\frac{\\partial E_1}{\\partial b} \\\\ \\frac{\\partial N_1}{\\partial a} & \\frac{\\partial N_1}{\\partial b} \\\\ \\frac{\\partial E_2}{\\partial a} & \\frac{\\partial E_2}{\\partial b} \\\\ \\frac{\\partial N_2}{\\partial a} & \\frac{\\partial N_2}{\\partial b} \\end{array} \\right]^{x^0} = \\left[ \\begin{array}{cc} e_1 & -n_1 \\\\ n_1 & e_1 \\\\ e_2 & -n_2 \\\\ n_2 & e_2 \\end{array} \\right] $$\n",
    "\n",
    "El vector de cierre ($w$) evaluado en $x^0$, el vector de residuos ($\\nu$), y el vector de correcciones a los parámetros aproximados ($\\delta$) se pueden dar, respectivamente, como\n",
    "\n",
    "$$ w = \\left[ \\begin{array}{c} a^0 e_1 - b^0 n_1 - E_1 \\\\ a^0 n_1 + b^0 e_1 - N_1 \\\\ a^0 e_2 - b^0 n_2 - E_2 \\\\ a^0 n_2 + b^0 e_2 - N_2 \\end{array} \\right], \\quad \\nu = \\left[ \\begin{array}{c} \\nu_1 \\\\ \\nu_2 \\\\ \\nu_3 \\\\ \\nu_4 \\end{array} \\right], \\quad \\delta = \\left[ \\begin{array}{c} \\delta a \\\\ \\delta b \\end{array} \\right] $$\n",
    "\n",
    "El modelo linealizado de las Ecuaciones (5.20)–(5.23) (evaluado en $x^0$) se puede dar como\n",
    "\n",
    "$$ \\left[ \\begin{array}{c} \\nu_1 \\\\ \\nu_2 \\\\ \\nu_3 \\\\ \\nu_4 \\end{array} \\right] = \\left[ \\begin{array}{c} a^0 e_1 - b^0 n_1 - E_1 \\\\ a^0 n_1 + b^0 e_1 - N_1 \\\\ a^0 e_2 - b^0 n_2 - E_2 \\\\ a^0 n_2 + b^0 e_2 - N_2 \\end{array} \\right] + \\left[ \\begin{array}{cc} e_1 & -n_1 \\\\ n_1 & e_1 \\\\ e_2 & -n_2 \\\\ n_2 & e_2 \\end{array} \\right] \\left[ \\begin{array}{c} \\delta a \\\\ \\delta b \\end{array} \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5040ebbb-ad45-4246-89fb-77ca2ba1973f",
   "metadata": {},
   "source": [
    "### Ejemplo 5.8\n",
    "\n",
    "Linealizar las Ecuaciones (5.24)–(5.27) en el Ejemplo 5.2 y presentarlas en la forma de la Ecuación (5.51), refiriéndose a las derivadas parciales para la observación de acimut en la Sección D.1, observación de distancia en la Sección D.4, y observación de ángulo horizontal en la Sección D.3.\n",
    "\n",
    "#### Solución:\n",
    "\n",
    "Para las Ecuaciones (5.24)–(5.27), el modelo linealizado se puede dar como la Ecuación (5.51), donde el vector de parámetros es $ p = \\left[ \\begin{array}{c} x \\\\ y \\end{array} \\right] $; dado el vector de parámetros aproximados $ p^0 = \\left[ \\begin{array}{c} x^0 \\\\ y^0 \\end{array} \\right] $, la primera matriz de diseño (evaluada en $ p^0 $) se puede dar como\n",
    "\n",
    "$$ A = \\left[ \\frac{\\partial f}{\\partial x} \\right]_{p^0} = \\left[ \\begin{array}{cc} \\frac{\\partial Az}{\\partial x} & \\frac{\\partial Az}{\\partial y} \\\\ \\frac{\\partial d_1}{\\partial x} & \\frac{\\partial d_1}{\\partial y} \\\\ \\frac{\\partial d_2}{\\partial x} & \\frac{\\partial d_2}{\\partial y} \\\\ \\frac{\\partial \\alpha}{\\partial x} & \\frac{\\partial \\alpha}{\\partial y} \\end{array} \\right]^{p^0} $$\n",
    "\n",
    "donde\n",
    "\n",
    "$$ \\frac{\\partial Az}{\\partial x} \\bigg|_{p^0} = \\frac{y^0 - 1000}{(y^0 - 1000)^2 + (x^0 - 1000)^2} $$\n",
    "\n",
    "$$ \\frac{\\partial Az}{\\partial y} \\bigg|_{p^0} = -\\frac{x^0 - 1000}{(y^0 - 1000)^2 + (x^0 - 1000)^2} $$\n",
    "\n",
    "$$ \\frac{\\partial d_1}{\\partial x} \\bigg|_{p^0} = \\frac{x^0 - 1000}{\\sqrt{(y^0 - 1000)^2 + (x^0 - 1000)^2}} $$\n",
    "\n",
    "$$ \\frac{\\partial d_1}{\\partial y} \\bigg|_{p^0} = \\frac{y^0 - 1000}{\\sqrt{(y^0 - 1000)^2 + (x^0 - 1000)^2}} $$\n",
    "\n",
    "$$ \\frac{\\partial d_2}{\\partial x} \\bigg|_{p^0} = -\\frac{2050 - x^0}{\\sqrt{(800 - y^0)^2 + (2050 - x^0)^2}} $$\n",
    "\n",
    "$$ \\frac{\\partial d_2}{\\partial y} \\bigg|_{p^0} = -\\frac{800 - y^0}{\\sqrt{(800 - y^0)^2 + (2050 - x^0)^2}} $$\n",
    "\n",
    "$$ \\frac{\\partial \\alpha}{\\partial x} \\bigg|_{p^0} = -\\frac{(800 - y^0)(1000 - y^0) + (2050 - x^0)(1000 - x^0)}{(800 - y^0)^2 + (2050 - x^0)^2 - (1000 - y^0)^2 + (1000 - x^0)^2} $$\n",
    "\n",
    "$$ \\frac{\\partial \\alpha}{\\partial y} \\bigg|_{p^0} = \\frac{(2050 - x^0)(1000 - y^0) + (800 - y^0)(1000 - x^0)}{(800 - y^0)^2 + (2050 - x^0)^2 + (1000 - y^0)^2 + (1000 - x^0)^2} $$\n",
    "\n",
    "El vector de cierre ($w$) evaluado en $ p^0 $, el vector de residuos ($\\nu$), y el vector de correcciones a los parámetros aproximados ($\\delta$) se pueden dar, respectivamente, como\n",
    "\n",
    "$$ w = \\left[ \\begin{array}{c} Az^0 - Az \\\\ d_1^0 - d_1 \\\\ d_2^0 - d_2 \\\\ \\alpha^0 - \\alpha \\end{array} \\right], \\quad \\nu = \\left[ \\begin{array}{c} \\nu_1 \\\\ \\nu_2 \\\\ \\nu_3 \\\\ \\nu_4 \\end{array} \\right], \\quad \\delta = \\left[ \\begin{array}{c} \\delta x \\\\ \\delta y \\end{array} \\right] $$\n",
    "\n",
    "donde $[Az^0 \\, d_1^0 \\, d_2^0 \\, \\alpha^0]^T$ es un vector de observaciones derivadas utilizando los valores aproximados de los parámetros en las Ecuaciones (5.24)–(5.27), respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f74ed70-b84e-46b6-8d65-0c891158fa35",
   "metadata": {},
   "source": [
    "### Ejemplo 5.9\n",
    "\n",
    "Linealizar las Ecuaciones (5.28)–(5.32) en el Ejemplo 5.3 de nivelación y presentarlas en la forma de la Ecuación (5.51).\n",
    "\n",
    "#### Solución:\n",
    "\n",
    "Para las Ecuaciones (5.28)–(5.32), el modelo linealizado se puede dar como la Ecuación (5.51), donde el vector de parámetros es $ x = \\left[ H_1 \\, H_2 \\, H_3 \\right]^T $; dado el vector de parámetros aproximados $ x^0 = \\left[ H_1^0 \\, H_2^0 \\, H_3^0 \\right]^T $, la primera matriz de diseño (evaluada en $ x^0 $) se puede dar como\n",
    "\n",
    "$$ A = \\left[ \\frac{\\partial f}{\\partial x} \\right]_{x^0} = \\left[ \\begin{array}{ccc} \\frac{\\partial h_{1B}}{\\partial H_1} & \\frac{\\partial h_{1B}}{\\partial H_2} & \\frac{\\partial h_{1B}}{\\partial H_3} \\\\ \\frac{\\partial h_{13}}{\\partial H_1} & \\frac{\\partial h_{13}}{\\partial H_2} & \\frac{\\partial h_{13}}{\\partial H_3} \\\\ \\frac{\\partial h_{12}}{\\partial H_1} & \\frac{\\partial h_{12}}{\\partial H_2} & \\frac{\\partial h_{12}}{\\partial H_3} \\\\ \\frac{\\partial h_{1A}}{\\partial H_1} & \\frac{\\partial h_{1A}}{\\partial H_2} & \\frac{\\partial h_{1A}}{\\partial H_3} \\\\ \\frac{\\partial h_{32}}{\\partial H_1} & \\frac{\\partial h_{32}}{\\partial H_2} & \\frac{\\partial h_{32}}{\\partial H_3} \\end{array} \\right]_{x^0} = \\left[ \\begin{array}{ccc} -1 & 0 & 0 \\\\ -1 & 0 & 1 \\\\ -1 & 1 & 0 \\\\ -1 & 0 & 0 \\\\ 0 & 1 & -1 \\end{array} \\right] $$\n",
    "\n",
    "El vector de cierre ($w$) evaluado en $ x^0 $, el vector de residuos ($\\nu$), y el vector de correcciones a los parámetros aproximados ($\\delta$) se pueden dar, respectivamente, como\n",
    "\n",
    "$$ w = \\left[ \\begin{array}{c} H_B - H_1^0 - h_{1B} \\\\ H_3^0 - H_1^0 - h_{13} \\\\ H_2^0 - H_1^0 - h_{12} \\\\ H_A - H_1^0 - h_{1A} \\\\ H_2^0 - H_3^0 - h_{32} \\end{array} \\right], \\quad \\nu = \\left[ \\begin{array}{c} \\nu_1 \\\\ \\nu_2 \\\\ \\nu_3 \\\\ \\nu_4 \\\\ \\nu_5 \\end{array} \\right], \\quad \\delta = \\left[ \\begin{array}{c} \\delta H_1 \\\\ \\delta H_2 \\\\ \\delta H_3 \\end{array} \\right] $$\n",
    "\n",
    "El modelo linealizado de las Ecuaciones (5.28)–(5.32) (evaluado en $ x^0 $) se puede dar como\n",
    "\n",
    "$$ \\left[ \\begin{array}{c} \\nu_1 \\\\ \\nu_2 \\\\ \\nu_3 \\\\ \\nu_4 \\\\ \\nu_5 \\end{array} \\right] = \\left[ \\begin{array}{c} H_B - H_1^0 - h_{1B} \\\\ H_3^0 - H_1^0 - h_{13} \\\\ H_2^0 - H_1^0 - h_{12} \\\\ H_A - H_1^0 - h_{1A} \\\\ H_2^0 - H_3^0 - h_{32} \\end{array} \\right] + \\left[ \\begin{array}{ccc} -1 & 0 & 0 \\\\ -1 & 0 & 1 \\\\ -1 & 1 & 0 \\\\ -1 & 0 & 0 \\\\ 0 & 1 & -1 \\end{array} \\right] \\left[ \\begin{array}{c} \\delta H_1 \\\\ \\delta H_2 \\\\ \\delta H_3 \\end{array} \\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad28de-041e-485a-a45e-e16004366def",
   "metadata": {},
   "source": [
    "### 5.4.2 Linealización del Modelo Paramétrico con Parámetro de Molestia\n",
    "\n",
    "Para ilustrar los conceptos de linealización mediante la expansión en serie de Taylor, consideremos un modelo paramétrico dado por\n",
    "\n",
    "$$ \\hat{\\ell} = f(\\hat{x}_1, \\hat{x}_2) \\quad \\text{(5.52)} $$\n",
    "\n",
    "donde $\\hat{\\ell}$ es un vector de observaciones ajustadas, $\\hat{x}_1$ es un vector de coordenadas ajustadas, y $\\hat{x}_2$ es un vector de parámetros de orientación ajustados (o parámetros de molestia). La expansión en serie de Taylor (hasta el primer orden) del modelo se puede dar como sigue:\n",
    "\n",
    "$$ \\hat{\\ell} = f(\\hat{x}_1, \\hat{x}_2) + \\frac{\\partial f}{\\partial x_1} (\\delta_1) + \\frac{\\partial f}{\\partial x_2} (\\delta_2) \\quad \\text{(5.53)} $$\n",
    "\n",
    "donde la Ecuación (5.53) es la forma lineal aproximada de la función dada $f(\\hat{x}_1, \\hat{x}_2)$ o $\\hat{\\ell}$ en la Ecuación (5.52); $f(\\hat{x}_1, \\hat{x}_2)$, el término de orden cero de la serie de Taylor, es la función original evaluada en los valores numéricos iniciales dados de las coordenadas ($\\hat{x}_1$) y los parámetros de orientación ($\\hat{x}_2$); $\\delta_1$ es un vector de correcciones que se aplicará a los valores iniciales de las coordenadas ($\\hat{x}_1$); $\\delta_2$ es un vector de correcciones que se aplicará a los valores iniciales de los parámetros de orientación ($\\hat{x}_2$); $\\frac{\\partial f}{\\partial x_1}$ es una matriz Jacobiana que contiene las derivadas parciales con respecto a las coordenadas; y $\\frac{\\partial f}{\\partial x_2}$ es una matriz Jacobiana de las derivadas parciales con respecto a los parámetros de orientación.\n",
    "\n",
    "Una observación típica del levantamiento que se representa en la forma de la Ecuación (5.52) es la observación de dirección de estación total ($d_{ij}$) desde la estación $i$ hasta $j$, reducida al sistema de coordenadas de proyección del mapa. Esta observación se expresa en forma matemática explícita en la Sección 5.1.2 como\n",
    "\n",
    "$$ \\hat{d}_{ij} = \\text{atan} \\left( \\frac{\\hat{y}_j - \\hat{y}_i}{\\hat{x}_j - \\hat{x}_i} \\right) - \\hat{\\gamma}_i \\quad \\text{(5.54)} $$\n",
    "\n",
    "donde $\\hat{\\gamma}_i$ es el parámetro de orientación ajustado en la estación $i$ y ($\\hat{x}_i, \\hat{y}_i$) y ($\\hat{x}_j, \\hat{y}_j$) son las coordenadas horizontales ajustadas de los puntos $i$ y $j$, respectivamente. Relacionando la Ecuación (5.52) con la Ecuación (5.54),\n",
    "\n",
    "$$ \\hat{\\ell} = \\hat{d}_{ij} $$\n",
    "\n",
    "$$ \\hat{x}_1 = (\\hat{x}_i, \\hat{y}_i, \\hat{x}_j, \\hat{y}_j)^T $$\n",
    "\n",
    "$$ \\hat{x}_2 = \\hat{\\gamma}_i $$\n",
    "\n",
    "$$ f(\\hat{x}_1, \\hat{x}_2) = \\text{atan} \\left( \\frac{\\hat{y}_j - \\hat{y}_i}{\\hat{x}_j - \\hat{x}_i} \\right) - \\hat{\\gamma}_i $$\n",
    "\n",
    "La expansión en serie de Taylor de la Ecuación (5.54) con respecto a la Ecuación (5.53) será\n",
    "\n",
    "$$ \\hat{d}_{ij} = \\text{atan} \\left( \\frac{y_j^0 - y_i^0}{x_j^0 - x_i^0} \\right) - \\gamma_i^0 + A_1 \\left[ \\begin{array}{c} \\delta x_i \\\\ \\delta y_i \\\\ \\delta x_j \\\\ \\delta y_j \\end{array} \\right] + A_2 [\\delta \\gamma_i] \\quad \\text{(5.55)} $$\n",
    "\n",
    "donde\n",
    "\n",
    "$$ f(\\hat{x}_1, \\hat{x}_2) = \\text{atan} \\left( \\frac{y_j^0 - y_i^0}{x_j^0 - x_i^0} \\right) - \\gamma_i^0 $$ correspondiente al orden cero de la expansión de Taylor evaluado en el vector de valores aproximados de los parámetros,\n",
    "\n",
    "$$ x^0 = \\left( x_i^0, y_i^0, x_j^0, y_j^0, \\gamma_i^0 \\right)^T, \\quad A_1 = \\left[ \\frac{\\partial f}{\\partial x_1} \\right]_{x^0} = \\left[ \\begin{array}{cccc} \\frac{\\partial \\hat{d}_{ij}}{\\partial x_i} & \\frac{\\partial \\hat{d}_{ij}}{\\partial y_i} & \\frac{\\partial \\hat{d}_{ij}}{\\partial x_j} & \\frac{\\partial \\hat{d}_{ij}}{\\partial y_j} \\end{array} \\right]_{x^0}, \\quad A_2 = \\left[ \\frac{\\partial f}{\\partial x_2} \\right]_{x^0} = \\left[ \\frac{\\partial \\hat{d}_{ij}}{\\partial \\gamma_i} \\right]_{x^0} $$\n",
    "\n",
    "y $\\delta_1 = \\left[ \\delta x_i, \\delta y_i, \\delta x_j, \\delta y_j \\right]^T, \\quad \\delta_2 = \\left[ \\delta \\gamma_i \\right];$ las matrices Jacobianas $A_1$ y $A_2$ se conocen con respecto al ajuste paramétrico de mínimos cuadrados como las primeras matrices de diseño. Los elementos de las matrices $A_1$ y $A_2$ se dan en la Sección D.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7c010-5218-46b0-89b0-0cfa0dfbf8f5",
   "metadata": {},
   "source": [
    "### 5.5 Derivación de la Función de Variación\n",
    "\n",
    "Se pueden seguir dos enfoques para derivar la función de variación a partir del modelo paramétrico linealizado dado en la Ecuación (5.51): el enfoque directo y el enfoque lagrangiano. El enfoque lagrangiano parece ser más flexible al resolver \"problemas relacionados con el mínimo\", como en el criterio de mínimos cuadrados. Sin embargo, la elección de cualquiera de los dos enfoques es una cuestión de conveniencia, ya que ambos terminan produciendo el mismo vector de solución.\n",
    "\n",
    "### 5.5.1 Derivación de la Función de Variación Usando el Enfoque Directo\n",
    "\n",
    "La función de variación es la forma cuadrática del modelo paramétrico linealizado dado en la Ecuación (5.51), excepto que ahora está \"correlacionada\" con el criterio de mínimos cuadrados. En la Ecuación (5.48), la matriz de peso $P$ está claramente asociada con el modelo dado, lo que significa que $P$ debe utilizarse explícitamente en la función de variación. La función de variación basada en la Ecuación (5.51) se deriva utilizando el enfoque directo como sigue. El criterio de mínimos cuadrados para este tipo de problema (refiriéndose a la Sección 4.2.1) se puede dar como\n",
    "\n",
    "$$ \\nu^T P \\nu = \\text{mínimo} \\quad \\text{(5.56)} $$\n",
    "\n",
    "La función de variación ($\\varphi$) en la Ecuación (5.57) se obtiene imponiendo el criterio de mínimos cuadrados (Ecuación (5.56)) en el modelo linealizado (5.51). Esto se hace sustituyendo el modelo linealizado directamente en el criterio de mínimos cuadrados como sigue:\n",
    "\n",
    "$$ \\varphi = \\nu^T P \\nu = (A \\delta + w)^T P (A \\delta + w) = \\text{mínimo} \\quad \\text{(5.57)} $$\n",
    "\n",
    "En forma expandida, la función de variación (Ecuación (5.57)) se puede dar como\n",
    "\n",
    "$$ \\varphi = \\delta^T A^T P A \\delta + \\delta^T A^T P w + w^T P A \\delta + w^T P w = \\text{mínimo} \\quad \\text{(5.58)} $$\n",
    "\n",
    "Siguiendo las reglas de las operaciones básicas de matrices en la Sección 1.6.3, se puede mostrar que $ (A \\delta + w)^T = \\delta^T A^T + w^T $ (notando que $A$ y $\\delta$ ahora se han intercambiado). Si se proporciona la matriz de covarianza de las observaciones ($C_\\ell$) en la Ecuación (5.48) en lugar de la matriz de peso dada $P$, la Ecuación (5.48) se modificará para parecerse al siguiente modelo:\n",
    "\n",
    "$$ \\hat{\\ell} = f(\\hat{x}) \\, C_\\ell \\quad \\text{(5.59)} $$\n",
    "\n",
    "donde $P$ ahora se reemplaza con la matriz de covarianza de las observaciones $C_\\ell$, que ahora está claramente asociada con el modelo dado. Esto significa que $C_\\ell$ debe utilizarse explícitamente en el criterio de mínimos cuadrados y la función de variación. Al sustituir $P = \\sigma_0^2 C_\\ell^{-1}$ (y estableciendo el factor de varianza a priori de peso unitario, $\\sigma_0^2 = 1$) en las Ecuaciones (5.56) y (5.58), los correspondientes criterios de mínimos cuadrados y la función de variación se obtienen como las Ecuaciones (5.60) y (5.61), respectivamente:\n",
    "\n",
    "$$ \\nu^T C_\\ell^{-1} \\nu = \\text{mínimo} \\quad \\text{(5.60)} $$\n",
    "\n",
    "$$ \\varphi = \\delta^T A^T C_\\ell^{-1} A \\delta + 2 \\delta^T A^T C_\\ell^{-1} w + w^T C_\\ell^{-1} w = \\text{mínimo} \\quad \\text{(5.61)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df306e58-ab9c-4e38-8335-b69e1f7872e0",
   "metadata": {},
   "source": [
    "### 5.5.2 Derivación de la Función de Variación Usando el Enfoque de Lagrange\n",
    "\n",
    "La función de variación basada en la Ecuación (5.51) asociada con el modelo en la Ecuación (5.48) y el criterio de mínimos cuadrados en la Ecuación (5.56) se deriva de la siguiente manera usando el enfoque de Lagrange. El enfoque de Lagrange es más flexible que el enfoque directo, especialmente cuando el criterio de mínimos cuadrados debe imponerse en muchos modelos linealizados; en este caso, todo lo que se necesita hacer es multiplicar cada modelo linealizado por un multiplicador de Lagrange diferente (k) y restar cada producto de (o añadir cada producto a) la función de criterio para producir una función de variación. Imponer el criterio de mínimos cuadrados (Ecuación (5.56)) en el modelo linealizado (Ecuación (5.51)) usando un vector de multiplicadores de Lagrange k (también conocido como un vector de correlatos) da la función de variación por el enfoque de Lagrange de la siguiente manera:\n",
    "\n",
    "$$ \\varphi = v^T P v - 2k^T (A\\delta + w - v) = \\text{mínimo} \\quad (5.62) $$\n",
    "\n",
    "Si la función de variación se basa en la Ecuación (5.51) asociada con el modelo en la Ecuación (5.59) y el criterio de mínimos cuadrados en la Ecuación (5.60), se obtendrá lo siguiente:\n",
    "\n",
    "$$ \\varphi = v^T C_t^{-1} v - 2k^T (A\\delta + w - v) = \\text{mínimo} \\quad (5.63) $$\n",
    "\n",
    "Las Ecuaciones (5.62) y (5.63) son las funciones de variación basadas en el enfoque de Lagrange. Como se puede ver en las dos ecuaciones, la única diferencia es el uso de P en la Ecuación (5.62) y $ C_t^{-1} d$ en la Ecuación (5.63).\n",
    "\n",
    "### 5.6 Derivación del Sistema de Ecuaciones Normales\n",
    "\n",
    "El sistema de ecuaciones normales de mínimos cuadrados se deriva de la función de variación expandida dada en la Ecuación (5.58) o en la Ecuación (5.61) dependiendo de si $ C_t d$ o P se dan en el caso del enfoque directo o la Ecuación (5.62) o la Ecuación (5.63) dependiendo de si $ C_t d$ o P se dan en el caso del enfoque de Lagrange. Las derivadas parciales de la función de variación deben encontrarse y establecerse igual a cero de la siguiente manera para obtener el sistema de ecuaciones normales.\n",
    "\n",
    "### 5.6.1 Ecuaciones Normales Basadas en la Función de Variación del Enfoque Directo\n",
    "\n",
    "El sistema de ecuaciones normales se puede derivar de las funciones de variación obtenidas basadas en el enfoque directo, de la siguiente manera. Por ejemplo, considerar la función de variación en la Ecuación (5.58), encontrar sus derivadas parciales (refiriéndose a las Ecuaciones (1.43)–(1.50)) con respecto a lo desconocido en la función (es decir, $ \\delta d$), y establecer la ecuación resultante a cero de la siguiente manera:\n",
    "\n",
    "$$ \\frac{\\partial \\varphi}{\\partial \\delta} = 2 \\delta^T A^T PA + 2w^T PA = 0 \\quad (5.64) $$\n",
    "\n",
    "Con respecto a las derivadas parciales hechas en la Ecuación (5.58) que conducen al resultado en la Ecuación (5.64), se deben tener en cuenta las siguientes reglas de matrices, que se pueden confirmar a partir de libros básicos de álgebra matricial:\n",
    "\n",
    "- Las derivadas parciales de $ \\delta^T A^T PA \\delta d$ con respecto a $ \\delta d$ dan $ 2 \\delta^T A^T PA d$ (ya que hay dos $ \\delta d$ involucradas en el término, siendo una la transpuesta de la otra).\n",
    "- Los dos términos $ \\delta^T A^T Pw + w^T PA \\delta d$ darán los mismos valores numéricos si se usan los mismos números en los vectores y matrices involucrados; sumarán hasta $ 2w^T PA d$ o $ 2 \\delta^T A^T Pw d$ ya que $ w^T PA \\delta = \\delta^T A^T Pw d$. Para mayor comodidad, se considera la derivada parcial de $ 2w^T PA \\delta d$ con respecto a $ \\delta d$, dando $ 2w^T PA d$.\n",
    "\n",
    "El sistema de ecuaciones normales de mínimos cuadrados se obtiene reorganizando la Ecuación (5.64) de la siguiente manera (dividiendo la ecuación por 2 y luego transponiéndola):\n",
    "\n",
    "$$ (A^T PA) \\delta + A^T Pw = 0 \\quad (5.65) $$\n",
    "\n",
    "Si la función de variación en la Ecuación (5.61) se usa en las derivadas parciales en la Ecuación (5.64), se obtendrá el siguiente sistema de ecuaciones normales:\n",
    "\n",
    "$$ (A^T C_t^{-1} A) \\delta + A^T C_t^{-1} w = 0 \\quad (5.66) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36198a3e-352f-483c-a5f1-d8c0aad2ba67",
   "metadata": {},
   "source": [
    "### 5.6.2 Ecuaciones Normales Basadas en la Función de Variación del Enfoque de Lagrange\n",
    "\n",
    "El sistema de ecuaciones normales de mínimos cuadrados se puede derivar de las funciones de variación obtenidas basadas en el enfoque de Lagrange en la Sección 5.5.2 de la siguiente manera. Por ejemplo, al encontrar las derivadas parciales de la función de variación en la Ecuación (5.63) con respecto a lo desconocido en la función (es decir, $ v $, $ \\delta $ y $ k $), se obtienen las siguientes (refiriéndose a las Ecuaciones (1.43)–(1.50) para las derivadas parciales de matrices):\n",
    "\n",
    "$$ \\frac{\\partial \\varphi}{\\partial v} = 2v^T C_t^{-1} + 2k^T = 0 \\quad (5.67) $$\n",
    "\n",
    "$$ \\frac{\\partial \\varphi}{\\partial \\delta} = -2k^T A = 0 \\quad (5.68) $$\n",
    "\n",
    "$$ \\frac{\\partial \\varphi}{\\partial k^T} = 2(A\\delta + w - v) = 0 \\quad (5.69) $$\n",
    "\n",
    "Las Ecuaciones (5.67)–(5.69) pueden reescribirse (dividiendo por 2 o -2) como sigue:\n",
    "\n",
    "$$ v^T C_t^{-1} + k^T = 0 \\quad (5.70) $$\n",
    "\n",
    "$$ k^T A = 0 \\quad (5.71) $$\n",
    "\n",
    "$$ A\\delta + w - v = 0 \\quad (5.72) $$\n",
    "\n",
    "Las Ecuaciones (5.70)–(5.72) son el sistema de ecuaciones normales de mínimos cuadrados (en la forma más expandida) basado en el enfoque de Lagrange. Si la función de variación en la Ecuación (5.62) se usa en las derivadas parciales en las Ecuaciones (5.67)–(5.69), la única diferencia en el sistema de ecuaciones normales será que $ C_t^{-1} $ se cambia a P en la Ecuación (5.70).\n",
    "\n",
    "### 5.7 Derivación de la Solución Paramétrica de Mínimos Cuadrados\n",
    "\n",
    "La solución de mínimos cuadrados se puede derivar del sistema de ecuaciones normales dado en la Sección 5.6.1 en el caso del enfoque directo o en la Sección 5.6.2 en el caso del enfoque de Lagrange.\n",
    "\n",
    "### 5.7.1 Solución de Mínimos Cuadrados Basada en las Ecuaciones Normales del Enfoque Directo\n",
    "\n",
    "La solución de mínimos cuadrados se puede derivar del sistema de ecuaciones normales dado en la Ecuación (5.65) resolviendo directamente lo desconocido ($ \\delta $) de la siguiente manera:\n",
    "\n",
    "$$ \\delta = -(A^T PA)^{-1} A^T Pw \\quad (5.73) $$\n",
    "\n",
    "o de la Ecuación (5.66), dando\n",
    "\n",
    "$$ \\delta = -(A^T C_t^{-1} A)^{-1} A^T C_t^{-1} w \\quad (5.74) $$\n",
    "\n",
    "Las Ecuaciones (5.73) y (5.74) son los vectores de solución para las correcciones desconocidas que se aplicarán a los valores aproximados de los parámetros ($ x^0 $). Los parámetros ajustados ($ \\hat{x} $) se pueden dar como\n",
    "\n",
    "$$ \\hat{x} = x^0 + \\delta \\quad (5.75) $$\n",
    "\n",
    "Del modelo paramétrico linealizado Ecuación (5.51), el vector de residuos de la observación ($ v $) se puede obtener como\n",
    "\n",
    "$$ v = w + A\\delta \\quad (5.76) $$\n",
    "\n",
    "con las observaciones ajustadas dadas como sigue:\n",
    "\n",
    "$$ \\hat{\\ell} = \\ell + v \\quad (5.77) $$\n",
    "\n",
    "Generalmente, el método de mínimos cuadrados oculta errores al minimizar las correcciones (residuos) a las observaciones al distribuir los errores alrededor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c37bb-b1d2-4d73-9684-8d7fca1ba1e7",
   "metadata": {},
   "source": [
    "### 5.7.2 Solución de Mínimos Cuadrados Basada en las Ecuaciones Normales del Enfoque de Lagrange\n",
    "\n",
    "La solución de mínimos cuadrados también se puede derivar resolviendo simultáneamente para $ \\delta $ del sistema de ecuaciones normales del enfoque de Lagrange en las Ecuaciones (5.70)–(5.72). Al post-multiplicar la Ecuación (5.70) por la matriz A y estableciendo $ k^T A = 0 $ según la Ecuación (5.71), se obtiene lo siguiente:\n",
    "\n",
    "$$ v^T C_t^{-1} A = 0 \\quad (5.78) $$\n",
    "\n",
    "Transponiendo la Ecuación (5.78) da\n",
    "\n",
    "$$ A^T C_t^{-1} v = 0 \\quad (5.79) $$\n",
    "\n",
    "Sustituyendo $ v $ de la Ecuación (5.72) en la Ecuación (5.79) da lo siguiente:\n",
    "\n",
    "$$ A^T C_t^{-1} A\\delta + A^T C_t^{-1} w = 0 \\quad (5.80) $$\n",
    "\n",
    "La Ecuación (5.80) es el sistema de ecuaciones normales (en forma condensada) basado en el enfoque de Lagrange. La solución de la Ecuación (5.80) da\n",
    "\n",
    "$$ \\delta = - (A^T C_t^{-1} A)^{-1} A^T C_t^{-1} w \\quad (5.81) $$\n",
    "\n",
    "Sustituyendo $ P = C_t^{-1} $ en la Ecuación (5.81) da\n",
    "\n",
    "$$ \\delta = - (A^T P A)^{-1} A^T P w \\quad (5.82) $$\n",
    "\n",
    "Las Ecuaciones (5.81) y (5.82) son los vectores de solución para las correcciones desconocidas que se aplicarán a los valores aproximados de los parámetros ($ x^0 $). Estas ecuaciones son las mismas que las derivadas del enfoque directo en las Ecuaciones (5.73) y (5.74). Esto quiere decir que los resultados finales son los mismos, sea cual sea el enfoque utilizado. En resumen, las ecuaciones útiles en las derivaciones anteriores para el procedimiento de ajuste de mínimos cuadrados paramétricos se pueden dar como sigue:\n",
    "\n",
    "$$ \\delta = - (A^T P A)^{-1} A^T P w \\quad (5.83) $$\n",
    "\n",
    "o\n",
    "\n",
    "$$ \\delta = - N^{-1} u \\quad (5.84) $$\n",
    "\n",
    "$$ N = A^T P A \\quad (5.85) $$\n",
    "\n",
    "$$ u = A^T P w \\quad (5.86) $$\n",
    "\n",
    "$$ A = \\frac{\\partial f}{\\partial x} \\quad (5.87) $$\n",
    "\n",
    "$$ w = f(x^0) - \\ell \\quad (5.88) $$\n",
    "\n",
    "$$ \\hat{x} = x^0 + \\delta \\quad (5.89) $$\n",
    "\n",
    "$$ \\hat{\\ell} = \\ell + v \\quad (5.90) $$\n",
    "\n",
    "$$ v = w + A\\delta \\quad (5.91) $$\n",
    "\n",
    "donde $ \\delta $ es el vector de correcciones al vector de parámetros aproximados $ x^0 $, $ N $ generalmente se refiere como la matriz de los coeficientes de las ecuaciones normales, $ A $ es la primera matriz de diseño, $ w $ es el vector de cierres, $ \\hat{x} $ es el vector de parámetros ajustados, $ \\hat{\\ell} $ es el vector de observaciones ajustadas, $ v $ es el vector de residuos o correcciones que se aplicarán a las observaciones originales $ \\ell $, y $ P $ es la matriz de pesos de las observaciones $ \\ell $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1da140-6d6c-4618-9ef9-302e1ea81fca",
   "metadata": {},
   "source": [
    "### 5.8 Modelos Estocásticos de Ajuste Paramétrico\n",
    "\n",
    "La relación entre la matriz de varianza-covarianza ($C_{\\ell}$) de algún vector de observación $\\ell$ y la matriz cofactor ($Q_{\\ell}$) del vector de observación se puede dar como\n",
    "\n",
    "$$ C_t = \\sigma_0^2 Q_{\\ell} \\quad (5.92) $$\n",
    "\n",
    "donde $\\sigma_0^2$ es un factor de varianza a priori de peso unitario (que siempre se toma como la varianza poblacional general con un valor de 1). Dado que $\\sigma_0^2 = 1$ en la Ecuación (5.92), entonces, al comienzo del ajuste de mínimos cuadrados, se asume que la matriz de varianza-covarianza de las observaciones es la misma que la matriz cofactor de las observaciones. Con esta suposición, la matriz de pesos ($P$) de las observaciones se toma como el inverso de la matriz de varianza-covarianza de las observaciones, dada como sigue:\n",
    "\n",
    "$$ P = C_t^{-1} = Q_{\\ell}^{-1} \\quad (5.93) $$\n",
    "\n",
    "Dado que las observaciones $\\ell$ y su matriz de varianza-covarianza $C_{\\ell}$ se utilizan para calcular las cantidades desconocidas, como los parámetros ajustados ($\\hat{x}$), las observaciones ajustadas ($\\hat{\\ell}$) y los residuos de las observaciones ($v$), es obvio que los errores en esas observaciones se propagarán a estas cantidades también. Los conceptos de propagación de la varianza-covarianza (Capítulo 2) se usarán como sigue para derivar la matriz cofactor de los parámetros ajustados ($Q_{\\hat{x}}$), la matriz cofactor de la observación ajustada ($Q_{\\hat{\\ell}}$) y la matriz cofactor de los residuos de la observación ($Q_v$).\n",
    "\n",
    "### 5.8.1 Derivación de la Matriz Cofactor de los Parámetros Ajustados\n",
    "\n",
    "El vector de los parámetros ajustados de mínimos cuadrados se puede dar a partir de las Ecuaciones (5.83), (5.88) y (5.89) como\n",
    "\n",
    "$$ \\hat{x} = x^0 - (A^T PA)^{-1} A^T P [f(x^0) - \\ell] \\quad (5.94) $$\n",
    "\n",
    "La Ecuación (5.94) es una forma de $\\hat{x} = f(\\ell)$ con la matriz cofactor propagada usual (basada en las reglas de propagación de la varianza-covarianza) dada como\n",
    "\n",
    "$$ Q_{\\hat{x}} = J Q_{\\ell} J^T \\quad (5.95) $$\n",
    "\n",
    "donde $Q_{\\ell}$ es la matriz cofactor de las observaciones y $J$ es la matriz Jacobiana dada como sigue:\n",
    "\n",
    "$$ J = \\frac{\\partial \\hat{x}}{\\partial \\ell} = (A^T PA)^{-1} A^T P \\quad (5.96) $$\n",
    "\n",
    "teniendo en cuenta que las derivadas parciales con respecto a $\\ell$ de todos los demás términos (excepto $\\ell$) serán cero. Sustituyendo la Ecuación (5.96) en la Ecuación (5.95) se obtiene lo siguiente:\n",
    "\n",
    "$$ Q_{\\hat{x}} = (A^T PA)^{-1} A^T P Q_{\\ell} P A (A^T PA)^{-1} \\quad (5.97) $$\n",
    "\n",
    "Dado que, por definición, $P = Q_{\\ell}^{-1}$, entonces $PQ_{\\ell} = I$ (una matriz identidad con todos los elementos diagonales principales como uno y todos los elementos restantes como cero), de modo que la Ecuación (5.97) se puede dar como\n",
    "\n",
    "$$ Q_{\\hat{x}} = (A^T PA)^{-1} (A^T PA) (A^T PA)^{-1} \\quad (5.98) $$\n",
    "\n",
    "De manera similar, $(A^T PA)(A^T PA)^{-1} = I$, de modo que la Ecuación (5.98) se puede reducir aún más a lo siguiente:\n",
    "\n",
    "$$ Q_{\\hat{x}} = (A^T PA)^{-1} \\quad (5.99) $$\n",
    "\n",
    "La Ecuación (5.99) es la matriz cofactor de los parámetros ajustados ($\\hat{x}$); esta matriz se puede deducir directamente, por inspección, del vector de solución de mínimos cuadrados paramétrico dado en la Ecuación (5.83)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a7e588-6e9e-4e05-a1fe-6f90f3e43174",
   "metadata": {},
   "source": [
    "### 5.8.2 Derivación de la Matriz Cofactor de las Observaciones Ajustadas\n",
    "\n",
    "El vector de observaciones ajustadas de mínimos cuadrados se puede obtener de las Ecuaciones (5.88), (5.90) y (5.91) como\n",
    "\n",
    "$$ \\hat{\\ell} = \\ell + A\\delta + f(x^0) - \\ell \\quad (5.100) $$\n",
    "\n",
    "A partir de las Ecuaciones (5.83), (5.88) y (5.100), se obtiene la siguiente ecuación:\n",
    "\n",
    "$$ \\hat{\\ell} = -A(A^T PA)^{-1} A^T P [f(x^0) - \\ell] + f(x^0) \\quad (5.101) $$\n",
    "\n",
    "La Ecuación (5.101) es una forma de $\\hat{\\ell} = f(\\ell)$ con la matriz cofactor propagada usual (basada en las reglas de propagación de la varianza-covarianza) dada como\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = J Q_{\\ell} J^T \\quad (5.102) $$\n",
    "\n",
    "donde $Q_{\\ell}$ es la matriz cofactor de las observaciones y $J$ es la matriz Jacobiana dada como sigue:\n",
    "\n",
    "$$ J = \\frac{\\partial \\hat{\\ell}}{\\partial \\ell} = A(A^T PA)^{-1} A^T P \\quad (5.103) $$\n",
    "\n",
    "teniendo en cuenta que las derivadas parciales con respecto a $\\ell$ de todos los demás términos (excepto $\\ell$) serán cero. Sustituyendo la Ecuación (5.103) en la Ecuación (5.102) se obtiene lo siguiente:\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = A(A^T PA)^{-1} A^T P Q_{\\ell} P A (A^T PA)^{-1} A^T \\quad (5.104) $$\n",
    "\n",
    "De manera similar, en la Ecuación (5.104), $PQ_{\\ell} = I$, de modo que la Ecuación (5.104) se puede dar como\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = A(A^T PA)^{-1} (A^T PA) (A^T PA)^{-1} A^T \\quad (5.105) $$\n",
    "\n",
    "De manera similar, $(A^T PA)(A^T PA)^{-1} = I$, de modo que la Ecuación (5.105) se puede reducir aún más a lo siguiente:\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = A(A^T PA)^{-1} A^T \\quad (5.106) $$\n",
    "\n",
    "La Ecuación (5.106) es la matriz cofactor de las observaciones ajustadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690df29f-276d-4426-90e0-45ef6d24498a",
   "metadata": {},
   "source": [
    "### 5.8.3 Derivación de la Matriz Cofactor de los Residuos de la Observación\n",
    "\n",
    "El vector de residuos de la observación se puede obtener de las Ecuaciones (5.83), (5.88) y (5.91) como\n",
    "\n",
    "$$ v = -A(A^T PA)^{-1} A^T P [f(x^0) - \\ell] + f(x^0) - \\ell \\quad (5.107) $$\n",
    "\n",
    "La Ecuación (5.107) es una forma de $ v = f(\\ell) $ con la matriz cofactor propagada usual (basada en las reglas de propagación de la varianza-covarianza) dada como\n",
    "\n",
    "$$ Q_v = J Q_{\\ell} J^T \\quad (5.108) $$\n",
    "\n",
    "donde $ Q_{\\ell} $ es la matriz cofactor de las observaciones y $ J $ es la matriz Jacobiana dada como sigue:\n",
    "\n",
    "$$ J = \\frac{\\partial v}{\\partial \\ell} = A(A^T PA)^{-1} A^T P - I \\quad (5.109) $$\n",
    "\n",
    "teniendo en cuenta que la derivada parcial con respecto a $\\ell$ del último término en la Ecuación (5.107) es una matriz identidad $ I $ ya que $\\ell$ es una cantidad vectorial. Sustituyendo la Ecuación (5.109) en la Ecuación (5.108) se obtiene lo siguiente:\n",
    "\n",
    "$$ Q_v = \\left[A(A^T PA)^{-1} - I\\right] Q_{\\ell} \\left[PA(A^T PA)^{-1} A^T - I\\right] \\quad (5.110) $$\n",
    "\n",
    "La Ecuación (5.110) en forma expandida se puede dar como\n",
    "\n",
    "$$ Q_v = A(A^T PA)^{-1} A^T PQ_{\\ell} PA(A^T PA)^{-1} A^T - A(A^T PA)^{-1} A^T PQ_{\\ell} PA(A^T PA)^{-1} A^T - Q_{\\ell} PA(A^T PA)^{-1} A^T + Q_{\\ell} \\quad (5.111) $$\n",
    "\n",
    "Tomando $ PQ_{\\ell} = I $ y $ Q_{\\ell} P = I $ en la Ecuación (5.111) reduce la ecuación a lo siguiente:\n",
    "\n",
    "$$ Q_v = A(A^T PA)^{-1} (A^T PA)(A^T PA)^{-1} A^T - A(A^T PA)^{-1} A^T - Q_{\\ell} PA(A^T PA)^{-1} A^T + Q_{\\ell} \\quad (5.112) $$\n",
    "\n",
    "Tomando $(A^T PA)(A^T PA)^{-1} = I$ y simplificando aún más la Ecuación (5.112) se obtiene lo siguiente:\n",
    "\n",
    "$$ Q_v = A(A^T PA)^{-1} A^T - A(A^T PA)^{-1} A^T - A(A^T PA)^{-1} A^T + Q_{\\ell} \\quad (5.113) $$\n",
    "\n",
    "lo cual se simplifica aún más a\n",
    "\n",
    "$$ Q_v = Q_{\\ell} - A(A^T PA)^{-1} A^T \\quad (5.114) $$\n",
    "\n",
    "La Ecuación (5.113) es la matriz cofactor de los residuos de la observación ($v$). Las matrices de varianza-covarianza de las cantidades ajustadas se pueden obtener de las Ecuaciones (5.99), (5.106) y (5.114), respectivamente, de la siguiente manera:\n",
    "\n",
    "$$ C_{\\hat{x}} = \\sigma_0^2 (A^T PA)^{-1} \\quad (5.115) $$\n",
    "\n",
    "$$ C_{\\hat{\\ell}} = \\sigma_0^2 \\left[A(A^T PA)^{-1} A^T\\right] \\quad (5.116) $$\n",
    "\n",
    "$$ C_v = \\sigma_0^2 Q_{\\ell} - \\sigma_0^2 \\left[A(A^T PA)^{-1} A^T\\right] \\quad (5.117) $$\n",
    "\n",
    "donde $C_{\\hat{x}}$ es la matriz de covarianza de los parámetros ajustados, $C_{\\hat{\\ell}}$ es la matriz de covarianza de las observaciones ajustadas, $C_v$ es la matriz de covarianza de los residuos de la observación, y $\\sigma_0^2$ es el factor de varianza a posteriori (APVF) de peso unitario, que se calcula después del ajuste de mínimos cuadrados de la siguiente manera:\n",
    "\n",
    "$$ \\sigma_0^2 = \\frac{v^T Pv}{n - u} \\quad (5.118) $$\n",
    "\n",
    "donde la redundancia se expresa como $ n - u $, $ n $ es el número de ecuaciones paramétricas, $ u $ es el número de parámetros desconocidos (que no debe confundirse con el símbolo similar usado en las Ecuaciones (5.84) y (5.86) como $ u = A^T Pw $), $ v $ es el vector de residuos de observación y $ P $ es la matriz de pesos de las observaciones. En la Ecuación (5.117), se puede ver que $ \\sigma_0^2 $ se usa para escalar la matriz cofactor ($ Q_\\ell $) de las observaciones originales para dar una matriz de covarianza más aceptable de las observaciones; esta es una forma de calibrar indirectamente el instrumento utilizado en la toma de las mediciones. El APVF ($ \\sigma_0^2 $) es un indicador (para toda la red) en cuanto a la consistencia de la red ajustada basada en los errores predichos a priori. Los errores predichos están representados por las desviaciones estándar de las observaciones. Si en promedio, cada observación se ajusta por una cantidad mayor que su error predicho, el APVF tenderá a ser mayor que 1; si en promedio, cada observación se ajusta por una cantidad menor que su error predicho, el APVF tenderá a ser menor que 1. En cualquier caso, uno puede no estar estimando correctamente la calidad de sus mediciones o puede tener algunas mediciones malas en la encuesta (especialmente aquellas mediciones que reciben un gran ajuste). Debe recordarse que si el factor de varianza a priori $ \\sigma_0^2 $ es bien conocido, debe usarse en las Ecuaciones (5.115)–(5.117); cuando se desconoce su valor, se establecería en 1 antes del ajuste para determinar la matriz de pesos ($ P $) de las observaciones. A partir de las Ecuaciones (5.115) a (5.117), se puede ver que la matriz cofactor de los parámetros ajustados ($ Q_{\\hat{x}} $) es la misma que $ N^{-1} $ con la matriz cofactor de las observaciones no ajustadas ($ Q_\\ell $) dada como $ P^{-1} $. A partir de las Ecuaciones (5.116) y (5.117), la matriz de covarianza de los residuos de la observación se puede reescribir como\n",
    "\n",
    "$$ C_v = \\hat{C}_\\ell - C_{\\hat{\\ell}} \\quad (5.119) $$\n",
    "\n",
    "donde $ C_{\\hat{\\ell}} $ (dada en la Ecuación (5.116)) es la matriz de covarianza de las observaciones ajustadas, que no debe confundirse con la matriz de covarianza escalada de las observaciones ($ \\hat{C}_\\ell $) de las observaciones originales $\\ell$, expresada como\n",
    "\n",
    "$$ \\hat{C}_\\ell = \\sigma_0^2 Q_\\ell \\quad (5.120) $$\n",
    "\n",
    "La Ecuación (5.120) tampoco debe confundirse con $ C_t = \\sigma_0^2 Q_\\ell $ (con $ \\sigma_0^2 = 1 $), que es la matriz de covarianza no escalada de las observaciones originales, comúnmente utilizada al comienzo de un ajuste de mínimos cuadrados. En realidad, la Ecuación (5.120) y $ C_t = \\sigma_0^2 Q_\\ell $ serán idénticas si $ \\sigma_0^2 = \\sigma_0^2 $. Al reorganizar la Ecuación (5.119), se obtiene lo siguiente:\n",
    "\n",
    "$$ C_{\\hat{\\ell}} = \\hat{C}_\\ell - C_v \\quad (5.121) $$\n",
    "\n",
    "Al interpretar la Ecuación (5.121), se puede entender que la matriz de covarianza de la observación ajustada ($ C_{\\hat{\\ell}} $) siempre es menor que la matriz de covarianza escalada de las observaciones originales ($ \\hat{C}_\\ell $) en la cantidad de la matriz de covarianza de los residuos ($ C_v $). Esto significa que el método de ajuste de mínimos cuadrados mejora las precisiones de las observaciones originales. Por ejemplo, en el ajuste con restricciones mínimas (discutido en el Capítulo 4) en el que se mantiene un punto de control fijo para un ajuste, la matriz de covarianza de los parámetros ajustados dada por la Ecuación (5.115) da la incertidumbre en las coordenadas ajustadas debido a las incertidumbres de las nuevas observaciones. Esta matriz de covarianza indica qué tan bien se conocen las coordenadas de los nuevos puntos de la encuesta en relación con el punto de control fijo, pero no qué tan bien se conocen en relación con el datum en su conjunto. La matriz de covarianza de las observaciones ajustadas (Ecuación (5.116)) es verdadera para todos los ajustes con restricciones mínimas, independientemente de cómo se defina el sistema de coordenadas y sin importar la incertidumbre del punto de control fijo. Sin embargo, las coordenadas obtenidas para los puntos libres pueden verse afectadas por los errores en el punto de control fijo, incluso si las observaciones ajustadas están libres de errores. La idea es que las observaciones ajustadas de los ajustes con restricciones mínimas no se ven afectadas por los errores en el punto de control fijo en el sentido de que los ajustes con restricciones mínimas se consideran \"ajustes libres\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f66ca9-7857-40a1-ac3f-b1333216f61e",
   "metadata": {},
   "source": [
    "### 5.8.4 Efectos de la Variación del Factor de Varianza en los Ajustes\n",
    "\n",
    "En algunos de los paquetes de software de ajuste de mínimos cuadrados hoy en día, el factor de varianza a priori de peso unitario se puede cambiar del valor habitual de uno a algunos otros números, especialmente en el proceso de detección de errores groseros. Esto generalmente se hace para hacer que el APVF de peso unitario sea igual a uno. El problema común con los usuarios de tales paquetes de software es entender cómo el cambio de un factor de varianza a priori realmente afecta las cantidades ajustadas aparte de cambiar el APVF de peso unitario ($\\sigma_0^2d$). Esto es común en el ajuste de mínimos cuadrados de las mediciones GNSS en las que las varianzas de los vectores de línea base son generalmente demasiado optimistas y a veces se acercan a valores cero. Cuando esos vectores de línea base y sus matrices de covarianza se usan en el ajuste subsiguiente de la red, el APVF calculado de peso unitario para el ajuste se vuelve extremadamente grande, de modo que las matrices de covarianza de los vectores de línea base de entrada tienen que ser escaladas por un factor. Por ejemplo, considere un caso en el que el factor de varianza a priori de peso unitario ($\\sigma_0^2 = 1d$) se cambia a un factor constante $1/kd$ (es decir, $\\sigma_0^2 = 1/kd$). Se puede demostrar matemáticamente, usando las Ecuaciones (5.81), (5.82), (5.99), (5.115) y (5.118), que el vector ajustado de parámetros $\\hat{x}d$ y su matriz de covarianza $C_{\\hat{x}}d$ permanecerán sin cambios. Esto quiere decir que cuando la matriz de covarianza inicial ($C_{\\ell}d$) de las mediciones se multiplica por un factor $kd$ (es decir, $Q_{\\ell} = kC_{\\ell}d$), esto no afectará a $\\hat{x}d$ y $C_{\\hat{x}}d$ después del ajuste; por lo tanto, la matriz de covarianza de los parámetros ajustados no se verá afectada por la elección del factor de varianza a priori. La matriz cofactor de los parámetros ajustados ($Q_{\\hat{x}}d$), sin embargo, se incrementará por un factor $kd$, y el APVF de peso unitario ($\\sigma_0^2d$) se reducirá por un factor $kd$. De manera similar, usando las Ecuaciones (5.92), (5.114), (5.117) y (5.118), se puede demostrar matemáticamente que la matriz cofactor de los residuos se escalará por un factor $kd$, pero los residuos y la matriz de covarianza de los residuos permanecerán sin cambios cuando $\\sigma_0^2 = 1/kd$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d264133c-c0d6-40b1-8bd6-85aadf87c0a1",
   "metadata": {},
   "source": [
    "### 5.9 Ajuste con Restricción de Pesos\n",
    "\n",
    "Formulación del Modelo\n",
    "\n",
    "Se dice que una estación de levantamiento está bajo restricción de peso si las coordenadas de la estación están asociadas con algunas desviaciones estándar o alguna incertidumbre. Esto es decir que las coordenadas de esta estación están abiertas a ajustes en la medida limitada por las desviaciones estándar asociadas de las coordenadas de la estación. En una estimación de mínimos cuadrados, estas coordenadas de la estación pueden considerarse como pseudo-mediciones y sus desviaciones estándar como factores de ponderación. Generalmente, una estimación de mínimos cuadrados basada en coordenadas previas y una matriz de covarianza a priori asociada $ C_{\\mathbf{x}} $ (o restricciones de peso, $ P_{\\mathbf{x}} $) dará valores ajustados que son casi idénticos a los basados en un ajuste con restricciones mínimas. El modelo de solución para el ajuste con restricción de peso se deriva en esta sección. El Ejemplo 5.10 da la derivación del procedimiento de ajuste con restricción de peso en forma simbólica. Supongamos que una red de levantamiento está compuesta por dos conjuntos de parámetros ($ \\mathbf{x}_1, \\mathbf{x}_2 $) con los parámetros previamente estimados como $ \\mathbf{x}_1 $ con una matriz de covarianza $ C_{\\mathbf{x}_1} $ asociada a ellos. Si se realiza un nuevo ajuste en esta red de levantamiento, los parámetros $ \\mathbf{x}_1 $ se considerarán tanto como mediciones como parámetros en el nuevo ajuste (teniendo una naturaleza dual en el nuevo ajuste). Si $ \\mathbf{x}_1 $ y $ \\mathbf{x}_2 $ tienen $ n_1 $ y $ n_2 $ elementos, respectivamente, la matriz de pesos $ P_{\\mathbf{x}} $ a formularse para los parámetros en el nuevo ajuste tendrá un tamaño de matriz ($ n_1 + n_2 $) por ($ n_1 + n_2 $) con el inverso de $ C_{\\mathbf{x}_1} $ ocupando el espacio correspondiente a $ \\mathbf{x}_1 $, y todos los demás elementos de la matriz $ P_{\\mathbf{x}} $ establecidos en cero. Este es un ejemplo típico de un problema de ajuste que involucra restricciones de peso en un subconjunto de puntos de la red. También es posible tener restricciones de peso en todos los puntos dados de la red. Esto puede ser el caso cuando toda una red previamente medida (probablemente de manera imprecisa usando equipo de menor calidad) en un levantamiento (primer levantamiento) se mide nuevamente con equipo de mayor precisión en otro levantamiento (segundo levantamiento). Las coordenadas de la red ajustada y sus matrices de covarianza del primer levantamiento servirán como pseudo-mediciones y restricciones de peso ($ P_{\\mathbf{x}} $) para el ajuste de las mediciones en el segundo levantamiento.\n",
    "\n",
    "Ejemplo 5.10: Dado el siguiente modelo paramétrico con restricción de peso ($ P_{\\mathbf{x}} $) en el parámetro:\n",
    "\n",
    "$$ \\hat{\\ell} = f(\\hat{x}) \\, P \\, P_{\\mathbf{x}} \\quad (5.122) $$\n",
    "\n",
    "donde $ f $ es un vector de modelo matemático, $ x $ es un vector de parámetros desconocidos, $ \\ell $ es un vector de observaciones, y $ P $ es la matriz de pesos de las observaciones.\n",
    "\n",
    "a) Formular la función de variación basada en el enfoque de Lagrange.\n",
    "\n",
    "### Solución:\n",
    "\n",
    "Reescribir la Ecuación (5.122) en términos de vectores de residuos $ v $, vector de observación ajustada $ \\hat{\\ell} $, vector de valores aproximados de parámetros ($ x^0 $), y vector de correcciones a los parámetros aproximados $ \\delta $:\n",
    "\n",
    "$$ \\ell + v = f(x^0 + \\delta) \\quad (5.123) $$\n",
    "\n",
    "Linealizar la Ecuación (5.123) mediante expansión en serie de Taylor:\n",
    "\n",
    "$$ v = f(x^0) + \\frac{\\partial f}{\\partial x} \\delta - \\ell \\quad (5.124) $$\n",
    "\n",
    "o\n",
    "\n",
    "$$ v = w + A\\delta \\quad (5.125) $$\n",
    "\n",
    "donde $ w = f(x^0) - \\ell $ es el vector de cierre y $ A = \\partial f / \\partial x $ es la primera matriz de diseño. La Ecuación (5.124) o la Ecuación (5.125) es la forma linealizada del modelo dado en la Ecuación (5.122).\n",
    "\n",
    "Dado que la matriz de pesos de las observaciones ($ P $) y la matriz de pesos de los parámetros ($ P_{\\mathbf{x}} $) están directamente asociadas con el modelo funcional dado en la Ecuación (5.122), deben usarse directamente en la formulación del criterio de mínimos cuadrados de la siguiente manera:\n",
    "\n",
    "$$ v^T P v + \\delta^T P_{\\mathbf{x}} \\delta = \\text{mínimo} \\quad (5.126) $$\n",
    "\n",
    "donde la matriz de pesos del parámetro es $ P_{\\mathbf{x}} = C_{\\mathbf{x}}^{-1} $ y la de la observación es $ P = C_{\\ell}^{-1} $ con el factor de varianza a priori de peso unitario $ \\sigma_0^2 = 1 $. Imponer el criterio de mínimos cuadrados en el modelo linealizado\n",
    "\n",
    "Ecuación (5.125), modificada como $$  (w + A\\delta - v = 0) $$. Se obtiene entonces la siguiente función de variación:\n",
    "\n",
    "$$ \\varphi = v^T P v + \\delta^T P_{\\mathbf{x}} \\delta - 2k^T (A\\delta + w - v) = \\text{mínimo} \\quad (5.127) $$\n",
    "\n",
    "donde $ k $ es un vector de correlatos (o valores constantes desconocidos).\n",
    "\n",
    "b) Derivar la forma más expandida del sistema de ecuaciones normales de mínimos cuadrados.\n",
    "\n",
    "### Solución:\n",
    "\n",
    "Encontrar las derivadas parciales de $\\varphi$ en la Ecuación (5.127) con respecto a las cantidades desconocidas $ v $, $ \\delta $, $ k^T $, y establecer sus valores a cero de la siguiente manera:\n",
    "\n",
    "$$ \\frac{\\partial \\varphi}{\\partial v} = 2v^T P + 2k^T = 0 \\quad (5.128) $$\n",
    "\n",
    "$$ \\frac{\\partial \\varphi}{\\partial \\delta} = 2\\delta^T P_{\\mathbf{x}} - 2k^T A = 0 \\quad (5.129) $$\n",
    "\n",
    "$$ \\frac{\\partial \\varphi}{\\partial k^T} = -2(A\\delta + w - v) = 0 \\quad (5.130) $$\n",
    "\n",
    "El sistema de ecuaciones normales de mínimos cuadrados más expandido se obtiene simplificando las Ecuaciones (5.128)–(5.130) de la siguiente manera:\n",
    "\n",
    "$$ v^T P + k^T = 0 \\quad (5.131) $$\n",
    "\n",
    "$$ \\delta^T P_{\\mathbf{x}} - k^T A = 0 \\quad (5.132) $$\n",
    "\n",
    "$$ A\\delta + w - v = 0 \\quad (5.133) $$\n",
    "\n",
    "c) Derivar la solución de mínimos cuadrados del sistema de ecuaciones normales.\n",
    "\n",
    "### Solución:\n",
    "\n",
    "A partir de la Ecuación (5.131), transponer la ecuación y reorganizar para obtener\n",
    "\n",
    "$$ v = -P^{-1} k \\quad (5.134) $$\n",
    "\n",
    "Sustituir la Ecuación (5.134) en la Ecuación (5.133) para obtener\n",
    "\n",
    "$$ A\\delta + w + P^{-1} k = 0 \\quad (5.135) $$\n",
    "\n",
    "Reorganizar la ecuación y resolver para $ k $ de la siguiente manera:\n",
    "\n",
    "$$ k = -P(A\\delta + w) \\quad (5.136) $$\n",
    "\n",
    "Transponer la Ecuación (5.132), y luego sustituir la Ecuación (5.136) en ella, dando\n",
    "\n",
    "$$ P_{\\mathbf{x}} \\delta + A^T P (A\\delta + w) = 0 \\quad (5.137) $$\n",
    "\n",
    "Resolver para lo desconocido $ \\delta $ en la Ecuación (5.137):\n",
    "\n",
    "$$ \\delta = - (P_{\\mathbf{x}} + A^T P A)^{-1} A^T P w \\quad (5.138) $$\n",
    "\n",
    "Los parámetros ajustados se pueden determinar de\n",
    "\n",
    "$$ \\hat{x} = x^0 + \\delta \\quad (5.139) $$\n",
    "\n",
    "Usando las Ecuaciones (5.138), (5.136) y (5.134), se puede determinar el vector de residuos $ v $, de modo que las observaciones ajustadas se pueden obtener como\n",
    "\n",
    "$$ \\hat{\\ell} = \\ell + v \\quad (5.140) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9e415a-2e59-4d1b-bf10-492c7d0c8461",
   "metadata": {},
   "source": [
    "### 5.9.1 Modelo Estocástico para Parámetros Ajustados con Restricción de Pesos\n",
    "\n",
    "Los parámetros ajustados del ajuste con restricción de pesos se pueden obtener de las Ecuaciones (5.138) y (5.139) como sigue:\n",
    "\n",
    "$$ \\hat{x} = x^0 - (P_{\\mathbf{x}} + A^T P A)^{-1} A^T P [f(x^0) - \\ell] \\quad (5.141) $$\n",
    "\n",
    "donde el vector de cierre es $ w = [f(x^0) - \\ell] $. Se asume en la Ecuación (5.141) que la matriz de pesos $ P_{\\mathbf{x}} $ tiene un tamaño de matriz completo de todos los parámetros a ajustar (incluyendo los parámetros desconocidos) y los elementos de la matriz de pesos se pueden derivar de la matriz cofactor a priori ($ Q_{\\mathbf{x}} $) de los parámetros; a los parámetros con valores desconocidos se les pueden asignar pesos cero en lugar de derivarlos directamente de sus cofactores. Mediante las leyes de propagación de la varianza-covarianza en la Ecuación (5.141), asumiendo la matriz cofactor de los parámetros ($ Q_{\\hat{x}} $) con \"elementos cero\" para los parámetros desconocidos, la matriz cofactor de los parámetros ajustados ($ Q_{\\hat{x}} $) se puede dar como\n",
    "\n",
    "$$ Q_{\\hat{x}} = J \\begin{bmatrix} Q_{\\mathbf{x}} & 0 \\\\ 0 & Q_{\\ell} \\end{bmatrix} J^T \\quad (5.142) $$\n",
    "\n",
    "donde $ Q_{\\ell} $ es el cofactor de las mediciones y $ J $ es la matriz Jacobiana de la Ecuación (5.141) con respecto al vector de parámetros ($ \\mathbf{x} $) y de las mediciones ($ \\ell $), dada como sigue:\n",
    "\n",
    "$$ J = \\begin{bmatrix} \\frac{\\partial \\hat{x}}{\\partial \\mathbf{x}} & \\frac{\\partial \\hat{x}}{\\partial \\ell} \\end{bmatrix} \\quad (5.143) $$\n",
    "\n",
    "con\n",
    "\n",
    "$$ \\frac{\\partial \\hat{x}}{\\partial \\mathbf{x}} = I - (P_{\\mathbf{x}} + A^T P A)^{-1} A^T P A \\quad (5.144) $$\n",
    "\n",
    "$$ \\frac{\\partial \\hat{x}}{\\partial \\ell} = (P_{\\mathbf{x}} + A^T P A)^{-1} A^T P \\quad (5.145) $$\n",
    "\n",
    "Tenga en cuenta de la Ecuación (5.144) que $\\frac{\\partial f(x^0)}{\\partial \\mathbf{x}} = A$, la primera matriz de diseño, y $ I $ es una matriz identidad con todos los elementos diagonales principales como unos y todos los elementos fuera de la diagonal como ceros. La forma expandida de la Ecuación (5.142) se puede dar como\n",
    "\n",
    "$$ Q_{\\hat{x}} = Q_{\\mathbf{x}} - Q_{\\mathbf{x}} NW - WNQ_{\\mathbf{x}} + WNQ_{\\mathbf{x}} NW + WNW \\quad (5.146) $$\n",
    "\n",
    "donde\n",
    "\n",
    "$$ W = (P_{\\mathbf{x}} + A^T P A)^{-1} \\quad (5.147) $$\n",
    "\n",
    "$$ N = (A^T P A) \\quad (5.148) $$\n",
    "\n",
    "La Ecuación (5.146) se puede demostrar que es equivalente a lo siguiente:\n",
    "\n",
    "$$ Q_{\\hat{x}} = (P_{\\mathbf{x}} + A^T P A)^{-1} \\quad (5.149) $$\n",
    "\n",
    "La matriz de varianza-covarianza de los parámetros ajustados se puede dar como\n",
    "\n",
    "$$ C_{\\hat{x}} = \\sigma_0^2 Q_{\\hat{x}} \\quad (5.150) $$\n",
    "\n",
    "donde el APVF de peso unitario $\\sigma_0^2$ se puede dar como\n",
    "\n",
    "$$ \\sigma_0^2 = \\frac{v^T P v + \\delta^T P_{\\mathbf{x}} \\delta}{n_d - u_d} \\quad (5.151) $$\n",
    "\n",
    "con $ n_d $ como el número de observaciones directas (o reales) y $ u_d $ como el número de parámetros directos (aquellos parámetros cuyos valores no están asociados con ninguna desviación estándar a priori)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32f20f-b393-4f01-b996-df4b79cc435b",
   "metadata": {},
   "source": [
    "### 5.9.2 Modelo Estocástico para Observaciones Ajustadas con Restricción de Pesos\n",
    "\n",
    "Las observaciones ajustadas se pueden obtener de las Ecuaciones (5.133), (5.138) y (5.140) con el vector de cierre $ w = f(x^0) - \\ell $ como sigue:\n",
    "\n",
    "$$ \\hat{\\ell} = \\ell - A(P_{\\mathbf{x}} + A^T PA)^{-1} A^T P [f(x^0) - \\ell] + [f(x^0) - \\ell] \\quad (5.152) $$\n",
    "\n",
    "o en una forma expandida como\n",
    "\n",
    "$$ \\hat{\\ell} = -A(P_{\\mathbf{x}} + A^T PA)^{-1} A^T P [f(x^0)] + A(P_{\\mathbf{x}} + A^T PA)^{-1} A^T P \\ell + f(x^0) \\quad (5.153) $$\n",
    "\n",
    "Se asume en la Ecuación (5.153) que la matriz de pesos $ P_{\\mathbf{x}} $ tiene un tamaño de matriz completo de todos los parámetros a ajustar (incluyendo los parámetros desconocidos) y los elementos de la matriz de pesos se pueden derivar de la matriz cofactor a priori ($ Q_{\\mathbf{x}} $) de los parámetros; a los parámetros con valores desconocidos se les pueden asignar pesos cero en lugar de derivarlos directamente de sus cofactores. Mediante las leyes de propagación de la varianza-covarianza en la Ecuación (5.153), asumiendo la matriz cofactor de los parámetros ($ Q_{\\hat{x}} $) con \"elementos cero\" para los parámetros desconocidos, la matriz cofactor de las observaciones ajustadas ($ Q_{\\hat{\\ell}} $) se puede dar como\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = J \\begin{bmatrix} Q_{\\mathbf{x}} & 0 \\\\ 0 & Q_{\\ell} \\end{bmatrix} J^T \\quad (5.154) $$\n",
    "\n",
    "donde $ Q_{\\ell} $ es el cofactor de las mediciones y $ J $ es la matriz Jacobiana de la Ecuación (5.153) con respecto al vector de parámetros ($ \\mathbf{x} $) y de las mediciones ($ \\ell $), dada como sigue:\n",
    "\n",
    "$$ J = \\begin{bmatrix} \\frac{\\partial \\hat{\\ell}}{\\partial \\mathbf{x}} & \\frac{\\partial \\hat{\\ell}}{\\partial \\ell} \\end{bmatrix} \\quad (5.155) $$\n",
    "\n",
    "con\n",
    "\n",
    "$$ \\frac{\\partial \\hat{\\ell}}{\\partial \\mathbf{x}} = -A(P_{\\mathbf{x}} + A^T PA)^{-1} A^T PA + A \\quad (5.156) $$\n",
    "\n",
    "$$ \\frac{\\partial \\hat{\\ell}}{\\partial \\ell} = A(P_{\\mathbf{x}} + A^T PA)^{-1} A^T P \\quad (5.157) $$\n",
    "\n",
    "Tenga en cuenta de la Ecuación (5.156) que $\\frac{\\partial f(x^0)}{\\partial \\mathbf{x}} = A$, la primera matriz de diseño, y $ I $ es una matriz identidad con todos los elementos diagonales principales como unos y todos los elementos fuera de la diagonal como ceros. La forma expandida de la Ecuación (5.154) se puede dar como\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = A Q_{\\mathbf{x}} A^T - A Q_{\\mathbf{x}} N W A^T - A W N Q_{\\mathbf{x}} A^T + A W N Q_{\\mathbf{x}} N W A^T + A W N W A^T \\quad (5.158) $$\n",
    "\n",
    "donde $ W $ y $ N $ son como se definieron previamente en las Ecuaciones (5.147) y (5.148). La Ecuación (5.158) se puede demostrar que es equivalente a lo siguiente:\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = A (P_{\\mathbf{x}} + A^T PA)^{-1} A^T \\quad (5.159) $$\n",
    "\n",
    "La matriz de varianza-covarianza de las observaciones ajustadas se puede dar como\n",
    "\n",
    "$$ C_{\\hat{\\ell}} = \\sigma_0^2 Q_{\\hat{\\ell}} \\quad (5.160) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550eceee-3e83-4ac6-b77b-25584d342ad6",
   "metadata": {},
   "source": [
    "## Problemas\n",
    "\n",
    "### 5.1 \n",
    "En un problema de resecado de tres puntos mostrado en la Figura P5.1, las coordenadas del punto P ($x, y$) deben determinarse utilizando los puntos de control A ($x_A, y_A$), B ($x_B, y_B$), y C ($x_C, y_C$). Las mediciones de dirección de la estación total desde el punto de instalación P son $\\ell_1, \\ell_2, y \\ell_3$; las mediciones de ángulo en el punto B son $\\theta_1$ y $\\theta_2$; la medición de distancia desde el punto B hasta P es $\\ell_4$; y el parámetro de orientación en el punto de instalación P es como se muestra en la figura. Formule las ecuaciones del modelo paramétrico ($\\hat{\\ell} = f(\\hat{x})$) para este problema.\n",
    "\n",
    "### 5.2\n",
    "Dado el siguiente modelo paramétrico linealizado:\n",
    "\n",
    "$$ r = Jy + m \\quad C_{\\lambda} $$\n",
    "\n",
    "donde $ J $ es la primera matriz de diseño con respecto al vector de parámetros $ x $, $ y $ es un vector de correcciones a los parámetros aproximados ($x^0$), $ m $ es el vector de cierres, $ C_{\\lambda} $ es una matriz de covarianza del vector de observaciones $\\lambda$, y $ r $ es un vector de residuos. Responda las siguientes preguntas usando los símbolos dados.\n",
    "\n",
    "a) Dé el criterio de mínimos cuadrados y la función de variación (basada en el enfoque de Lagrange) para este problema en términos de los símbolos usados en esta pregunta.\n",
    "\n",
    "b) Derive el sistema de ecuaciones normales de mínimos cuadrados y el vector de solución ($y$) para este problema en términos de los símbolos usados en esta pregunta (explique claramente cada paso de sus derivaciones)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71acb68a-9f51-4236-ad72-702d47860355",
   "metadata": {},
   "source": [
    "### 5.3\n",
    "\n",
    "a) Refiriéndose a la Sección 5.5 del libro, asuma que el factor de varianza a priori de peso unitario ($\\sigma_0^2$) no es igual a uno sino igual a un factor constante desconocido $ k $ (es decir, $\\sigma_0^2 = k$). Muestre matemáticamente, utilizando las Ecuaciones (5.73), (5.74), (5.99), (5.115) y (5.118), cómo el vector de solución del modelo paramétrico y sus matrices de cofactor y covarianza se verán afectados por el factor constante desconocido $ k $. (No se otorgarán puntos completos a menos que se proporcionen todos los pasos lógicos y explicaciones, incluidas las sustituciones en las fórmulas).\n",
    "\n",
    "b) Refiriéndose a la Sección 5.5 del libro, asuma que el factor de varianza a priori de peso unitario ($\\sigma_0^2$) no es igual a uno sino igual a un factor constante desconocido $ k $ (es decir, $\\sigma_0^2 = k$). Muestre matemáticamente, utilizando las Ecuaciones (5.92), (5.114), (5.117) y (5.118), cómo el cofactor y las matrices de covarianza de los residuos se verán afectados por el factor constante desconocido $ k $. (No se otorgarán puntos completos a menos que se proporcionen todos los pasos lógicos y explicaciones, incluidas las sustituciones en las fórmulas).\n",
    "\n",
    "### 5.4\n",
    "\n",
    "Dado los siguientes modelos matemáticos:\n",
    "\n",
    "$$ \\hat{\\lambda} = f(\\hat{y}) \\quad C_{\\lambda} $$\n",
    "\n",
    "donde $ f $ es un vector de modelos matemáticos, $\\hat{y}$ es un vector de parámetros ajustados, $\\hat{\\lambda}$ es un vector de observaciones ajustadas, y $ C_{\\lambda} $ es una matriz de covarianza de las observaciones. Responda las siguientes preguntas, definiendo cada símbolo utilizado en sus derivaciones.\n",
    "\n",
    "a) Derive (tan completamente como sea posible con una explicación completa de sus pasos) el modelo paramétrico linealizado.\n",
    "\n",
    "b) Dé el criterio de mínimos cuadrados y la función de variación (basada en el enfoque de Lagrange) para este problema en términos de los símbolos utilizados en esta pregunta.\n",
    "\n",
    "### 5.5\n",
    "\n",
    "Dado los siguientes modelos matemáticos:\n",
    "\n",
    "$$ \\hat{\\ell} = f(\\hat{x}_1, \\hat{x}_2, \\hat{x}_3) \\, P \\, P_{x_1} \\, P_{x_3} $$\n",
    "\n",
    "donde $ f $ es un vector de modelos matemáticos, $\\hat{x}_1$, $\\hat{x}_2$ y $\\hat{x}_3$ son vectores de parámetros ajustados, $\\hat{\\ell}$ es un vector de observaciones ajustadas, $ P $ es una matriz de pesos de las observaciones, $ P_{x_1} $ es la matriz de pesos de los parámetros $\\hat{x}_1$, y $ P_{x_3} $ es la matriz de pesos de los parámetros $\\hat{x}_3$. Responda las siguientes preguntas, definiendo cada símbolo utilizado en sus derivaciones.\n",
    "\n",
    "a) Derive (tan completamente como sea posible con una explicación completa de sus pasos) el modelo linealizado.\n",
    "\n",
    "b) Dé el criterio de mínimos cuadrados para este problema.\n",
    "\n",
    "c) Derive la función de variación (basada en el enfoque de Lagrange).\n",
    "\n",
    "d) Derive el sistema de ecuaciones normales de mínimos cuadrados minimizando la función de variación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d352950f-1731-4fc6-b89b-a03517e0c9bf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
