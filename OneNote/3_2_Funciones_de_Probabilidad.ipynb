{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "899b9039-e7c8-4c97-9ec1-0af3dba03d75",
   "metadata": {},
   "source": [
    "## 3.2 Funciones de Probabilidad\n",
    "\n",
    "Las funciones de probabilidad son modelos matemáticos formulados con su validez ya probada por experimentos. También se las conoce como modelos estocásticos, que son funciones de algunos observables aleatorios (o variables). Al ser una función de algunos observables aleatorios, un modelo estocástico en sí mismo se convierte en un observable aleatorio. Un observable aleatorio (o variable) es una cantidad física que puede ser asignada mediante medición u observación, como distancia, ángulo, altura, etc. Un observable aleatorio que puede asumir posibles valores contables se refiere como observable aleatorio discreto; el que puede asumir un número infinito posible de valores es un observable aleatorio continuo. Si los posibles valores de un observable aleatorio se ordenan en un orden creciente de magnitud con sus probabilidades asociadas, se forma una función de probabilidad o función de distribución de probabilidad ($ f(x) $). \n",
    "\n",
    "Una función de probabilidad $ f(x) $ es tal que cuando se ingresa uno de los valores que el observable aleatorio puede asumir, produce un valor de probabilidad asociado como una salida. Esta función describe la probabilidad de que ocurra un valor dado. Algunas propiedades de una función de probabilidad válida son que su salida siempre es mayor o igual a cero y la suma de todas sus posibles salidas tenderá a la unidad (o 1). Si el observable aleatorio es de tipo discreto, la función de probabilidad asociada generalmente se conoce como función de masa de probabilidad. Las funciones de masa de probabilidad se refieren específicamente a distribuciones de probabilidad discretas en las que la función de probabilidad $ f(x) $ puede tomar un valor discreto $ x $ de una variable aleatoria (como lanzar una moneda) y proporcionar su probabilidad exacta $ p(x) $ de ocurrencia, usualmente entre los valores de 0 y 1. Un observable aleatorio continuo, que puede asumir valores entre dos valores diferentes en un intervalo de $-\\infty$ a $+\\infty$ (pero no en un punto único en un instante de tiempo), tendrá una función de probabilidad conocida como función de densidad de probabilidad (pdf) o simplemente densidad de probabilidad. La función de densidad de probabilidad ($ f(x) $) se puede integrar para obtener la función de distribución acumulativa (cdf) para observables aleatorios discretos y continuos.\n",
    "\n",
    "Es típico en la tradición de probabilidad representar un observable aleatorio (o variable) en letras mayúsculas, como $ X $, y sus valores en letras minúsculas, como $ x $. En este caso, la función de masa de probabilidad de una variable aleatoria $ X $ tomando un valor $ x $ se puede expresar como $ P(X = x) $, mientras que la cdf de una variable aleatoria $ X $ tomando un valor menor o igual a $ x $ se expresará como $ P(X \\leq x) $. Dado que la cdf tiene importantes aplicaciones en las pruebas de hipótesis estadísticas, se explorará en este capítulo. Además, la distribución normal (o distribución gaussiana), que es uno de los ejemplos más importantes de una distribución de probabilidad continua, se discutirá en la Sección 3.6.\n",
    "\n",
    "### 3.2.1 Distribuciones de Probabilidad Normal y Funciones de Densidad\n",
    "\n",
    "En geomática, los observables son aleatorios y sus observaciones se consideran continuas, es decir, cada vez que se mide un observable, es posible un valor numérico diferente para el observable, y generalmente el observable puede asumir cualquier valor dentro de un cierto intervalo. Por ejemplo, un observable de distancia medido tres veces puede asumir los valores 12.255, 12.250, y 12.245 m; considerando estas mediciones de muestra, se puede ver que el observable de distancia probablemente asume cualquier valor dentro o fuera del intervalo 12.245 y 12.555 m. Este observable, por lo tanto, se considera una variable continua aleatoria ya que puede asumir cualquier valor dentro de un intervalo. Desde los principios de probabilidad y estadísticas, un observable aleatorio continuo $ X $ tendrá su distribución de probabilidad completamente descrita por su pdf y su cdf. En geomática, los observables, como variables continuas aleatorias, se asumen que tienen poblaciones que se distribuyen normalmente con los errores involucrados satisfaciendo las ecuaciones de Gaussian de errores.\n",
    "\n",
    "Los observables geomáticos pueden representarse y analizarse gráficamente (o numéricamente). La representación gráfica incluirá histogramas creados a partir de las observaciones y, si uno sigue el método de mediciones repetidas de observables de encuesta, los errores restantes muestran una campana característica llamada la curva de distribución de error normal o la pdf de una variable aleatoria normal. La función de densidad es una función suavizada de un histograma que describe las probabilidades relativas (o frecuencias relativas) de los valores tomados por el observable dado. Si la densidad de probabilidad alrededor de un valor es grande, significa que el observable aleatorio es probable que esté cerca de ese valor. Para un número infinito de valores del observable aleatorio con probabilidad igual, esto teóricamente significará que la probabilidad de cero será asumida por cada valor para que uno no pueda pensar en la pdf como proporcionando valores de probabilidad, sino probabilidades relativas. Cuando la densidad de probabilidad es alta, significa que el valor asociado es relativamente más probable, y cuando es baja, el valor es relativamente menos probable. La densidad de probabilidad proporciona la probabilidad de estar dentro de un intervalo muy pequeño que contiene el valor dado. El área bajo la función de densidad representa la suma de todas las probabilidades de los valores del observable, y esto es igual a 1; las áreas bajo la función de densidad entre valores en el eje-x dan las probabilidades de mentir en esos intervalos. La ecuación de la curva de distribución normal, también conocida como pdf normal, se da como sigue:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x-\\mu}{\\sigma}\\right)^2} \\tag{3.1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbedb04d-62bc-4700-a215-07be8991b98e",
   "metadata": {},
   "source": [
    "donde $ f(x) $ representa la probabilidad de la ocurrencia de $ (x - \\mu) $ (es decir, la probabilidad de que el valor observable $ x $ se desvíe por $ x - \\mu $ desde la posición central $ \\mu $ de la distribución), $ \\sigma $ es la verdadera desviación estándar (o dispersión de la distribución) de la medición; $ e $ es la base de los logaritmos naturales con valor aproximado de 2.718 28, $ \\pi $ es la constante matemática familiar con valor aproximado de 3.141 59, $ \\mu $ es el valor verdadero de $ x $, $ \\frac{1}{\\sigma\\sqrt{2\\pi}} $ es un factor para asegurar que el área total bajo la curva de distribución sea igual a uno (haciendo que la función sea una función de probabilidad), y la mitad en el exponente es para asegurar que la distribución tenga varianza unitaria (y también desviación estándar unitaria) en el caso de la distribución normal estándar. Aunque el eje $ f(x) $ representa las frecuencias de los valores de la variable, las áreas bajo la curva (que representan las probabilidades) son más importantes que las frecuencias. Esta distribución normal es por lo tanto una familia de curvas de dos parámetros con los parámetros como $ \\mu $ y $ \\sigma $. Dado que el valor verdadero del error aleatorio debe ser cero ($ \\mu = 0 $), entonces la Ecuación (3.1), cuando se usa en relación con errores aleatorios, se convertirá en\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}\\left(\\frac{x}{\\sigma}\\right)^2} \\tag{3.2}\n",
    "$$\n",
    "\n",
    "Una distribución normal estándar ($ f(z) $) se obtiene cuando la Ecuación (3.1) se usa en relación con un observable aleatorio estandarizado $ Z $ cuyo valor puede ser representado por\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma} \\tag{3.3}\n",
    "$$\n",
    "\n",
    "donde la distribución normal estándar ($ f(z) $) establece $ \\sigma $ a 1, dando, desde la Ecuación (3.1), lo siguiente:\n",
    "\n",
    "$$\n",
    "f(z) = \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}z^2} \\tag{3.4}\n",
    "$$\n",
    "\n",
    "Algunas de las propiedades importantes de $ z $ son que tiene una media poblacional ($ \\mu $) de cero y una varianza poblacional ($ \\sigma^2 $) de 1 y es adimensional. Los valores de $ z $ a veces se refieren como puntuaciones estándar (o puntuaciones z). Note que la puntuación z en la Ecuación (3.3) representa cuántas desviaciones estándar el valor observable $ x $ está alejado de la media poblacional, $ \\mu $. La representación gráfica de la distribución normal estándar se da en la Figura 3.1. Como se puede ver en la figura, los valores del eje z se dan en términos de cuántas desviaciones estándar el valor observable $ x - \\mu $ está alejado de la posición donde $ x - \\mu $ asume un valor cero. Los valores numéricos de la pdf en la Ecuación (3.4) generalmente se proporcionan en las tablas estadísticas para la distribución normal estandarizada para cualquier valor dado de $ z $.\n",
    "\n",
    "En la Figura 3.1, se puede ver que la función de densidad es de aproximadamente 0.4 para un valor central de 0, y para un valor de -1 o 1, su densidad de probabilidad es de aproximadamente 0.2. Esto significa que un valor cercano a 0 es aproximadamente dos veces más probable que un valor cercano a -1 o 1. Nótese que la densidad en 0 no es la probabilidad de obtener 0, porque la densidad en sí misma no es probabilidad. El área (no el valor de la función en sí) bajo la función de probabilidad en la Ecuación (3.1) (o la integral de la función), entre dos puntos distintos ($x = a$ y $x = b$), proporciona la probabilidad para ese intervalo, como se muestra en la Figura 3.2. Esto se puede interpretar como que la probabilidad de que la variable aleatoria $X$ tenga su valor en el intervalo entre dos puntos $a$ y $b$ es el área sombreada bajo la función de densidad entre $a$ y $b$, expresado matemáticamente como:\n",
    "\n",
    "$$\n",
    "P(a \\leq X \\leq b) = \\int_{a}^{b} f(x)dx \\tag{3.5}\n",
    "$$\n",
    "\n",
    "El área de la función sobre toda la población de valores (desde menos infinito hasta más infinito) debe ser igual a uno. La cdf $F(x)$ de una variable aleatoria $X$ se define en relación con la pdf para un valor variable $x = a$ como sigue:\n",
    "\n",
    "$$\n",
    "F(x = a) = P(X \\leq a) = \\int_{-\\infty}^{a} f(x)dx \\tag{3.6}\n",
    "$$\n",
    "\n",
    "La Ecuación (3.6) significa que el área ($F(a)$) bajo la pdf ($f(x)$) desde menos infinito hasta $x = a$ es la probabilidad de que el valor de $X$ no sea mayor que $a$. De la Ecuación (3.6), la relación matemática entre $f(x)$ y $F(x)$ se puede dar como sigue:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{d}{dx}F(x) \\tag{3.7}\n",
    "$$\n",
    "\n",
    "La representación gráfica de la cdf ($F(x)$) expresada por la Ecuación (3.6) se da en la Figura 3.3. En la práctica, la pdf no se puede conocer con precisión ya que requerirá un examen exhaustivo de toda una población. Generalmente, las estimaciones de la pdf se hacen en base a muestras finitas con sus incertidumbres asociadas. Los estimadores de probabilidad más populares son los histogramas. Un ejemplo de una pdf bien conocida se basa en la curva de distribución normal (con los parámetros como la media $\\mu$ y la desviación estándar $\\sigma$), cuya pdf se da para un valor variable $x$ por la Ecuación (3.1).\n",
    "\n",
    "El área bajo la pdf normal estándar (la integral de la pdf) de una variable aleatoria (como un error aleatorio) sobre una región dada como se muestra en la Figura 3.4, por ejemplo, describe la probabilidad relativa de que esta variable aleatoria ocurra dentro de la región. La distribución de errores aleatorios (o errores estandarizados o residuos estandarizados) como se muestra en la Figura 3.4 tiene las siguientes propiedades:\n",
    "\n",
    "- La frecuencia de ocurrencia (o probabilidad) de un error aleatorio de una magnitud dada depende de la magnitud del error. Por ejemplo, la probabilidad de un error de magnitud $-1\\sigma$ o $+1\\sigma$ (donde $\\sigma$ es la desviación estándar de la medición) como se muestra en la Figura 3.4 es 68.27%. Esto significa que para cada 100 mediciones, hay una probabilidad de que 68.27 de las mediciones tendrán un error de magnitud $\\pm1\\sigma$. Este valor se puede determinar usando la cdf en la distribución normal estándar Z, expresada como\n",
    "\n",
    "$$\n",
    "P(-1 \\leq Z \\leq 1) = F(1) - F(-1) \\tag{3.8}\n",
    "$$\n",
    "\n",
    "usando la distribución normal acumulativa estándar, por ejemplo, la rutina de software Microsoft Excel 2013 NORM.S.DIST, la Ecuación (3.9) se puede reescribir como\n",
    "\n",
    "$$\n",
    "P(-1 \\leq Z \\leq 1) = NORM.S.DIST(1, TRUE) - NORM.S.DIST(-1, TRUE) \\tag{3.10}\n",
    "$$\n",
    "\n",
    "dando lo siguiente:\n",
    "\n",
    "$$\n",
    "P(-1 \\leq Z \\leq 1) = 0.84134 - 0.158655 \\tag{3.11}\n",
    "$$\n",
    "\n",
    "que es 0.6827 o 68.27%. De manera similar, la probabilidad de un error de magnitud $-3\\sigma$ o $+3\\sigma$ es 0.9973 o 99.73%, que también se puede obtener de la distribución normal acumulativa estándar en la Figura 3.5 como sigue:\n",
    "\n",
    "$$\n",
    "P(-3 \\leq Z \\leq 3) = 0.99865 - 0.00135 \\tag{3.12}\n",
    "$$\n",
    "\n",
    "- Los errores grandes ocurren con menos frecuencia que los errores pequeños. Por ejemplo, en la Figura 3.4, hay 1 - (0.6827) o 31.73% de probabilidad de ocurrencia de errores mayores que $\\pm1\\sigma$. Esto significa que cuanto mayor sea el error, menos probable es que ocurra en una medición. La pdf en la Ecuación (3.4) y la Figura 3.4 muestran que la pdf se aproxima a cero a medida que $z$ (valor estandarizado) aumenta en magnitud, lo que significa que los errores grandes son extremadamente improbables.\n",
    "- La distribución de errores puede ser positiva y negativa de la misma magnitud. En la Figura 3.4, se puede ver que los valores de error positivos y negativos de la misma magnitud son igualmente probables que cualquier otro valor.\n",
    "- En geomática, las observaciones y sus residuos (o errores aleatorios) se consideran normalmente distribuidos con la función de densidad expresada por la Ecuación (3.1). También es común en geomática asociar el error máximo aceptable en la medición con un rango de incertidumbre que tiene un nivel de probabilidad muy alto de ocurrencia, como $\\pm3\\sigma$ (o el error con una probabilidad de 99.73% de que ocurrirá). Este error máximo aceptable en la medición a menudo se refiere como tolerancia de medición o tolerancia de encuesta. En algunos proyectos geomáticos, se puede especificar la tolerancia de medición a nivel de probabilidad de 95%; si la tolerancia no está especificada, sin embargo, será seguro usar el nivel de probabilidad de 99.73% (especialmente en la etapa de diseño de un proyecto).\n",
    "\n",
    "Si la probabilidad de una variable Z que toma un valor menor que un valor desconocido $z$ es conocida (por ejemplo, nivel de probabilidad de 95%), el valor de $z$ se puede estimar dependiendo de qué extremo (cola) de la distribución de probabilidad esté involucrada. La cola de la distribución generalmente se refiere a la región de la distribución que está lejos de la media (que es el centro de la distribución). Un punto donde una cola comienza cuando se dirige hacia infinito positivo o donde termina cuando comienza desde infinito negativo se conoce como el valor crítico. Las áreas bajo las colas desde el valor crítico hacia infinito positivo y negativo se conocen como el nivel de significancia (o $\\alpha$). El área de la región en el medio de la distribución contenida por los valores críticos inferior y superior se conoce como el nivel de confianza. Las colas, los valores críticos, el nivel de confianza y el nivel de significancia de una distribución estándar se ilustran en la Figura 3.6. Por ejemplo, dado que la probabilidad de $Z$ tomando un valor menor que un valor desconocido $z$ es 95%, el valor de $z$ se puede determinar usando la función de probabilidad estándar normal inversa (NORM.S.INV (probabilidad)) en el software Microsoft Excel 2013 como sigue. Para el problema de dos colas (con nivel de significancia de 0.025 para colas inferior y superior cada una), NORM.S.INV(0.025) = -1.96 es el valor crítico en la cola inferior y NORM.S.INV(0.975) = 1.96 es el valor crítico en la cola superior. En el caso de un problema de una cola (con 0.05 para la cola), NORM.S.INV(0.05) = -1.64 y 1.64 para la cola superior. Así, se puede ver que los valores críticos son simétricos alrededor de la media con uno de ellos siendo el negativo del otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591ae46-d07b-4c0b-baf6-a6a6c427d354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
