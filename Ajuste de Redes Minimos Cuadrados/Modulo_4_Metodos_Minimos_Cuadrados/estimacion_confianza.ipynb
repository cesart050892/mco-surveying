{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1d651a-735a-4299-9d9e-3229df8a3b22",
   "metadata": {},
   "source": [
    "### 7 Estimación de la Región de Confianza\n",
    "\n",
    "#### 7.1 Introducción\n",
    "\n",
    "La estimación es un procedimiento para hacer deducciones sobre la población utilizando información derivada de una muestra. Las piezas típicas de información que pueden derivarse de una muestra incluyen estadísticas de muestra, como la media de la muestra, la desviación estándar de la muestra, el puntaje z, el puntaje t, la estadística chi-cuadrado y la estadística F. Un estimador es un ejemplo particular de una estadística, es decir, una función de esos datos que se utiliza para inferir el valor de un parámetro desconocido en un modelo estadístico. Es una regla para calcular estadísticas de muestra (media, desviación estándar, etc.) basada en datos de muestra; la regla generalmente se expresa como una fórmula. Se puede definir en general como una función de observables o datos de muestra para estimar el parámetro desconocido. Todo lo que produzca una estimación es un estimador, como el algoritmo para calcular promedios.\n",
    "\n",
    "Algunas estadísticas son buenos estimadores y otras no lo son, como las pruebas de hipótesis. Se puede decir que cada estimador es una estadística, pero no todas las estadísticas son estimadores. Sin embargo, las estadísticas y los estimadores son similares porque ambos son funciones de observables aleatorios y ambos tienen distribuciones de muestreo. Una salida del estimador cuando se aplica a un conjunto particular de datos de muestra es una estimación. Cuando el nombre de la distribución de muestreo de una estadística es igual a un parámetro de la población, esa estadística se llama un estimador insesgado del parámetro. Un estimador insesgado es aquel cuyo valor esperado es igual al parámetro que está estimando. Se dice que es un estimador consistente si la diferencia entre el estimador y el parámetro se vuelve más pequeña a medida que el tamaño de la muestra aumenta.\n",
    "\n",
    "El valor esperado de un estimador asegura que un promedio de varias observaciones del estimador dará un valor que es igual al parámetro desconocido. Muchos estimadores diferentes son posibles para un parámetro dado. Los dos tipos que se discuten aquí son los estimadores puntuales y los intervalos de confianza. Mientras que los estimadores puntuales producen estimaciones de una sola magnitud, los intervalos de confianza producen regiones de confianza. En el contexto de intervalos de confianza, una región de confianza es una generalización multidimensional de intervalos de confianza. En este caso, un intervalo de confianza se considera como una región de confianza unidimensional. Los detalles de cómo construir regiones de confianza se discuten en este capítulo.\n",
    "\n",
    "#### 7.2 Error Cuadrático Medio y Expectativa Matemática\n",
    "\n",
    "##### 7.2.1 Error Cuadrático Medio\n",
    "\n",
    "El error cuadrático medio (ECM) de un estimador es el promedio del cuadrado de la desviación del estimador del parámetro que se estima. Esta es una de las muchas formas de cuantificar la cantidad en la que un estimador difiere del valor verdadero del parámetro que se está estimando. Es una medida del promedio del cuadrado del error (el error que surge del cual el estimador difiere de la cantidad que se va a estimar).\n",
    "\n",
    "En el análisis de regresión, por ejemplo, ECM es una medida de qué tan cerca se ajusta una línea ajustada a las observaciones como medida de la diferencia entre las observaciones reales y la respuesta predicha por el modelo. Esto puede utilizarse para determinar si el modelo se ajusta a los datos bien o si el modelo puede simplificarse eliminando algunos términos. Cuanto menor sea el ECM, mejor se ajustará a los datos. En este caso, el ECM es el cuadrado de la desviación de los puntos de su posición verdadera, que puede considerarse como una estimación del error verdadero (una función de una cantidad observada en lugar de una función del parámetro desconocido).\n",
    "\n",
    "$$\n",
    "\\text{MSE}(\\bar{x}) = E[(\\bar{x} - \\mu)^2]\n",
    "$$\n",
    "\n",
    "La ecuación (7.1), que es el segundo momento de la cantidad observable, explica generalmente qué tan cerca algunos datos se ajustan a una línea ajustada (en el caso de la regresión lineal). Si el estimador $\\bar{x}$ es insesgado, el siguiente resultado será:\n",
    "\n",
    "$$\n",
    "\\text{MSE}(\\bar{x}) = \\left(\\frac{\\sigma}{\\sqrt{n}}\\right)^2\n",
    "$$\n",
    "\n",
    "De lo contrario, se obtendrá el siguiente resultado:\n",
    "\n",
    "$$\n",
    "\\text{MSE}(\\bar{x}) = \\left(\\frac{\\sigma}{\\sqrt{n}}\\right)^2 + \\text{Sesgo}^2\n",
    "$$\n",
    "\n",
    "Un estimador insesgado como el ECM($\\hat{x}$) que es un valor mínimo entre todos los estimadores insesgados ($\\sigma^2$) se llama estimador insesgado de varianza mínima. Del mismo modo, cuando la varianza de la muestra ($s^2$) es un estimador insesgado de la varianza de la población ($\\sigma^2$), el ECM cuando el valor verdadero $\\theta = \\sigma^2$ (la varianza de la población) se puede dar como sigue:\n",
    "\n",
    "$$\n",
    "\\text{MSE}(s^2) = E[(s^2 - \\sigma^2)^2] = \\frac{2\\sigma^4}{n-1}\n",
    "$$\n",
    "\n",
    "El valor del ECM será cero, lo que es posible si las observaciones del parámetro se predicen perfectamente por el estimador. El cuadrado de la raíz del ECM se conoce como el error cuadrático medio de la raíz (RMSE), que es una medida de qué tan bien se ajusta una línea a un conjunto de datos. El RMSE es una medida de la diferencia entre los valores observados previstos por un modelo y los valores observados reales. La diferencia es llamada residuo y el RMSE es una medida de la dispersión de estos residuos cuando se ajusta una línea a los datos observados.\n",
    "\n",
    "##### 7.2.2 Expectativa Matemática\n",
    "\n",
    "La expectativa matemática, valor esperado, o simplemente expectativa de una cantidad observable aleatoria es un concepto importante en probabilidad y estadísticas. Es el promedio aritmético (o ponderado) del valor sumado de todas las observaciones posibles de la cantidad. Los valores de la cantidad observable con sus pesos son la probabilidad correspondiente de las observaciones (por ejemplo, la expectativa ($\\mu$) de la media (μ) de todas las observaciones posibles ($x_i$), suponiendo una función de distribución $f$ donde todas las observaciones ($x_i$) están marcadas con sus pesos ($p_i$) para las cantidades ($x_1, x_2, ..., x_m$).\n",
    "\n",
    "$$\n",
    "\\mu = E(X) = \\sum_{i=1}^{m} x_i p(x_i)\n",
    "$$\n",
    "\n",
    "donde $E(x_i) = \\mu$, $n_s$ es el número de muestras, y $1/n_s$ es la probabilidad de cada muestra (suponiendo igual probabilidad). En la ecuación (7.8), el promedio de todas las muestras se convierte en la media de la población ($\\mu$); las medias de muestras individuales pueden sobreestimar o subestimar la media de la población, pero su promedio aritmético ($\\bar{x}$) siempre es igual a la media de la población. La desviación estándar de la media, que se llama el error estándar de la media ($\\sigma_{\\bar{x}}$), se puede determinar como sigue:\n",
    "\n",
    "$$\n",
    "\\sigma_{\\bar{x}} = \\sqrt{\\frac{\\sum (x_i - \\mu)^2}{n_s}}\n",
    "$$\n",
    "\n",
    "donde $n_s$ es el número de muestras. Este error estándar de la media indica la diferencia \"promedio\" entre la media de varias muestras y la media de la población. En promedio, cada muestra difiere de la media de la población por $\\sigma_{\\bar{x}}$. Si $\\sigma_{\\bar{x}}$ es pequeño, cualquier muestra será una buena estimación de la media de la población. La estimación aproximada del error estándar de la media se puede dar como\n",
    "\n",
    "$$\n",
    "\\sigma_{\\bar{x}} = \\frac{\\sigma}{\\sqrt{n}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5eb55e-2eaa-4224-b3a9-b63d3bcf2da8",
   "metadata": {},
   "source": [
    "donde $n$ es el tamaño de la muestra. De acuerdo con la Ecuación (7.10), la desviación estándar de la media se vuelve más pequeña a medida que el tamaño de la muestra aumenta, lo que significa que una muestra grande es más confiable que una pequeña. De las Ecuaciones (7.2), (7.3) y (7.10), se puede ver que RMSE y el error estándar de la media son iguales solo para un observable aleatorio de media cero (donde no hay sesgo). Las medias de las muestras se distribuyen aproximadamente de manera normal cuando el tamaño de la muestra es 30 o más. Si se seleccionan todas las posibles muestras de tamaño $n \\geq 30$ de una población dada, entonces las diversas medias de muestra se distribuyen aproximadamente de manera normal, teniendo un promedio que es igual a la media de la población con un error estándar que es igual a la desviación estándar de la población dividida por la raíz cuadrada del tamaño de la muestra.\n",
    "\n",
    "El valor medio o esperado para un caso de observable aleatorio continuo puede darse por\n",
    "\n",
    "$$\n",
    "\\mu = E(X) = \\int_{-\\infty}^{\\infty} x f(x) dx\n",
    "$$\n",
    "\n",
    "donde $f(x)$ desde el infinito negativo hasta el infinito positivo proporciona la distribución de probabilidad para el\n",
    "\n",
    " observable aleatorio dado. En las Ecuaciones (7.5) y (7.7), uno necesita conocer los valores posibles del observable aleatorio dado ($X$) y las probabilidades que corresponden a cada uno de estos valores para determinar la media. Como se puede ver, las expectativas están interesadas en los posibles resultados de un evento que aún no ha ocurrido. Una media aritmética o una media de muestra es un caso especial de expectativa en el que las probabilidades asociadas de los valores de la cantidad aleatoria son las mismas. Esencialmente, las mismas fórmulas se utilizan para determinar la media de muestra y la varianza de la muestra, excepto que una está interesada en los resultados reales de $m$ eventos que ya habían ocurrido en el caso de la media de muestra y la varianza de la muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894f1dbc-d18d-4d02-a367-0d665275e57f",
   "metadata": {},
   "source": [
    "### Ejemplo 7.1\n",
    "\n",
    "Un observable aleatorio discreto $Y$ tiene una distribución de probabilidad $p(y)$ y un valor esperado $E(Y)$, que puede representarse como:\n",
    "\n",
    "$$ E(Y) = \\sum_{i=1}^{m} y p(y) $$\n",
    "\n",
    "con los elementos sumados sobre todos los valores posibles $y$ del observable aleatorio $Y$. Deje que el observable aleatorio $Y$ sea el número de caras al lanzar dos monedas simultáneamente; la moneda número 1 tiene caras como (H1, T1) y la moneda número 2 tiene caras como (H2, T2). Lanzar dos monedas al mismo tiempo probablemente producirá una de las siguientes cuatro combinaciones diferentes: H1H2, H1T2, T1H2 o T1T2. Si $y$ es el número de caras observadas en cada caso, la distribución de probabilidad de lanzar dos monedas simultáneamente se puede dar como se muestra en la Tabla 7.1. En la tabla se puede ver que ninguna cara en un lanzamiento ($y = 0$) probablemente ocurra una vez cada cuatro veces, una cara en un lanzamiento ($y = 1$) probablemente ocurra dos veces cada cuatro veces, y dos caras en un lanzamiento ($y = 2$) probablemente ocurra una vez cada cuatro veces.\n",
    "\n",
    "### Tabla 7.1: Distribución de probabilidad de lanzar dos monedas.\n",
    "\n",
    "| $ y $ | $ p(y) $ | Comentarios |\n",
    "|---------|------------|-------------|\n",
    "| 0       | 1/4        | Cuando no se espera ninguna cara (H1 o H2) |\n",
    "| 1       | 1/2        | Cuando se espera solo una cara (H1 o H2) |\n",
    "| 2       | 1/4        | Cuando se esperan dos caras (H1 y H2) |\n",
    "\n",
    "Si el lanzamiento de dos monedas simultáneamente se realizara 4,000,000 veces, ¿cuál sería el valor promedio de $ y $?\n",
    "\n",
    "### Solución:\n",
    "\n",
    "De la Tabla 7.1 y la Ecuación (7.9),\n",
    "\n",
    "$$ E(y) = \\left(\\frac{1}{4}(0) + \\frac{1}{2}(1) + \\frac{1}{4}(2)\\right) \\rightarrow 1 $$\n",
    "\n",
    "Esto puede interpretarse como que se esperaría una cara en promedio. Como se puede ver, el lanzamiento real de las dos monedas no está involucrado en el cálculo realizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6040c972-a9cf-4bab-985c-40c6d176a556",
   "metadata": {},
   "source": [
    "### 7.3 Estimación de Parámetros de la Población\n",
    "\n",
    "Los tipos comunes de parámetros de población que son de interés en este capítulo son la media de la población ($\\mu$) y la desviación estándar de la población ($\\sigma$), que se estiman a partir de datos muestrales como la media muestral ($\\bar{x}$) y la desviación estándar muestral ($s$), respectivamente. La desviación estándar muestral es una aproximación suficientemente buena de la desviación estándar de la población ($\\sigma$) si el tamaño de la muestra es lo suficientemente grande. El criterio citado frecuentemente para el tamaño requerido de una muestra, en inferencias estadísticas, es que un tamaño mayor a 30 constituye una muestra grande. La media de la población ($\\mu$) puede estimarse de dos maneras: como estimación puntual y como estimación por intervalo.\n",
    "\n",
    "#### 7.3.1 Estimación Puntual de la Media de la Población\n",
    "\n",
    "Una **estimación puntual** es una estimación de un parámetro de la población expresada como un valor único con una precisión de estimación indicada a una cierta probabilidad; por ejemplo, un ángulo promedio dado como 60°30'27\" es una estimación puntual. La estimación puntual de la media de la población proporciona una única estimación de la media de la población ($\\mu$) como un valor específico ($\\bar{x}$) conocido como media muestral. Sin embargo, este valor no revela inmediatamente la incertidumbre de la estimación hasta que se proporciona la probabilidad de error máximo de la estimación. La probabilidad está involucrada porque la incertidumbre (precisión o desviación estándar) de la estimación está involucrada. El error de la estimación puntual ($\\bar{x}$) puede darse como:\n",
    "\n",
    "$$\n",
    "\\varepsilon = \\bar{x} - \\mu \\tag{7.13}\n",
    "$$\n",
    "\n",
    "donde $\\varepsilon$ puede considerarse como una medida de la precisión de $\\bar{x}$ como una estimación de $\\mu$. A partir de la distribución muestral, la puntuación-z para la estadística de la media puede darse como:\n",
    "\n",
    "$$\n",
    "z = \\frac{\\bar{x} - \\mu}{\\text{SE}} \\tag{7.14}\n",
    "$$\n",
    "\n",
    "donde el error estándar es $\\text{SE} = \\sigma / \\sqrt{n}$ para un caso en que el tamaño de la muestra ($n$) sea mayor a 30 con una desviación estándar de la población conocida ($\\sigma$) o $\\text{SE} = s / \\sqrt{n}$ en el caso en que la desviación estándar de la población sea desconocida pero se determine la desviación estándar muestral ($s$). La estadística-t (para un caso en que el tamaño de la muestra sea menor o igual a 30) puede darse como:\n",
    "\n",
    "$$\n",
    "t = \\frac{\\bar{x} - \\mu}{\\text{SE}} \\tag{7.15}\n",
    "$$\n",
    "\n",
    "donde SE se determina según si $\\sigma$ o $s$ es conocido, como se discutió anteriormente. A una probabilidad de $1 - \\alpha$, los valores críticos de $z$ y $t$ (para el caso bilateral) serán $z_{1-\\alpha/2}$ y $t_{1-\\alpha/2, \\text{df}}$, respectivamente, y df es el número de grados de libertad. A partir de las ecuaciones (7.13) a (7.15), el error de muestreo ($\\varepsilon = |\\bar{x} - \\mu|_{1 - \\alpha}$) de la estimación (o lo que a veces se conoce como margen de error) a una probabilidad de $1 - \\alpha$ puede expresarse como:\n",
    "\n",
    "$$\n",
    "|\\bar{x} - \\mu|_{1 - \\alpha} = (\\text{SE}) k_p \\tag{7.16}\n",
    "$$\n",
    "\n",
    "donde $k_p = z_{p = 1 - \\alpha/2}$ o $k_p = t_{p = 1 - \\alpha/2, \\text{df}}$ dependiendo de si se cumple la condición en la ecuación (7.14) o (7.15), respectivamente. $k_p$ puede considerarse como un factor para escalar la SE a un nivel de probabilidad $p$ apropiado. En la ecuación (7.16), la probabilidad de que $|\\bar{x} - \\mu|_{1 - \\alpha}$ sea menor que (\\text{SE}) $k_p$ es $1 - \\alpha$. La ecuación (7.16) puede utilizarse para estimar el error máximo de la estimación puntual. En este caso, $\\varepsilon = (\\text{SE}) k_p$ a la probabilidad dada de $p = 1 - \\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9150af39-2d13-401a-a51f-80a8d2ddb0bf",
   "metadata": {},
   "source": [
    "#### 7.3.2 Estimación por Intervalo de la Media de la Población\n",
    "\n",
    "Una **estimación por intervalo** de un parámetro de población se expresa mediante dos números entre los cuales se puede considerar que se encuentra el parámetro. Por ejemplo, el ángulo promedio dado como 60°30'27\" ± 2\" representa una estimación por intervalo con ± 2\" indicando la precisión de la estimación. Debe mencionarse que el uso de la desviación estándar para expresar la incertidumbre funciona bien cuando se involucran tamaños de muestra grandes (más de 30); los intervalos son más válidos cuando se involucran tamaños de muestra pequeños. La **estimación por intervalo** coloca la media de la población ($\\mu$) dentro de un intervalo y estipula un grado de confianza como una medida de la incertidumbre de la estadística estimada (la media). La estimación por intervalo revela inmediatamente la incertidumbre asociada con la estimación de la media de la población ($\\mu$). El **intervalo de confianza** se usa para describir la cantidad de incertidumbre (o la región de duda) asociada con una estimación muestral de un parámetro de población.\n",
    "\n",
    "La **estimación del intervalo de confianza** se usa en esta sección para significar lo mismo que la estimación de la región de confianza unidimensional. Un intervalo de confianza es, por lo tanto, una región aleatoria que contiene la estadística con cierto nivel de confianza ($1 - \\alpha$) o ($1 - \\alpha$)% asociado con él para que el verdadero valor del parámetro pueda afirmarse que cae entre los dos puntos (**límites de confianza**) del intervalo. Por ejemplo, si $\\alpha = 0.05$, el intervalo de confianza del 95% es el intervalo en el cual se tiene un 95% de confianza de que el verdadero valor de la media o la diferencia entre dos medias caerá. Estrictamente hablando, un intervalo de confianza no debe interpretarse en el sentido de que la media de la población ($\\mu$) caería dentro de los límites con una probabilidad del 95%; más bien, se entiende que si uno establece muchos intervalos de confianza del 95% para muchas muestras diferentes, entonces el 95% del tiempo $\\mu$ caería dentro de los límites del intervalo de confianza. En este caso, la declaración de probabilidad no es sobre la validación del intervalo de confianza, sino sobre la validación del proceso que lleva a la construcción del intervalo de confianza. Recordando que los parámetros de la población ($\\mu$, $\\sigma$) son cantidades con valores constantes (o fijos), no se pueden tratar nuevamente las cantidades como variables o estadísticas. Se necesitan tres piezas de información para construir un intervalo de confianza, como las siguientes:\n",
    "\n",
    "- Un nivel de confianza ($1 - \\alpha$) o un nivel de significancia ($\\alpha$).\n",
    "- Estadística muestral ($\\bar{x}$).\n",
    "- Error de muestreo (o margen de error) de la estadística dada en la Ecuación (7.16).\n",
    "\n",
    "Los límites del intervalo de confianza pueden definirse entonces como sigue:\n",
    "\n",
    "$$\n",
    "\\text{Límites del intervalo de confianza} = \\text{estadística muestral} \\pm \\text{margen de error} \\tag{7.17}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Margen de error} = \\text{valor crítico} \\times \\text{desviación estándar muestral} \\tag{7.18}\n",
    "$$\n",
    "\n",
    "donde el margen de error se considera como la incertidumbre en el intervalo de confianza. Este intervalo de confianza puede construirse como sigue:\n",
    "\n",
    "$$\n",
    "\\mu = \\bar{x} \\pm b \\tag{7.19}\n",
    "$$\n",
    "\n",
    "o\n",
    "\n",
    "$$\n",
    "\\bar{x} - b < \\mu < \\bar{x} + b \\tag{7.20}\n",
    "$$\n",
    "\n",
    "donde $b$ (el margen de error de la estimación) se determina en base al nivel de confianza seleccionado ($1 - \\alpha$) y a si la desviación estándar de la población $\\sigma$ es conocida, como se discutió en la Sección 7.3.1. Debe notarse que siempre que se involucra un problema de construcción de intervalos, uno está tratando con problemas bilaterales, ya que el intervalo sólo tiene sentido cuando se involucran dos puntos, de ahí la prueba bilateral. Con respecto al intervalo, se puede decir que uno está seguro con probabilidad ($1 - \\alpha$) de que el verdadero valor $\\mu$ caerá dentro de los límites de confianza; algunos libros usan $\\leq$ y $\\geq$, pero < y > se usan en este libro ya que redondear errores en cálculos, tablas de distribución y elegir el nivel de significancia hará que el signo igual sea sin sentido. Con respecto a un intervalo de confianza, se puede afirmar que la probabilidad de que un valor verdadero $\\mu$ caiga dentro de la región de confianza es ($1 - \\alpha$), lo que puede expresarse matemáticamente como:\n",
    "\n",
    "$$\n",
    "P(\\bar{x} - b < \\mu < \\bar{x} + b) = 1 - \\alpha \\tag{7.21}\n",
    "$$\n",
    "\n",
    "Dado que la media de la población $\\mu$ no se conoce, el intervalo creado basado en la media muestral como se muestra en la Ecuación (7.21) no es una garantía de que uno sabrá si $\\mu$ está realmente incluido dentro del intervalo calculado. Sin embargo, uno puede decir que si los intervalos se basan en una probabilidad de $1 - \\alpha$, y si uno obtiene un gran número de muestras, uno esperaría que $\\mu$ caiga dentro de los intervalos $1 - \\alpha$% del tiempo. Debe notarse que uno no puede decir que la probabilidad es $1 - \\alpha$ y que $\\mu$ caerá dentro de cualquier intervalo particular ya que la probabilidad es una si $\\mu$ cae dentro del intervalo y la probabilidad es cero si no lo hace. Para abordar esto, los estadísticos han ideado un concepto relacionado, llamado **grado de confianza**, que permite hacer declaraciones sobre $\\mu$ dentro de intervalos particulares. El grado de confianza es una medida de cuán seguro está uno de que el intervalo indicado contendrá $\\mu$. Note que los extremos del intervalo de confianza se llaman **límites de confianza** y la diferencia entre los límites superior e inferior es el **ancho del intervalo de confianza**. Así como la precisión de la estimación para una estimación puntual aumenta con un aumento en la probabilidad, también el ancho del intervalo de confianza aumenta con un aumento en el grado de confianza; cuanto más amplio el intervalo, más seguro puede estar de que el intervalo contendrá $\\mu$.\n",
    "\n",
    "Los intervalos de confianza pueden construirse generalmente a partir de las Ecuaciones (7.19) y (7.20) como sigue:\n",
    "\n",
    "$$\n",
    "\\mu = \\bar{x} \\pm (\\text{SE}) k_p \\tag{7.22}\n",
    "$$\n",
    "\n",
    "o\n",
    "\n",
    "$$\n",
    "\\bar{x} - (\\text{SE}) k_p < \\mu < \\bar{x} + (\\text{SE}) k_p \\tag{7.23}\n",
    "$$\n",
    "\n",
    "donde $b = (\\text{SE}) k_p$, $k_p = z_{p = 1 - \\alpha/2}$ cuando el tamaño de la muestra ($n$) es mayor a 30 o la desviación estándar de la población $\\sigma$ es conocida o ambas condiciones son satisfechas y de otra manera, y $k_p = t_{p = 1 - \\alpha/2, \\text{df}}$ con $\\text{df}$ como el número de grados de libertad. En este caso, la SE en las Ecuaciones (7.22) y (7.23) es el error estándar propagado, que puede darse como $\\text{SE} = \\sigma / \\sqrt{n}$ para un caso donde la desviación estándar de la población ($\\sigma$) es conocida o $\\text{SE} = s / \\sqrt{n}$ en el caso donde la desviación estándar de la población ($\\sigma$) es desconocida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8492eea6-f864-4e3b-abbf-ebf18032b1fc",
   "metadata": {},
   "source": [
    "La desviación estándar de la población es desconocida, pero se determina la desviación estándar de la muestra ($s$). Se puede observar en las ecuaciones (7.22) y (7.23) que los intervalos de confianza se vuelven más estrechos a medida que aumenta el número ($n$) de observaciones (o grados de libertad). El valor $z_{1 - \\alpha/2}$ se obtiene de la tabla de distribución normal estándar (donde se proporcionan las áreas bajo la curva normal estándar) y $n$ es el número de observaciones. Se muestra una curva normal estándar en la Figura 7.1, donde las áreas de la curva normal estándar (sombreada) están relacionadas con sus valores $z_p$.\n",
    "\n",
    "El área a la izquierda de $z_p$ (donde $p = 1 - \\alpha$) es la probabilidad de que se alcance un valor menor que $z_p$, que es lo mismo que el nivel de confianza $1 - \\alpha$. El nivel de confianza ($1 - \\alpha$) se puede expresar matemáticamente integrando (o encontrando el área) desde el infinito negativo ($-\\infty$) hasta el punto $z_p$ utilizando la función de densidad normal estándar dada como sigue:\n",
    "\n",
    "$$\n",
    "1 - \\alpha = \\int_{-\\infty}^{z_p} \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2} dz \\quad (7.24)\n",
    "$$\n",
    "\n",
    "De manera similar, el área ($\\alpha$) a la derecha de $z_p$, que es la probabilidad de que se alcance o se supere el valor de $z_p$, se puede obtener matemáticamente integrando desde el punto $z_p$ hasta el infinito positivo ($\\infty$) usando lo siguiente:\n",
    "\n",
    "$$\n",
    "\\alpha = \\int_{z_p}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2} dz \\quad (7.25)\n",
    "$$\n",
    "\n",
    "La integral en la Ecuación (7.24), por ejemplo, se puede determinar utilizando tablas de distribución de probabilidad acumulativa normal estándar o utilizando algún paquete de software, como Microsoft Excel 2013, que proporciona la rutina de distribución de probabilidad NORM.S.DIST ($z_p, TRUE$). Si $z_p = 1.645$ se introduce en la rutina, se obtendrá el valor de $1 - \\alpha = 0.95$. Si $1 - \\alpha$ es conocido, la inversa de la Ecuación (7.24) dará el valor de $z_p$. En lugar de hacer esto matemáticamente, uno puede consultar las tablas de distribución normal estándar para $z_p$ o el Microsoft Excel 2013, que proporciona NORM.S.INV ($p$) para el cálculo inverso. Por ejemplo, si $p = 0.95$ (o $\\alpha = 0.05$), NORM.S.INV (0.95) da $z_p = 1.645$. Recordando que $z$ es simétrico alrededor del centro ($z = 0$), uno notará que los valores de $z$ a la izquierda del centro serán negativos, mientras que aquellos a la derecha del centro serán positivos. Por ejemplo, usando $p = 0.05$ en NORM.S.INV dará $z_p = -1.645$.\n",
    "\n",
    "En una estimación de intervalo de confianza donde el número de observaciones o tamaño de muestra ($n$) es menor o igual a 30, se utilizará el valor de la distribución $t$ de Student como $k_p = t_p = t_{1 - \\alpha/2, df}$ en las Ecuaciones (7.22) y (7.23). En este caso, en lugar de utilizar la distribución normal estándar, el valor $t_{1 - \\alpha/2, df}$ se obtendrá de la tabla de distribución $t$ o de la rutina T.INV($p, df$) de Microsoft Excel 2013 con los grados de libertad (o redundancia) df. La distribución $t$ es similar a la distribución normal, excepto que los grados de libertad son ahora involucrados. Por ejemplo, si $p = 0.95$ y df = 5 se introducen en T.INV ($p, df$), se obtendrá $t_p, df = 2.015$. El resumen del procedimiento de estimación de intervalo para la media de la población se da en la Figura 7.2.\n",
    "\n",
    "**7.3.3 Estimación de Precisión Relativa**\n",
    "\n",
    "La precisión relativa (RP) de una medición dada es la relación entre la precisión de la medición y el valor de la medición en sí. Generalmente, la RP se determina para un nivel de confianza dado, como el nivel de confianza del 95%, y comúnmente se expresa en razón, como 1 : $p$ (ej. 1 : 5000). La RP de una medición al nivel de confianza del 95% se puede dar como sigue:\n",
    "\n",
    "$$\n",
    "RP = 1 : \\frac{\\text{Medición media}}{\\text{Margen de error}} \\quad (7.26)\n",
    "$$\n",
    "\n",
    "En el caso donde el tamaño de muestra es mayor a 30, la RP al nivel de confianza ($1 - \\alpha$) se puede dar como\n",
    "\n",
    "$$\n",
    "RP = 1 : \\frac{\\bar{x}}{(SE)k_p} \\quad (7.27)\n",
    "$$\n",
    "\n",
    "donde $k_p = z_p = 1 - \\alpha/2$. El valor $z_{1 - \\alpha/2}$ se obtiene de la curva de distribución normal: $SE = \\sigma / \\sqrt{n}$ para un caso donde la desviación estándar de la población ($\\sigma$) es conocida o $SE = s / \\sqrt{n}$ en el caso donde la desviación estándar de la población es desconocida pero se determina la desviación estándar de la muestra ($s$). En el caso donde el tamaño de muestra es menor o igual a 30, la RP al nivel de confianza ($1 - \\alpha$) se calculará utilizando la Ecuación (7.27) con $k_p = t_p = 1 - \\alpha/2, df$ y el valor $t_{1 - \\alpha/2, df}$ se obtiene de la curva de distribución $t$ con los grados de libertad (o redundancia) df."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae61574-5365-4556-8cda-70cd052e5395",
   "metadata": {},
   "source": [
    "![Texto alternativo](./m_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5882497e-f247-4f9e-9220-3e21e39503f8",
   "metadata": {},
   "source": [
    "Este diagrama de flujo proporciona una guía para la estimación por intervalos de la media poblacional ($\\mu$) basándose en la media muestral ($\\bar{x}$). Aquí se describen los pasos y las fórmulas involucradas:\n",
    "\n",
    "1. **Determinar la media muestral ($\\bar{x}$):**\n",
    "   - El primer paso es calcular la media de la muestra.\n",
    "\n",
    "2. **Evaluar el tamaño de la muestra ($n$):**\n",
    "   - Si $n > 30$:\n",
    "     - **Asumir que $\\bar{x}$ se distribuye normalmente.**\n",
    "       - Luego, verificar si se conoce la desviación estándar de la población ($\\sigma$):\n",
    "         - **Desviación estándar de la población conocida ($\\sigma$)**:\n",
    "           - Utilizar la fórmula de intervalo de confianza:\n",
    "             $$\n",
    "             \\bar{x} \\pm (SE)z\n",
    "             $$\n",
    "             donde $SE = \\frac{\\sigma}{\\sqrt{n}}$.\n",
    "         - **Desviación estándar de la población desconocida**:\n",
    "           - Utilizar la fórmula de intervalo de confianza:\n",
    "             $$\n",
    "             \\bar{x} \\pm (SE)t\n",
    "             $$\n",
    "             donde $SE = \\frac{s}{\\sqrt{n}}$, siendo $s$ la desviación estándar muestral y $t$ el valor crítico de la distribución t de Student.\n",
    "   - Si $n < 30$:\n",
    "     - Verificar si la población está normalmente distribuida:\n",
    "       - **Si la población está normalmente distribuida**:\n",
    "         - La media muestral $\\bar{x}$ es normalmente distribuida, independientemente de $n$.\n",
    "         - Verificar si se conoce la desviación estándar de la población ($\\sigma$):\n",
    "           - **Desviación estándar de la población conocida ($\\sigma$)**:\n",
    "             - Utilizar la fórmula de intervalo de confianza:\n",
    "               $$\n",
    "               \\bar{x} \\pm (SE)z\n",
    "               $$\n",
    "               donde $SE = \\frac{\\sigma}{\\sqrt{n}}$.\n",
    "           - **Desviación estándar de la población desconocida**:\n",
    "             - Utilizar la fórmula de intervalo de confianza:\n",
    "               $$\n",
    "               \\bar{x} \\pm (SE)t\n",
    "               $$\n",
    "               donde $SE = \\frac{s}{\\sqrt{n}}$.\n",
    "       - **Si la población no está normalmente distribuida**:\n",
    "         - La distribución de $\\bar{x}$ es desconocida y se debe detener la estimación.\n",
    "\n",
    "En resumen, el diagrama de flujo guía el proceso de selección de la fórmula adecuada para la estimación del intervalo de confianza de la media poblacional, dependiendo del tamaño de la muestra y del conocimiento sobre la desviación estándar de la población."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd32fc15-4bc7-47a2-886a-6f79c942f4b1",
   "metadata": {},
   "source": [
    "### 7.3.4 Estimación de Intervalo para la Varianza de la Población\n",
    "\n",
    "De la distribución muestral, la estadística $\\chi^2$ (o estadística de chi-cuadrado) para la varianza muestral $(s^2)$ puede darse como:\n",
    "\n",
    "$$ \\chi^2 = \\frac{(df)s^2}{\\sigma^2} \\tag{7.28} $$\n",
    "\n",
    "El intervalo de confianza para la varianza de la población $(\\sigma)$ en el caso de un problema de dos colas con una observación involucrada puede darse como sigue (refiérase a la Figura 7.3 para usar esta ecuación):\n",
    "\n",
    "$$ \\chi^2_{1-\\alpha/2, df} < \\chi^2 < \\chi^2_{\\alpha/2, df} \\tag{7.29} $$\n",
    "\n",
    "O sustituyendo la Ecuación (7.28) en la Ecuación (7.29), se puede deducir:\n",
    "\n",
    "$$ \\frac{(df)s^2}{\\chi^2_{\\alpha/2, df}} < \\sigma^2 < \\frac{(df)s^2}{\\chi^2_{1-\\alpha/2, df}} \\tag{7.30} $$\n",
    "\n",
    "donde $ n $ es el número de observaciones\n",
    "\n",
    "$$ \\alpha = \\text{nivel de significancia} $$\n",
    "$$ df = \\text{grados de libertad (por ejemplo, } n - 1 \\text{ para una sola observación)} $$\n",
    "$$ \\sigma = \\text{desviación estándar de la población} $$\n",
    "$$ \\chi^2 = \\text{valor de chi-cuadrado} $$\n",
    "$$ s = \\text{desviación estándar calculada} $$\n",
    "\n",
    "El chi-cuadrado en la Tabla B.3 se basa en $ p $ siendo un área a la izquierda del valor crítico en la distribución. En esta tabla estándar de chi-cuadrado, las áreas (es decir, $ p $) se dan como las áreas a la izquierda del valor crítico. Para buscar, por ejemplo, un área = 1/2 a la izquierda de un valor crítico, tome $ p = 1 - \\alpha/2 $ y luego búsquelo en la tabla. Refiérase a la Figura 7.3 y la Tabla B.3 para valores de chi-cuadrado con $ p $ refiriéndose al área a la izquierda de un valor crítico.\n",
    "\n",
    "Por ejemplo, los valores de chi-cuadrado correspondientes a $\\alpha = 0.010$ en los grados de libertad, df = 4 (en la Figura 7.3) para el caso de dos colas, serán $\\chi^2_{0.01/2, df = 4} = 0.207$ y $\\chi^2_{1-0.01/2, df = 4} = 14.860$ para $ p = 0.005$ y 0.995, respectivamente. Refiérase a la Tabla B.3 y también a la rutina CHISQ.INV(p, df) de Microsoft Excel 2013 para obtener los valores de chi-cuadrado en los valores dados de $ p $ y los grados de libertad $ df $. La relación entre el valor de chi-cuadrado (por ejemplo, $\\chi^2_{0.01/2, df = 4}$) y el nivel de significancia $(\\alpha$ que es el área desde el infinito negativo hasta $ \\chi^2_{0.01/2, df = 4}$) está dada por la ecuación\n",
    "\n",
    "$$ p = 0.01/2 = \\int_{-\\infty}^{\\chi^2} f(x)dx \\tag{7.31} $$\n",
    "\n",
    "Si se considera la distribución de chi-cuadrado con áreas a la derecha de los valores críticos, la integral en la Ecuación (7.31) se realizará desde el valor crítico dado hasta el infinito positivo ($\\infty$) para obtener $ p = \\alpha/2 $. Si se usa una distribución de chi-cuadrado no estándar (aquella que da áreas a la derecha de los valores críticos), se debe usar el siguiente intervalo de confianza (modificado de la Ecuación (7.30)):\n",
    "\n",
    "$$ \\frac{(df)s^2}{\\chi^2_{1-\\alpha, df (\\text{área superior})}} < \\sigma^2 < \\frac{(df)s^2}{\\chi^2_{\\alpha, df (\\text{área superior})}} \\tag{7.32} $$\n",
    "\n",
    "El Microsoft Excel 2013 rutina CHISQ.INV.RT(p, df) da el valor de área superior de la distribución chi-cuadrado (usando el valor de área superior de $ \\alpha $). Sin embargo, para obtener el valor de chi-cuadrado dado en la Figura 7.3, debe usarse la rutina CHISQ.INV(p, df) de Microsoft Excel 2013.\n",
    "\n",
    "### 7.3.5 Estimación de Intervalo para la Razón de Dos Varianzas de Población\n",
    "\n",
    "El intervalo de confianza puede construirse para la razón de dos varianzas de dos poblaciones distribuidas normalmente. Considere dos desviaciones estándar experimentales $ s_1 $ y $ s_2 $ calculadas a partir de dos muestras independientes (Muestra I y Muestra II) de tamaños $ n_1 $ y $ n_2 $, respectivamente, y que las dos muestras (Muestra I y Muestra II) se tomen de dos poblaciones distribuidas normalmente con desviaciones estándar de población de $ \\sigma_1 $ y $ \\sigma_2 $, respectivamente. De la distribución muestral, el estadístico F para la razón de varianzas muestrales puede darse como\n",
    "\n",
    "$$ F = \\frac{\\frac{s_1^2}{\\sigma_1^2}}{\\frac{s_2^2}{\\sigma_2^2}} \\tag{7.33} $$\n",
    "\n",
    "donde $ F $ se distribuye como distribución de Fisher. Una típica distribución F (Fisher) para un caso de dos colas se da en la Figura 7.4. El intervalo de confianza para la razón de las varianzas de la población $(\\sigma_1^2/\\sigma_2^2)$ puede darse como sigue:\n",
    "\n",
    "$$ F_{\\alpha/2, df_1, df_2} < F < F_{1-\\alpha/2, df_1, df_2} \\tag{7.34} $$\n",
    "\n",
    "o sustituyendo la Ecuación (7.33) en la Ecuación (7.34), se puede deducir:\n",
    "\n",
    "$$ \\frac{s_1^2}{F_{1-\\alpha/2, df_1, df_2}} < \\frac{\\sigma_1^2}{\\sigma_2^2} < \\frac{s_1^2}{F_{\\alpha/2, df_1, df_2}} \\tag{7.35} $$\n",
    "\n",
    "donde $ df_1 $ y $ df_2 $ son los grados de libertad para calcular los valores críticos de F. La relación expresada en la Ecuación (7.36) puede probarse mediante el cambio de área dado con los grados de libertad y usando $ p = 1 - \\alpha $ en lugar de $ p = \\alpha $. Por ejemplo, usando la Tabla B.4, el valor F a $ df_1 = 8, df_2 = 4, p = 0.95 $ (cambiando los valores de $ df_1 $ y $ df_2 $ y usando 1 - $\\alpha$ en lugar de $\\alpha$) será 0.166; el recíproco de este valor F es 0.166, lo mismo que el valor obtenido arriba para el valor F en $ df_1 = 4, df_2 = 8$ y $ \\alpha = 0.05 $.\n",
    "\n",
    "Otros útiles extractos de tablas estadísticas están proporcionados en los apéndices, tales como Extractos del Nomograma de Baarda (Baarda 1968) en el Apéndice A, Tablas Estadísticas Básicas (compiladas por el autor) en el Apéndice B, y la Tabla de Distribución Tau de Pope (1976), que fue computada usando códigos de computadora Visual Basic por el autor, en el Apéndice C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7e8823-036d-42b0-8903-ab788e301661",
   "metadata": {},
   "source": [
    "### 7.4 Comentarios Generales sobre la Estimación de Intervalos de Confianza\n",
    "\n",
    "Los intervalos de confianza construidos para los parámetros de población de las observaciones de encuestas pueden interpretarse mejor si se comprenden los conceptos de intervalos de confianza. Los siguientes comentarios son para ayudar en esta dirección:\n",
    "\n",
    "1) Los intervalos de confianza se crean para los parámetros de población y no para las estadísticas de muestra. Cabe señalar que el parámetro de población de una variable u observable es un valor constante, mientras que las estadísticas de muestra son variables aleatorias (que pueden tener muchos valores dependiendo de las condiciones de su determinación). Cada vez que se aplica un método particular para construir un intervalo de confianza a una nueva muestra, se genera un nuevo intervalo que puede ser diferente de los otros intervalos anteriores creados para muestras similares. En este caso, sería incorrecto, por ejemplo, decir que la probabilidad de que una verdadera media se encuentre en un intervalo dado es del 95%, ya que el valor verdadero es fijo y siempre tendrá una probabilidad del 50% de estar dentro del intervalo dado o no estarlo.\n",
    "\n",
    "2) Considerando el caso de un intervalo de confianza del 95%, se puede decir que si un encuestador tomara 100 muestras del conjunto de mediciones de la misma observación, el 95% de las veces, la verdadera observación caerá dentro de los intervalos creados. Esto también puede expresarse de manera diferente al decir que el encuestador está un 95% seguro de que el valor verdadero caerá dentro de los intervalos creados. Esta es una declaración objetiva sobre cómo se crean los intervalos en lugar de la declaración anterior, que considera el valor verdadero fijo pero desconocido, dependiendo de los valores aleatorios de la muestra. En este caso, el sujeto de la declaración de probabilidad está realmente en el intervalo y no en los parámetros desconocidos que se investigan. En realidad, la idea de probabilidad no tendría sentido en este caso, ya que el valor verdadero caerá dentro de los intervalos o no (con un 50% de probabilidad). Esto explica los conceptos de que un intervalo de confianza se refiere solo a la aleatoriedad que resulta en la creación del intervalo y no al intervalo real en sí mismo; esto es decir que no es que el intervalo particular contenga el verdadero valor con un 95% de probabilidad, sino que el intervalo construido de esa manera particular contendrá el valor verdadero el 95% de las veces. En la práctica, el encuestador tomará una sola muestra y construirá un solo intervalo de confianza. Ese único intervalo de confianza puede o no contener el verdadero parámetro de la población, pero el encuestador solo puede decir que están un 95% seguros de que su único intervalo capturará el parámetro de la población.\n",
    "\n",
    "### 7.5 Elipse de Error y Distribución Normal Bivariada\n",
    "\n",
    "La función de densidad para un caso unidimensional se expresa en la Ecuación (3.1), donde la desviación estándar ($\\sigma$) puede verse como una barra de error alrededor de la media. La función de densidad de multivariada de $n$ dimensiones (para múltiples observables) de la distribución normal se da a partir de la Ecuación (3.19) como\n",
    "\n",
    "$$ f(X) = \\frac{1}{(2\\pi)^{n/2} \\sqrt{\\det(\\Sigma)}} e^{-\\frac{1}{2}(X-\\mu)^T \\Sigma^{-1} (X-\\mu)} \\tag{7.38} $$\n",
    "\n",
    "donde $ X $ es un vector de los valores medidos de los observables, $\\Sigma$ es una matriz de covarianza $n \\times n$ del vector de los valores medidos, $\\mu$ es el vector de los valores verdaderos de los observables, $ n $ es el número de observaciones (no el número de observables) considerado en el caso multivariado, $(2\\pi)^{n/2} \\sqrt{\\det(\\Sigma)}$ es la constante de normalización que hace que el volumen bajo la distribución normal multivariada sea igual a uno, y $\\det(\\Sigma)$ es el determinante de la matriz de covarianza $\\Sigma$. La matriz de covarianza $\\Sigma$ puede considerarse como un elipsoide de error alrededor de las medias de los observables involucrados. La superficie de la función de densidad de probabilidad normal bivariada bidimensional expresada por la Ecuación (7.38) se da en la Figura 7.5. En esta figura, cuando un plano paralelo al plano $x, y$ corta la superficie de densidad en un nivel dado, se forma una elipse de intersección. La elipse formada es la gráfica de contorno de la línea de densidad de probabilidad constante; una serie de elipses (o contornos) se forman correspondientes a diferentes alturas de la función de probabilidad. Los contornos así trazados serán líneas de igual altitud (igual probabilidad) en un mapa topográfico. La ecuación para la elipse de intersección en el caso bivariado bidimensional está determinada al requerir que el exponente en la función de densidad en la Ecuación (7.38) sea una constante ($k^2$). Este exponente, que representa una familia de elipses de error centradas en las medias de las variables, es una forma cuadrática de\n",
    "\n",
    "$$ k^2 = (X-\\mu)^T \\Sigma^{-1} (X-\\mu) \\tag{7.39} $$\n",
    "\n",
    "que se distribuye como chi-cuadrado ($\\chi^2$) con dos grados de libertad (para el caso bidimensional). La Ecuación (7.39) es simplemente la suma de cuadrados de datos de muestra que se distribuyen normalmente, lo que produce otra estadística conocida como la estadística chi-cuadrado $\\chi^2$. Puede demostrarse que la probabilidad es $1-\\alpha$ y que el valor de un vector aleatorio caerá dentro del elipsoide definido por la Ecuación (7.38); esta probabilidad puede expresarse como\n",
    "\n",
    "$$ P \\left\\{ k^2 \\leq \\chi^2_{df=n, 1-\\alpha} \\right\\} = 1-\\alpha \\tag{7.40} $$\n",
    "\n",
    "o\n",
    "\n",
    "$$ P \\left\\{ (X-\\mu)^T \\Sigma^{-1} (X-\\mu) < \\chi^2_{df=n, 1-\\alpha} \\right\\} = 1-\\alpha \\tag{7.41} $$\n",
    "\n",
    "donde $ \\alpha $ es el nivel de significancia (que representa el área de cola inferior de la distribución chi-cuadrado), $ df $ es el número de grados de libertad, $ n $ es el número de variables, y $\\chi^2_{df=n, 1-\\alpha}$ es el valor chi-cuadrado en el nivel de significancia de $\\alpha$. La forma cuadrática en la Ecuación (7.39) es una distancia estadística cuadrada de $ X $ desde $\\mu$ teniendo en cuenta el hecho de que las varianzas de las $ n $ variables pueden ser diferentes y pueden estar correlacionadas. Los valores $ X $ que producen una altura constante para la elipse de densidad de probabilidad normalmente forman elipsoides centrados en $\\mu$. Para el caso bidimensional, la Ecuación (7.39) produce una elipse que se centra en el punto correspondiente a las medias $(\\mu_x, \\mu_y)$ de los observables $X$. Para una distribución bivariada, por ejemplo, $ f(X) $ representa la superficie de probabilidad con el volumen total delimitado por la superficie y el plano $ x-y $ igual a uno.\n",
    "\n",
    "Lo siguiente puede considerarse como los elementos típicos involucrados en la función $ f(X) $ en la Ecuación (7.38):\n",
    "\n",
    "$$ X = \\begin{bmatrix} x \\\\ y \\end{bmatrix} \\quad \\mu = \\begin{bmatrix} \\mu_x \\\\ \\mu_y \\end{bmatrix} \\quad \\text{y} \\quad \\Sigma = \\begin{bmatrix} \\sigma^2_1 & \\sigma_{12} \\\\ \\sigma_{21} & \\sigma^2_2 \\end{bmatrix} \\tag{7.42} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a6d5be-af46-4218-929c-bc86919f248a",
   "metadata": {},
   "source": [
    "La matriz de covarianza $2 \\times 2$ $\\Sigma$ se diagonaliza primero para producir los valores propios máximos y mínimos $\\lambda_1$ y $\\lambda_2$, respectivamente, con sus correspondientes vectores propios. Los vectores propios, que definen los ejes alineados con los ejes mayor y menor de la elipse de error, producen el sistema de coordenadas rotadas $(u, v)$ de modo que las variables aleatorias en las direcciones de estos ejes no están correlacionadas. La Ecuación (7.39), para la distribución de probabilidad bivariada centrada en $(\\mu_x, \\mu_y)$, se puede dar como\n",
    "\n",
    "$$ \\left( \\frac{x - \\mu_x}{\\sqrt{\\lambda_1}} \\right)^2 + \\left( \\frac{y - \\mu_y}{\\sqrt{\\lambda_2}} \\right)^2 = k^2 \\tag{7.43} $$\n",
    "\n",
    "que puede relacionarse con la ecuación usual de una elipse centrada en un origen $(u = 0, v = 0)$, dada como\n",
    "\n",
    "$$ \\frac{u^2}{a^2} + \\frac{v^2}{b^2} = 1 \\tag{7.44} $$\n",
    "\n",
    "con $u$ y $v$ representando las direcciones de los vectores propios con el valor del eje mayor $(a)$ y el valor del eje menor $(b)$ de la elipse, dados, respectivamente, como sigue:\n",
    "\n",
    "$$ a = k \\sqrt{\\lambda_1} \\tag{7.45} $$\n",
    "$$ b = k \\sqrt{\\lambda_2} \\tag{7.46} $$\n",
    "\n",
    "donde $k$ es la escala de la elipse, representando un nivel de confianza elegido. De la Ecuación (7.40), el valor marginal de $k$ se puede dar de la siguiente manera:\n",
    "\n",
    "$$ k = \\sqrt{\\chi^2_{df=n, 1-\\alpha}} \\tag{7.47} $$\n",
    "\n",
    "La elipse de error representada por las Ecuaciones (7.43) y (7.44) se muestra en la Figura 7.6 con $u$ y $v$ representando las direcciones definidas por los vectores propios correspondientes.\n",
    "\n",
    "En el caso donde el vector de valores verdaderos $\\mu$ de los observables y su matriz de covarianza correspondiente $\\Sigma$ no están disponibles, se pueden usar los valores estimados de los observables $\\bar{X}$ y la matriz de covarianza estimada $C$ en su lugar, en la Ecuación (7.39) como sigue:\n",
    "\n",
    "$$ k^2 = (X - \\bar{X})^T C^{-1} (X - \\bar{X}) \\tag{7.48} $$\n",
    "\n",
    "donde todos los valores del vector $X$ que satisfacen la Ecuación (7.48) definen una elipse con los ejes en las direcciones de los vectores propios de $C$ y las longitudes de los ejes definidas por la raíz cuadrada de los valores propios correspondientes. Dado que los valores de las cantidades en la Ecuación (7.48) son los siguientes:\n",
    "\n",
    "$$ X = \\begin{bmatrix} x \\\\ y \\end{bmatrix}, \\quad \\bar{X} = \\begin{bmatrix} \\bar{x} \\\\ \\bar{y} \\end{bmatrix}, \\quad y \\quad C = \\begin{bmatrix} \\lambda_1 & \\\\ & \\lambda_2 \\end{bmatrix} \\tag{7.49} $$\n",
    "\n",
    "donde $\\lambda_1$ y $\\lambda_2$ son los valores propios de la matriz de covarianza $C$ (cuando está diagonalizada), la Ecuación (7.48) se puede expresar de la Ecuación (7.43) como sigue:\n",
    "\n",
    "$$ \\left( \\frac{x - \\bar{x}}{\\sqrt{\\lambda_1}} \\right)^2 + \\left( \\frac{y - \\bar{y}}{\\sqrt{\\lambda_2}} \\right)^2 = k^2 \\tag{7.50} $$\n",
    "\n",
    "lo que representa la ecuación de una elipse bidimensional centrada en el punto $(\\bar{x}, \\bar{y})$ con los valores del eje mayor y menor expresados por las Ecuaciones (7.45) y (7.46), respectivamente, donde $\\alpha$ es el nivel de significancia y $df = 2$ es el número de grados de libertad, que es 2 para dos dimensiones. La Figura 7.6 representa una línea de gráfico de contorno (contorno iso-densidad) que denota el conjunto de puntos para los cuales los valores de $x$ y $y$ dan el mismo valor para la función de densidad $f(X)$ como se define por el contorno. Este contorno se da para un valor fijo de $k$, que define una probabilidad constante y centrada en $(\\bar{x}, \\bar{y})$. Varios valores de $k^2$ en la Ecuación (7.43) producirán una familia de elipses concéntricas (en diferentes secciones transversales de la función de densidad de probabilidad con las intersecciones en varios niveles de las alturas de la superficie). Las Ecuaciones (7.43) y (7.50) se convertirán en las ecuaciones de elipses de error estándar si el valor de $k$ es uno. Dada la probabilidad $p$ y la dimensión o grados de libertad $(df)$, la rutina de software Microsoft Excel 2013 CHISQ.INV(p, df) se puede usar para determinar los valores equivalentes de chi-cuadrado $\\chi^2_{p, df}$ y los valores de $k$ como se muestra en la Tabla 7.2 (para el nivel de significancia $\\alpha$ siendo el área de la cola inferior).\n",
    "\n",
    "Dada la dimensión o grados de libertad $(df)$ y la constante $(k)$, la rutina de software Microsoft Excel 2013 CHISQ.DIST($\\chi^2, df, TRUE$) se puede usar para determinar el valor de probabilidad equivalente $(p)$ como se muestra en la Tabla 7.3 (para el nivel de significancia $\\alpha$ siendo el área de la cola inferior).\n",
    "\n",
    "**Tabla 7.2** Valores de chi-cuadrado y $k$ en varios valores de probabilidad y dimensiones.\n",
    "\n",
    "| p       | df | $\\chi^2_{p, df}$ | k                  | df | $\\chi^2_{p, df}$ | k                |\n",
    "|---------|----|--------------------|--------------------|----|--------------------|------------------|\n",
    "| 0.3935  | 2  | 1.0000             | 1.0000             | 3  | 1.8389             | 1.3561           |\n",
    "| 0.5000  | 2  | 1.3863             | 1.1774             | 3  | 2.3660             | 1.5382           |\n",
    "| 0.9000  | 2  | 4.6052             | 2.1460             | 3  | 6.2514             | 2.5003           |\n",
    "| 0.9500  | 2  | 5.9915             | 2.4477             | 3  | 7.8147             | 2.7955           |\n",
    "| 0.9900  | 2  | 9.2103             | 3.0349             | 3  | 11.3449            | 3.3682           |\n",
    "\n",
    "**Tabla 7.3** Valores de probabilidad en varios valores de $k$ y dimensiones.\n",
    "\n",
    "| k       | $\\chi^2_{p, df} = k^2$ | df | p        | df | p        |\n",
    "|---------|---------------------------|----|----------|----|----------|\n",
    "| 0.5000  | 0.2500                    | 2  | 0.1175   | 3  | 0.0309   |\n",
    "| 1.0000  | 1.0000                    | 2  | 0.3935   | 3  | 0.1987   |\n",
    "| 2.0000  | 4.0000                    | 2  | 0.8647   | 3  | 0.7385   |\n",
    "| 2.4477  | 5.9915                    | 2  | 0.9500   | 3  | 0.8880   |\n",
    "| 3.0000  | 9.0000                    | 2  | 0.9889   | 3  | 0.9707   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004d3b4d-1b5d-4650-9570-328b8eaf3702",
   "metadata": {},
   "source": [
    "### 7.6 Elipses de Error para Parámetros Bivariados\n",
    "\n",
    "Los parámetros bivariados son cantidades que están asociadas con dos dimensiones, tales como las ubicaciones de puntos (involucrando coordenadas $x, y$). La medida inmediata de la precisión de tales cantidades, como las coordenadas ajustadas de un punto, generalmente está relacionada con la matriz de covarianza de las coordenadas ajustadas de ese punto. Suponga que la matriz de covarianza de las coordenadas ajustadas $\\hat{p}$ de un punto (usando la matriz de covarianza en bloques $2 \\times 2$ correspondiente al punto) se da como sigue:\n",
    "\n",
    "$$ C_{\\hat{p}} = \\begin{bmatrix} s_{xx}^2 & s_{xy} \\\\ s_{xy} & s_{yy}^2 \\end{bmatrix} \\tag{7.51} $$\n",
    "\n",
    "donde las desviaciones estándar (o precisiones) de las coordenadas ajustadas $\\hat{x}$ y $\\hat{y}$ son $s_{xx}$ y $s_{yy}$, respectivamente, y $s_{xx}$ y $s_{xy}$ son las covarianzas de las coordenadas ajustadas, que son iguales entre sí en el caso de una matriz de covarianza simétrica. Si el factor de varianza a priori de peso unitario $(\\sigma_0^2)$ es desconocido pero se supone igual a 1, un nuevo valor $(s_0^2)$ llamado factor de varianza a posteriori de peso unitario debe calcularse y usarse para escalar el cofactor de las coordenadas ajustadas para obtener una matriz de covarianza más realista de las coordenadas ajustadas. En la práctica, es común mostrar la precisión de una red mediante su elipse de error estándar bidimensional de punto $\\textit{elipses de error estándar}$ o $\\textit{elipses de error de confianza}$. Las elipses de error estándar son las generalizaciones de las desviaciones estándar utilizadas en los casos unidimensionales, mientras que las elipses de error de confianza son el equivalente bidimensional de los intervalos de confianza utilizados en los casos unidimensionales.\n",
    "\n",
    "Se requieren tres cantidades (parámetros) para definir una elipse de error: el eje mayor $(a)$, el eje menor $(b)$, y el ángulo de orientación del eje mayor $(\\beta)$. Una elipse de error típica se ilustra en la Figura 7.7. Hay dos tipos de elipses de error según donde se sitúan las elipses de error: $\\textit{elipses de error absoluto}$, que se refieren a puntos de estación dados, y $\\textit{elipses de error relativo}$, que se refieren a diferencias de posición de pares de puntos situados entre los pares de puntos de estación que están conectados por observaciones. En general, los tamaños de las elipses de error dependen de la geometría de los puntos de la red, los tipos de cantidades observadas y las desviaciones estándar de las observaciones; no dependen de las correcciones (o residuales) que deben aplicarse a las observaciones, excepto que las elipses de error están escaladas por el factor de varianza a posteriori de peso unitario.\n",
    "\n",
    "#### 7.6.1 Elipses de Error Absoluto\n",
    "\n",
    "Las elipses de error absoluto se utilizan comúnmente como criterios de precisión, especialmente en redes donde solo unos pocos puntos en la red son de interés o deben posicionarse con una precisión especificada, por ejemplo, al definir el punto central de un eje vertical, los otros puntos de control solo existen para permitir que ese punto se posicione con precisión. En el ajuste de mínimos cuadrados paramétricos, donde los puntos de control se fijan para definir el datum para el ajuste, las elipses de error absoluto asociadas aumentan proporcionalmente a la distancia desde esos puntos fijos (lo que significa que los tamaños de las elipses de error absoluto dependen del datum). Una elipse de error absoluto se puede construir para un punto dado usando la matriz de covarianza $(C_{\\hat{p}})$ de las coordenadas ajustadas del punto. Si la matriz de cofactor del punto está estimada, debe multiplicarse por el factor de varianza a posteriori de peso unitario $(s_0^2)$ si el factor de varianza a priori de peso unitario $(\\sigma_0^2 = 1)$ no se conoce bien o las desviaciones estándar de las observaciones no están bien estimadas. Los parámetros de una elipse de error absoluto, por ejemplo, se pueden calcular a partir de la matriz de covarianza en la Ecuación (7.51), dependiendo de si $\\sigma_0^2$ es bien conocido o no. Los pasos para los cálculos son los siguientes:\n",
    "\n",
    "i) Calcule los valores propios $\\lambda_1$ (valor máximo) y $\\lambda_2$ (valor mínimo) de la matriz de covarianza $C_{\\hat{p}}$ de las coordenadas ajustadas del punto resolviendo el determinante de la siguiente ecuación compuesta a partir de la Ecuación (7.51):\n",
    "\n",
    "$$ \\det(C_{\\hat{p}} - \\lambda I) = 0 \\tag{7.52} $$\n",
    "\n",
    "donde $I$ es una matriz de identidad y $\\lambda = [\\lambda_1, \\lambda_2]^T$ es un vector de los valores propios. La solución de la Ecuación (7.52) puede darse como sigue:\n",
    "\n",
    "$$ \\lambda_1 = \\frac{1}{2} \\left( s_{xx}^2 + s_{yy}^2 + z \\right) \\tag{7.53} $$\n",
    "$$ \\lambda_2 = \\frac{1}{2} \\left( s_{xx}^2 + s_{yy}^2 - z \\right) \\tag{7.54} $$\n",
    "\n",
    "donde\n",
    "\n",
    "$$ z = \\left[ (s_{xx}^2 - s_{yy}^2)^2 + 4s_{xy}^2 \\right]^{1/2} \\tag{7.55} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c70ba1-a869-43d5-8bcb-70f55b5b058b",
   "metadata": {},
   "source": [
    "y $s_{xy} = s_{yx}$, lo cual es usual en los cálculos de ajuste. Se puede ver en las Ecuaciones (7.53) y (7.54) que el valor propio $\\lambda_1$ es siempre numéricamente mayor que el valor propio $\\lambda_2$; note también que no es un error tipográfico que la covarianza $s_{xy}$ esté elevada al cuadrado como $s_{xy}^2$ en la Ecuación (7.55) pero no en la matriz de covarianza original en la Ecuación (7.51).\n",
    "\n",
    "ii) Los parámetros de la elipse de error estándar pueden darse como sigue:\n",
    "\n",
    "$$ a_{st} = \\sqrt{\\lambda_1} \\tag{7.56} $$\n",
    "\n",
    "$$ b_{st} = \\sqrt{\\lambda_2} \\tag{7.57} $$\n",
    "\n",
    "$$ \\beta = \\arctan \\left( \\frac{s_{xy}}{\\lambda_1 - s_{xx}^2} \\right) \\tag{7.58} $$\n",
    "\n",
    "donde $a_{st}$, $b_{st}$ y $\\beta$ son los valores del eje mayor, el eje menor y la orientación del eje mayor de la elipse de error estándar, y $\\lambda_1$ y $\\lambda_2$ son los valores propios definidos arriba (con $\\lambda_1$ siempre mayor que $\\lambda_2$).\n",
    "\n",
    "iii) En el caso donde $\\sigma_0^2$ es conocido, los parámetros de la elipse de error de confianza (al nivel de confianza $1-\\alpha$) pueden darse como sigue (usando $\\chi^2_{1-\\alpha, df=2}$ de la distribución chi-cuadrado con grados de libertad $df=2$ y los 2 que representan dos coordenadas asociadas con el punto):\n",
    "\n",
    "$$ a_{(1-\\alpha)100\\%} = a_{st}k \\tag{7.59} $$\n",
    "\n",
    "$$ b_{(1-\\alpha)100\\%} = b_{st}k \\tag{7.60} $$\n",
    "\n",
    "$$ \\beta = \\arctan \\left( \\frac{s_{xy}}{\\lambda_1 - s_{xx}^2} \\right) \\tag{7.61} $$\n",
    "\n",
    "$$ k = \\sqrt{\\chi^2_{1-\\alpha, df=2}} \\tag{7.62} $$\n",
    "\n",
    "donde $a_{(1-\\alpha)100\\%}$, $b_{(1-\\alpha)100\\%}$ y $\\beta$ son los valores del eje mayor, el eje menor y la orientación del eje mayor de la elipse de error de confianza al $1-\\alpha$% de confianza; $k$ es el factor de escala para transformar las elipses estándar en elipses de confianza; $df=2$ es el número de grados de libertad, lo cual representa las dimensiones del sistema de coordenadas involucrado (por ejemplo, 2 para el sistema de coordenadas $x-y$ y 3 para el sistema de coordenadas $x-y-z$); y $\\lambda_1$ y $\\lambda_2$ son los valores propios definidos arriba (con $\\lambda_1$ siempre mayor que $\\lambda_2$). Por ejemplo, $\\chi^2_{1-\\alpha, df=2}$ = 5.99 y 9.21 para $\\alpha = 0.05$ y 0.01, respectivamente.\n",
    "\n",
    "iv) En el caso donde $\\sigma_0^2$ es desconocido y $s_0^2$ se usó para escalar el cofactor de las coordenadas ajustadas, los parámetros de la elipse de error de confianza (al nivel de confianza $1-\\alpha$) pueden darse como sigue. La distribución $F_{1-\\alpha, df_1=2, df_2=n-u}$ se usa con los grados de libertad $df_1=2$, $df_2=n-u$, donde los 2 representan las dos coordenadas asociadas con el punto, $n$ es el número de observaciones y $u$ es el número de parámetros desconocidos (coordenadas) determinados en el ajuste original:\n",
    "\n",
    "$$ a_{(1-\\alpha)100\\%} = a_{st}k \\tag{7.63} $$\n",
    "\n",
    "$$ b_{(1-\\alpha)100\\%} = b_{st}k \\tag{7.64} $$\n",
    "\n",
    "$$ \\beta = \\arctan \\left( \\frac{s_{xy}}{\\lambda_1 - s_{xx}^2} \\right) \\tag{7.65} $$\n",
    "\n",
    "$$ k = \\sqrt{2F_{1-\\alpha, df_1=2, df_2=n-u}} \\tag{7.66} $$\n",
    "\n",
    "donde $a_{(1-\\alpha)100\\%}$, $b_{(1-\\alpha)100\\%}$ y $\\beta$ son los valores del eje mayor, el eje menor y la orientación del eje mayor de la elipse de error de confianza al $1-\\alpha$% de confianza y $\\lambda_1$ y $\\lambda_2$ son los valores propios definidos arriba (con $\\lambda_1$ siempre mayor que $\\lambda_2$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1378e6cf-18aa-4da7-842f-2d2424638dc4",
   "metadata": {},
   "source": [
    "### 7.6.2 Elipses de Error Relativo\n",
    "\n",
    "Las elipses de error relativo se centran tradicionalmente en el punto medio de dos estaciones involucradas. En este caso, la matriz de varianza-covarianza de las diferencias de coordenadas entre los dos puntos se utilizará para construir las elipses de error relativo.\n",
    "\n",
    "Por ejemplo, la elipse de error relativo entre dos estaciones (1 y 2) puede construirse como se muestra en la Figura 7.8. En la figura, la elipse de error relativo se centra en el punto $c$, y hay dos puntos específicos en ambos extremos de la elipse con líneas tangentes a esos puntos que intersectan perpendicularmente la línea 1-2 (en puntos $m_1$ y $m_3$) a la cual se refiere la elipse de error relativo; otra línea perpendicular desde el centro de la elipse de error relativo intersectará la elipse de error en el punto $m_2$. La distancia $cm_1$ o $cm_3$ es la desviación estándar $\\sigma_D$ de la distancia 1-2 (de longitud $D$), y la distancia $cm_2$ es $D\\sigma_\\beta$ para la orientación $\\beta$ con $\\sigma_\\beta$ (en radianes) como la desviación estándar de la orientación, que puede calcularse a partir de las coordenadas ajustadas de los puntos 1 y 2.\n",
    "\n",
    "Para ilustrar la computación de los parámetros de una elipse de error relativo, sea la matriz de varianza-covarianza (del ajuste de mínimos cuadrados) para dos estaciones (1 y 2) dada como sigue:\n",
    "\n",
    "$$ C_{\\hat{x}} = \\begin{bmatrix} s^2_{x_1} & s_{x_1y_1} & s_{x_1x_2} & s_{x_1y_2} \\\\ s_{y_1x_1} & s^2_{y_1} & s_{y_1x_2} & s_{y_1y_2} \\\\ s_{x_2x_1} & s_{x_2y_1} & s^2_{x_2} & s_{x_2y_2} \\\\ s_{y_2x_1} & s_{y_2y_1} & s_{y_2x_2} & s^2_{y_2} \\end{bmatrix} \\tag{7.68} $$\n",
    "\n",
    "Las diferencias de coordenadas entre los dos puntos 1 $(x_1, y_1)$ y 2 $(x_2, y_2)$ pueden darse como sigue:\n",
    "\n",
    "$$ \\Delta x = x_2 - x_1 \\tag{7.69} $$\n",
    "\n",
    "$$ \\Delta y = y_2 - y_1 \\tag{7.70} $$\n",
    "\n",
    "Por la ley de propagación de la varianza-covarianza en las Ecuaciones (7.69) y (7.70), la matriz de covarianza relativa $(C_{\\Delta 12})$ para los dos puntos puede darse como\n",
    "\n",
    "$$ C_{\\Delta 12} = BC_{\\hat{x}}B^T \\tag{7.71} $$\n",
    "\n",
    "donde $B$ es la jacobiana de las Ecuaciones (7.69) y (7.70) con respecto a las coordenadas de los puntos 1 $(x_1, y_1)$ y 2 $(x_2, y_2)$:\n",
    "\n",
    "$$ B = \\begin{bmatrix} \\frac{\\partial \\Delta x}{\\partial x_1} & \\frac{\\partial \\Delta x}{\\partial y_1} & \\frac{\\partial \\Delta x}{\\partial x_2} & \\frac{\\partial \\Delta x}{\\partial y_2} \\\\ \\frac{\\partial \\Delta y}{\\partial x_1} & \\frac{\\partial \\Delta y}{\\partial y_1} & \\frac{\\partial \\Delta y}{\\partial x_2} & \\frac{\\partial \\Delta y}{\\partial y_2} \\end{bmatrix} = \\begin{bmatrix} -1 & 0 & 1 & 0 \\\\ 0 & -1 & 0 & 1 \\end{bmatrix} \\tag{7.72} $$\n",
    "\n",
    "Usando las Ecuaciones (7.68) y (7.72) en la Ecuación (7.71) se obtiene\n",
    "\n",
    "$$ C_{\\Delta 12} = \\begin{bmatrix} s^2_{\\Delta x} & s_{\\Delta x \\Delta y} \\\\ s_{\\Delta x \\Delta y} & s^2_{\\Delta y} \\end{bmatrix} \\tag{7.73} $$\n",
    "\n",
    "donde\n",
    "\n",
    "$$ s^2_{\\Delta x} = s^2_{x_1} + s^2_{x_2} - 2s_{x_1x_2} \\tag{7.74} $$\n",
    "\n",
    "$$ s^2_{\\Delta y} = s^2_{y_1} + s^2_{y_2} - 2s_{y_1y_2} \\tag{7.75} $$\n",
    "\n",
    "$$ s_{\\Delta x \\Delta y} = s_{x_1y_1} + s_{x_2y_2} - s_{x_1y_2} - s_{y_1x_2} \\tag{7.76} $$\n",
    "\n",
    "Para calcular los parámetros de la elipse de error relativo entre los puntos 1 y 2, use la matriz de covarianza relativa $(C_{\\Delta 12})$ en la Ecuación (7.73) como sigue:\n",
    "\n",
    "$$ \\lambda_1 = \\frac{1}{2} \\left( s^2_{\\Delta x} + s^2_{\\Delta y} + R \\right) \\tag{7.77} $$\n",
    "\n",
    "$$ \\lambda_2 = \\frac{1}{2} \\left( s^2_{\\Delta x} + s^2_{\\Delta y} - R \\right) \\tag{7.78} $$\n",
    "\n",
    "$$ \\theta = \\arctan \\left( \\frac{s_{\\Delta x \\Delta y}}{\\lambda_1 - s^2_{\\Delta x}} \\right) \\tag{7.79} $$\n",
    "\n",
    "$$ R = \\left[ \\left( s^2_{\\Delta x} - s^2_{\\Delta y} \\right)^2 + 4s^2_{\\Delta x \\Delta y} \\right]^{1/2} \\tag{7.80} $$\n",
    "\n",
    "donde $\\lambda_1$ y $\\lambda_2$ son los valores propios máximo y mínimo de la matriz de covarianza relativa $C_{\\Delta 12}$ (note también aquí que $\\lambda_1$ es siempre mayor que $\\lambda_2$) y $\\theta$ es la orientación del eje mayor de la elipse de error relativo. Las elipses de error de confianza y las elipses de error estándar pueden obtenerse de manera similar que en el caso de las elipses de error absoluto, sustituyendo los valores propios en las ecuaciones apropiadas en los pasos (ii)-(iv) en la Sección 7.6.1. En comparación con las elipses de error absoluto, debe señalarse que las elipses de error relativo son invariantes respecto a la traslación del datum, mientras que las elipses de error absoluto dependen del datum subyacente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c41e3-a126-4139-9c23-c083be13fdc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
