{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6235226a-9e32-4ef2-9459-3a9f1e0030b5",
   "metadata": {},
   "source": [
    "### Formulación de Ecuaciones de Modelos Paramétricos\n",
    "\n",
    "Un modelo paramétrico es un modelo que relaciona algunas observaciones ajustadas $(\\hat{\\ell}$) con algunos parámetros (ajustados) desconocidos ($\\hat{x}$). Esto se puede representar simbólicamente como:\n",
    "\n",
    "$$ \\hat{\\ell} = f(\\hat{x}) $$\n",
    "\n",
    "En este tipo de modelo, cada una de las mediciones producirá una ecuación que involucre algunos o todos los parámetros especificados sin que otras observaciones intervengan en la ecuación. Por ejemplo, 10 mediciones producirán 10 ecuaciones independientes con la observación (el sujeto) apareciendo solo una vez en cada ecuación. Las ecuaciones paramétricas se formulan para que cuando se sustituyan los valores aproximados de los parámetros desconocidos en las ecuaciones, se obtengan las observaciones derivadas o calculadas; las diferencias entre las observaciones originales y estas observaciones derivadas son los cierres defectuosos. \n",
    "\n",
    "La **redundancia de las ecuaciones de modelos paramétricos** o el **número de grados de libertad** de un ajuste se determina como el número de ecuaciones de modelos paramétricos formuladas menos el número de parámetros desconocidos involucrados en las ecuaciones. Dado que el número de ecuaciones de modelos paramétricos es siempre el mismo que el número de observaciones, el número de grados de libertad también se puede definir como el número de observaciones menos el número de parámetros desconocidos. Las cantidades típicas medidas (las observables) en el levantamiento son distancias (horizontales o inclinadas), direcciones horizontales (o ángulos, ángulos verticales o cenitales), acimuts (o rumbos), diferencias de elevación, coordenadas de puntos (en sistemas GNSS), etc. Los parámetros desconocidos son típicamente coordenadas de puntos de red, que están vinculados juntos con las observaciones en forma matemática. Tome nota de lo siguiente al formular ecuaciones de modelos paramétricos:\n",
    "\n",
    "1. Los elementos importantes a manipular en las ecuaciones son los parámetros ($x$) y observaciones ($\\ell$). Identifique qué constituye los parámetros ($x$) y las observaciones ($\\ell$) en la pregunta. Utilice símbolos adecuados para representar cada una de las observaciones y los parámetros, y formule las ecuaciones utilizando los símbolos.\n",
    "2. Organice esos elementos que representan los parámetros ($x$) y las observaciones ($\\ell$) en las ecuaciones ($\\hat{\\ell} = f(\\hat{x})$) de tal manera que cada observación sea el sujeto de una ecuación que implique solo parámetros y valores constantes posibles. Cada uno de los parámetros y observaciones identificados ya debe presentarse, por ahora, en símbolos mientras se pospone el uso de sus valores numéricos cuando se están resolviendo las ecuaciones.\n",
    "\n",
    "Lo siguiente muestra cómo se vinculan matemáticamente las observables y los parámetros (es decir, las coordenadas). Las ecuaciones formuladas para distancias, acimut y observaciones de dirección horizontal de estaciones totales se dan con respecto a la Figura 5.1.\n",
    "\n",
    "#### 5.1.1 Observable de Distancia\n",
    "\n",
    "Para una distancia de pendiente EDM medida ($s_{ij}$) (desde la estación $i$ hasta la estación $j$ en la Figura 5.1) después de que se hayan aplicado las correcciones meteorológicas e instrumentales, la ecuación observacional (paramétrica) de distancia se puede dar como:\n",
    "\n",
    "$$ s_{ij} = \\sqrt{(x_j - x_i)^2 + (y_j - y_i)^2 + (z_j - z_i)^2} \\tag{5.1} $$\n",
    "\n",
    "donde $(x_i, y_i, z_i)$ y $(x_j, y_j, z_j)$ son las coordenadas tridimensionales de la estación de instrumentos $i$ y la estación objetivo $j$, respectivamente. Para el sistema de coordenadas bidimensionales, se descartarán los componentes $z$.\n",
    "\n",
    "#### 5.1.2 Observables de Acimut y Dirección Horizontal (Estación Total)\n",
    "\n",
    "Para el acimut medido reducido a 2-D ($a_{ij}$ medido desde $i$ a $j$ en la Figura 5.1) reducido al sistema de coordenadas de proyección del mapa ($a_{ij}$), la ecuación paramétrica se puede dar como:\n",
    "\n",
    "$$ a_{ij} = atan \\left( \\frac{y_j - y_i}{x_j - x_i} \\right) + \\text{[Análisis de cuadrante]} \\tag{5.2} $$\n",
    "\n",
    "donde $atan()$ se usa para representar la función arco tangente o tangente inversa trigonométrica. El análisis de cuadrante se ilustra utilizando la Figura 5.2. En la figura, la cuadrícula positiva en $x$ es este, y la cuadrícula positiva en $y$ es norte. Supongamos que los acimuts medidos $O-1, O-2, O-3$ y $O-4$ están ubicados en los cuatro cuadrantes diferentes como se muestra en la Figura 5.2; las ecuaciones paramétricas de los acimuts medidos se pueden formular de la siguiente manera.\n",
    "\n",
    "En las ecuaciones formuladas a continuación, $atan()$ representa arco tangente o tangente inversa; este símbolo se usa principalmente en este libro. Usar $atan()$ producirá los ángulos $\\alpha_1, \\alpha_2, \\alpha_3, \\alpha_4$ mostrados en la Figura 5.2 dependiendo del cambio en el este ($dx = x_j - x_i$) desde el Punto $O$ y el cambio en el norte ($dy = y_j - y_i$) desde el Punto $O$ con respecto a la estación observada (tal como $i = 1, 2, 3, 4$). Estos ángulos se pueden determinar usando $atan()$ como sigue:\n",
    "\n",
    "1. Si $dx$ es positivo y $dy$ es positivo, ubicando la línea $O-1$ en el cuadrante 1 (dando el ángulo positivo $\\alpha_1$: el acimut $\\beta_{O-1}$ es el mismo que $\\alpha_1$):\n",
    "\n",
    "$$ \\alpha_1 = atan \\left( \\frac{dy}{dx} \\right) \\tag{5.3} $$\n",
    "$$ \\beta_{O-1} = \\alpha_1 \\tag{5.4} $$\n",
    "\n",
    "2. Si $dx$ es negativo y $dy$ es positivo, ubicando la línea $O-2$ en el cuadrante 2 (dando el ángulo negativo $\\alpha_2$: el acimut $\\beta_{O-2}$ es el mismo que $\\alpha_2 + 180$):\n",
    "\n",
    "$$ \\alpha_2 = atan \\left( \\frac{dy}{dx} \\right) \\tag{5.5} $$\n",
    "$$ \\beta_{O-2} = \\alpha_2 + 180 \\tag{5.6} $$\n",
    "\n",
    "3. Si $dx$ es negativo y $dy$ es negativo, ubicando la línea $O-3$ en el cuadrante 3 (dando el ángulo positivo $\\alpha_3$: el acimut $\\beta_{O-3}$ es el mismo que $\\alpha_3 + 180$):\n",
    "\n",
    "$$ \\alpha_3 = atan \\left( \\frac{dy}{dx} \\right) \\tag{5.7} $$\n",
    "$$ \\beta_{O-3} = \\alpha_3 + 180 \\tag{5.8} $$\n",
    "\n",
    "4. Si $dx$ es negativo y $dy$ es positivo, ubicando la línea $O-4$ en el cuadrante 4 (dando el ángulo negativo $\\alpha_4$: el acimut $\\beta_{O-4}$ es el mismo que $\\alpha_4 + 360$):\n",
    "\n",
    "$$ \\alpha_4 = atan \\left( \\frac{dy}{dx} \\right) \\tag{5.9} $$\n",
    "$$ \\beta_{O-4} = \\alpha_4 + 180 \\tag{5.10} $$\n",
    "\n",
    "Para las observaciones de dirección horizontal (estación total) medidas en bruto ($d_{ij}$) reducidas al sistema de coordenadas de proyección del mapa y medidas en relación con el \"cero\" del círculo horizontal, la ecuación paramétrica se puede dar como:\n",
    "\n",
    "$$ d_{ij} = atan \\left( \\frac{y_j - y_i}{x_j - x_i} \\right) - \\gamma_i + \\text{[Análisis de cuadrante]} \\tag{5.11} $$\n",
    "\n",
    "Donde $\\gamma_i$ es el parámetro de orientación desconocido en la estación $i$. El término parámetro de orientación en la Ecuación (5.11) necesita un poco más de énfasis para que las mediciones de acimut (rumbo) y dirección no se malinterpreten como lo mismo. Las direcciones del instrumento de estación total (o teodolito) son simplemente lecturas de dirección arbitrarias proporcionadas por el instrumento con respecto a la lectura cero del instrumento; no son lo mismo que los acimuts (o rumbos), que se dan con respecto a la dirección del norte (la dirección del norte siendo su punto de referencia cero).\n",
    "\n",
    "La diferencia entre la lectura del punto cero de la estación total y el punto cero para la medición del acimut (o rumbo) es el **parámetro de orientación desconocido**. Este parámetro de orientación desconocido para la lectura de dirección de estación total en una línea es la cantidad de ángulo por la cual la medición de dirección de estación total en esa línea debe ajustarse para que la medición de dirección de estación total sea idéntica al acimut o rumbo de esa línea. Este valor no se determina directamente en una configuración, pero se considera como un parámetro de orientación desconocido ($\\gamma$), lo que lo convierte en un parámetro a determinar en un ajuste.\n",
    "\n",
    "Dado que generalmente no interesa conocer el valor numérico de un parámetro de orientación, el parámetro de orientación se denomina de otro modo **parámetro de molestia**. Es necesario en las ecuaciones del modelo para obtener ecuaciones correctas, pero no se requiere el conocimiento de su valor. Nótese que siempre habrá un parámetro de orientación desconocido por cada configuración de estación de instrumento para todas las direcciones que tengan una lectura común del punto cero de la estación total; si la orientación del punto cero de la estación total en el espacio cambia (como resultado de nivelación y recentrado del instrumento sobre otro punto o sobre el mismo punto), se asociará otro parámetro de orientación desconocido con la nueva configuración. Para cada configuración de estación total que implique la medición de direcciones, habrá un parámetro de orientación desconocido por cada estación configurada. Por ejemplo, si se toman direcciones de estación total en cuatro estaciones configuradas (o el cero del instrumento se restablece cuatro veces en una estación), habrá cuatro parámetros de orientación desconocidos para los cuatro conjuntos de direcciones tomados en las cuatro estaciones (o en la misma estación). Nótese que los parámetros de orientación están involucrados cuando se miden ángulos entre dos líneas, como se discute en la Sección 5.1.3.\n",
    "\n",
    "El propósito principal de relacionar la dirección de la estación total con el acimut (o rumbo) es porque no hay una ecuación directa para la medición de dirección de estación total; esto, por lo tanto, requiere que la ecuación correspondiente de acimut (o rumbo) de la línea se derive indirectamente con el parámetro de orientación introducido para reducir el acimut a la medición de dirección de estación total. Por ejemplo, la dirección de estación total de una línea es igual al acimut de esa línea menos el parámetro de orientación desconocido para esa configuración, como se da en la Ecuación (5.11).\n",
    "\n",
    "Nótese que al elegir el parámetro de orientación desconocido, uno no necesita primero visualizar cómo se relacionará el valor con el acimut; todo lo que se requiere es elegir un símbolo arbitrario para el parámetro. Además, la consistencia en la aplicación del parámetro de orientación en las ecuaciones del modelo es importante. El concepto de parámetro de orientación desconocido se ilustra en los Ejemplos 5.5 y 5.6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1a2af-e8ce-4303-af7f-5752de65fbda",
   "metadata": {},
   "source": [
    "### 5.1.3 Observable de Ángulo Horizontal\n",
    "\n",
    "La dirección horizontal medida $\\theta_{ijk}$ se puede dar como la diferencia entre dos mediciones de dirección $d_{ik}$ y $d_{ij}$ como se muestra en la Figura 5.3.\n",
    "\n",
    "Para el ángulo bruto medido $\\theta_{ijk}$ reducido al sistema de coordenadas de proyección del mapa (bidimensional), la ecuación paramétrica se puede dar como:\n",
    "\n",
    "$$ \\theta_{ijk} = atan \\left( \\frac{x_k - x_i}{y_k - y_i} \\right) - atan \\left( \\frac{x_j - x_i}{y_j - y_i} \\right) \\tag{5.12} $$\n",
    "\n",
    "donde el punto $i$ es la estación del instrumento y los puntos $j$ y $k$ son los puntos objetivo. Puede verse en la Ecuación (5.12) que el parámetro de orientación ($\\gamma$) no está involucrado en las mediciones de ángulo.\n",
    "\n",
    "### 5.1.4 Observable de Ángulo Cenital\n",
    "\n",
    "Para el ángulo cenital bruto medido ($Z_{ij}$) reducido al plano local para la línea $i$ a $j$ en la Figura 5.3, la ecuación paramétrica (en el caso tridimensional) se puede dar como:\n",
    "\n",
    "$$ Z_{ij} = atan \\left( \\frac{\\sqrt{(x_j - x_i)^2 + (y_j - y_i)^2}}{z_j - z_i} \\right) \\tag{5.13} $$\n",
    "\n",
    "### 5.1.5 Observable de Diferencia de Coordenadas\n",
    "\n",
    "Las diferencias de coordenadas GNSS (en el sistema de coordenadas geocéntricas tridimensionales) para una línea base $i$ a $j$ en la Figura 5.3 producen las siguientes ecuaciones paramétricas:\n",
    "\n",
    "$$ \\Delta x_{ij} = x_j - x_i $$\n",
    "$$ \\Delta y_{ij} = y_j - y_i $$\n",
    "$$ \\Delta z_{ij} = z_j - z_i \\tag{5.14} $$\n",
    "\n",
    "donde $\\Delta x_{ij}, \\Delta y_{ij}, \\Delta z_{ij}$ son los vectores de línea base medidos entre los puntos $i$ y $j$.\n",
    "\n",
    "### 5.1.6 Observable de Diferencia de Elevación\n",
    "\n",
    "La medición de diferencia de elevación ($\\Delta h_{ij}$) entre los puntos $i$ y $j$ en la Figura 5.3 (basada en el procedimiento de nivelación diferencial) produce la siguiente ecuación paramétrica:\n",
    "\n",
    "$$ \\Delta h_{ij} = h_j - h_i \\tag{5.15} $$\n",
    "\n",
    "donde $h_i$ y $h_j$ son las alturas de los puntos $i$ y $j$ por encima de un datum dado, respectivamente. La diferencia de elevación ($\\Delta h_{ij}$) entre los puntos $i$ y $j$ en la Figura 5.3 (basada en el procedimiento de nivelación trigonométrica con equipo de estación total, asumiendo que la distancia entre puntos $i$ y $j$ es corta y sin tener en cuenta la curvatura de la Tierra y las correcciones de refracción atmosférica) no se mide directamente sino que se calcula (como un parámetro desconocido, $x$) como sigue:\n",
    "\n",
    "$$ \\Delta h_{ij} = HI - HT + s_{ij} \\cos z_{ij} \\tag{5.16} $$\n",
    "\n",
    "donde HI es la altura medida del instrumento de estación total en el punto $i$, HT es la altura medida del objetivo en el punto $j$, $s_{ij}$ es la distancia inclinada medida, y $z_{ij}$ es el ángulo cenital medido. Dado que las cantidades medidas en la Ecuación (5.16) son $\\ell^T = [HI \\ HT \\ s_{ij} \\ z_{ij}]$ y el parámetro desconocido, $x = [\\Delta h_{ij}]$, entonces la Ecuación (5.16) es una forma especial de ecuación de modelo general $\\hat{x} = f(\\hat{\\ell})$. Si la ecuación se reorganiza, forma la ecuación de modelo general $f(\\hat{x}, \\hat{\\ell}) = 0$, como sigue:\n",
    "\n",
    "$$ \\Delta h_{ij} - HI + HT - s_{ij} \\cos z_{ij} = 0 \\tag{5.17} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af0f21-842f-4a1e-af79-9fd4afd6c46e",
   "metadata": {},
   "source": [
    "### 5.2 Ecuaciones Típicas del Modelo Paramétrico\n",
    "\n",
    "Se proporcionan ecuaciones típicas del modelo paramétrico en los ejemplos dados en esta sección.\n",
    "\n",
    "**Ejemplo 5.1** Dado el siguiente problema de transformación de dos parámetros que relaciona las coordenadas locales del sistema de foto ($e, n$) con las coordenadas del modelo fotogramétrico global ($E, N$) y las correspondientes coordenadas de los puntos 1 y 2 (refiriéndose a la Tabla 5.1 y Figura 5.4):\n",
    "\n",
    "$$ E_i = a e_i - b n_i \\tag{5.18} $$\n",
    "\n",
    "#### Tabla 5.1 Coordenadas de los puntos 1 y 2.\n",
    "\n",
    "| Punto | Sistema local (foto) | Sistema global (modelo) |\n",
    "|-------|----------------------|-------------------------|\n",
    "|       | $e_i$ (cm) | $n_i$ (cm) | $E_i$ (cm) | $N_i$ (cm) |\n",
    "| 1     | 0.0       | 1.0       | -2.1      | 1.1       |\n",
    "| 2     | 1.0       | 0.0       | 1.0       | 2.0       |\n",
    "\n",
    "$$ N_i = a n_i + b e_i \\tag{5.19} $$\n",
    "\n",
    "Si las coordenadas ($E, N$) de los puntos 1 y 2 se consideran como mediciones, las coordenadas ($e, n$) de los puntos 1 y 2 son valores conocidos con precisión, y las cantidades $a$ y $b$ son los desconocidos a determinar, escriba la ecuación matemática apropiada ($\\hat{\\ell} = f(\\hat{x})$) para el problema.\n",
    "\n",
    "**Solución:**\n",
    "\n",
    "El modelo paramétrico debe parecerse a $\\hat{\\ell} = f(\\hat{x})$. Tenga en cuenta que en este problema, las coordenadas ($e, n$) de los puntos 1 y 2 son valores conocidos con precisión (considerados como constantes). Los pasos dados en la Sección 5.1 se siguen para formular las ecuaciones paramétricas como sigue:\n",
    "\n",
    "1. Dado que las coordenadas ($E, N$) de los puntos 1 y 2 bajo el sistema global se consideran como las únicas mediciones con las otras coordenadas dadas como constantes, solo habrá cuatro observaciones. Los parámetros desconocidos ($x$) indicados en la pregunta son $a$ y $b$. En esta etapa, las observaciones se representan por los símbolos $\\ell = [E_1 \\ N_1 \\ E_2 \\ N_2]^T$, donde $E_1$ y $N_1$ son las coordenadas Este y Norte (en el sistema global) para el punto 1.\n",
    "2. Mirando las Ecuaciones representativas (5.18) y (5.19), se puede ver que cada elemento del vector de observación ($\\ell$) es un sujeto independiente igualado a una expresión que involucra los elementos ($a, b$) de los parámetros ($x$) con algunas cantidades constantes $e_i$ y $n_i$. Las ecuaciones ya están en el arreglo requerido $\\hat{\\ell} = f(\\hat{x})$ con cada punto asociado a dos ecuaciones (Ecuaciones (5.18) y (5.19)). Las ecuaciones finales del modelo paramétrico pueden escribirse para todos los puntos como sigue:\n",
    "\n",
    "$$ \\hat{E}_1 = a e_1 - b n_1 \\tag{5.20} $$\n",
    "$$ \\hat{N}_1 = a n_1 + b e_1 \\tag{5.21} $$\n",
    "$$ \\hat{E}_2 = a e_2 - b n_2 \\tag{5.22} $$\n",
    "$$ \\hat{N}_2 = a n_2 + b e_2 \\tag{5.23} $$\n",
    "\n",
    "donde $(e_1, n_1)$ y $(e_2, n_2)$ son, respectivamente, las coordenadas conocidas con precisión de los puntos 1 y 2, y ($\\hat{a}, \\hat{b}$) representan los parámetros ajustados (desconocidos). Tenga en cuenta que $(e_1, n_1)$ y $(e_2, n_2)$ no tienen gorros agregados a ellos ya que son cantidades constantes.\n",
    "\n",
    "**Ejemplo 5.2** Las coordenadas horizontales ($x, y$) del punto PT2 se determinarán en un polígono horizontal de la encuesta que se muestra en la Figura 5.5. Las cantidades medidas son el acimut Az, las distancias $d_1$ y $d_2$, y el ángulo ($\\alpha$) en el punto PT2.\n",
    "\n",
    "Si las coordenadas de los puntos PT1 y PT3 son fijas, formule las relaciones ($\\hat{\\ell} = f(\\hat{x})$) entre las observaciones y los parámetros desconocidos.\n",
    "\n",
    "**Solución:**\n",
    "\n",
    "El modelo paramétrico a formular debe parecerse a $\\hat{\\ell} = f(\\hat{x})$. Los parámetros desconocidos en este problema son $x$ e $y$ del punto PT2. Siguiendo los pasos dados en el Ejemplo 5.1 y el procedimiento de análisis de cuadrantes en la Sección 5.1.2, el modelo paramétrico requerido se puede formular como sigue:\n",
    "\n",
    "1. Las cantidades medidas son el acimut Az, las distancias $d_1$ y $d_2$ y el ángulo $\\alpha$; constituyen las observaciones ($\\ell$), que son cuatro en número. En esta etapa, las observaciones se representan por los símbolos $\\ell = [Az \\ d_1 \\ d_2 \\ \\alpha]^T$. Los parámetros son las coordenadas horizontales ($x, y$) del punto PT2 que deben ajustarse. Las coordenadas de los puntos PT1 y PT3 se dan, pero no se ajustarán; así, se consideran como constantes.\n",
    "\n",
    "2. A partir de la comprensión del tipo de modelo ($\\hat{\\ell} = f(\\hat{x})$) que se formulará, cada elemento del vector de observación ($\\ell$) debe yacer solo como un sujeto igualado a una expresión que involucra los parámetros ($x, y$) y algunas cantidades constantes (coordenadas de los puntos PT1 y PT3). Las formuladas son (Ecuaciones (5.24)-(5.27)):\n",
    "\n",
    "$$ \\hat{Az} = atan \\left( \\frac{\\hat{y} - 1000}{\\hat{x} - 1000} \\right) \\tag{5.24} $$\n",
    "\n",
    "Para cada observación de distancia, el inverso de las dos coordenadas correspondientes usando el teorema de Pitágoras usual da:\n",
    "\n",
    "$$ \\hat{d}_1 = \\sqrt{(\\hat{x} - 1000)^2 + (\\hat{y} - 1000)^2} \\tag{5.25} $$\n",
    "$$ \\hat{d}_2 = \\sqrt{(2050 - \\hat{x})^2 + (800 - \\hat{y})^2} \\tag{5.26} $$\n",
    "\n",
    "Usando el concepto de que un ángulo es la diferencia entre dos rumbos, el ángulo medido $\\alpha$ será igual al rumbo de la línea PT2–PT3 menos el rumbo de la línea PT2–PT1 más 360° para hacer que el ángulo sea un valor positivo:\n",
    "\n",
    "$$ \\text{Rumbo de la línea PT2–PT1 (en el cuadrante 3)} = atan \\left( \\frac{1000 - \\hat{x}}{1000 - \\hat{y}} \\right) + 180 $$\n",
    "$$ \\text{Rumbo de la línea PT2–PT3 (en el cuadrante 2)} = atan \\left( \\frac{2050 - \\hat{x}}{800 - \\hat{y}} \\right) + 180 $$\n",
    "\n",
    "$$ \\hat{\\alpha} = atan \\left( \\frac{2050 - \\hat{x}}{800 - \\hat{y}} \\right) - atan \\left( \\frac{1000 - \\hat{x}}{1000 - \\hat{y}} \\right) + 360° \\tag{5.27} $$\n",
    "\n",
    "donde ($\\hat{x}, \\hat{y}$) son las coordenadas ajustadas (parámetros) del punto PT2, ($\\hat{d}_1, \\hat{d}_2$) son las distancias ajustadas, $\\hat{Az}$ es el acimut ajustado y $\\hat{\\alpha}$ es el ángulo ajustado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d8d36-90bf-4ea0-a045-ec8c8422646a",
   "metadata": {},
   "source": [
    "### Ejemplo 5.3\n",
    "\n",
    "Considere una red de nivelación mostrada en la Figura 5.6 con las direcciones de las flechas que indican las direcciones de los recorridos de nivelación. Los puntos A y B son los puntos de referencia dados cuyas elevaciones son bien conocidas como $H_A$ y $H_B$, respectivamente; las elevaciones $H_1$, $H_2$ y $H_3$ de los puntos 1, 2 y 3, respectivamente, se determinarán. Las diferencias de elevación niveladas y las distancias aproximadas entre los puntos correspondientes se miden y se dan como se muestra en la figura. Formule las ecuaciones del modelo paramétrico ($\\hat{\\ell} = f(\\hat{x})$) para este problema.\n",
    "\n",
    "**Solución:**\n",
    "\n",
    "Las ecuaciones del modelo paramétrico deben parecerse a $\\hat{\\ell} = f(\\hat{x})$. Usando los pasos dados en el Ejemplo 5.1, el modelo paramétrico requerido puede formularse de la siguiente manera:\n",
    "\n",
    "1. Las diferencias de altura niveladas y las distancias aproximadas entre los puntos correspondientes se miden. Dado que las distancias aproximadas no se usan directamente en la derivación de puntos en levantamientos de nivelación diferencial, las únicas observaciones ($\\ell$) que deben considerarse son las diferencias de elevación niveladas ($h_{1B}, h_{13}, h_{12}, h_{1A}, h_{32}$). Como de costumbre, las observaciones se representan por los símbolos $\\ell = [h_{1B} \\ h_{13} \\ h_{12} \\ h_{1A} \\ h_{32}]^T$. Las elevaciones de los puntos de referencia dados ($H_A$ y $H_B$) se consideran como constantes ya que no deben cambiar en un ajuste y no son parámetros ni observaciones. Las elevaciones $H_1$, $H_2$, $H_3$ deben determinarse, por lo que son los parámetros ($x$).\n",
    "2. Al formular el modelo ($\\hat{\\ell} = f(\\hat{x})$), cada elemento del vector de observación ($\\ell$) debe yacer solo como un sujeto igualado a una expresión que involucra las elevaciones ($H_1, H_2, H_3$) de los parámetros ($x$) y las elevaciones de los puntos A y B como cantidades constantes. Para cinco observaciones, las siguientes ecuaciones paramétricas son posibles:\n",
    "\n",
    "$$ h_{1B} = H_B - H_1 \\tag{5.28} $$\n",
    "$$ h_{13} = H_3 - H_1 \\tag{5.29} $$\n",
    "$$ h_{12} = H_2 - H_1 \\tag{5.30} $$\n",
    "$$ h_{1A} = H_1 - H_A \\tag{5.31} $$\n",
    "$$ h_{32} = H_2 - H_3 \\tag{5.32} $$\n",
    "\n",
    "Se puede ver en las Ecuaciones (5.28) y (5.31) que $H_A$ y $H_B$ no tienen sombreros sobre ellos ya que no son parámetros ni observaciones.\n",
    "\n",
    "### Ejemplo 5.4\n",
    "\n",
    "El ángulo $\\theta$ y la distancia $S_{AB}$ en la red de polígono mostrada en la Figura 5.7 se midieron. En el polígono, dos puntos A y C están fijos. Formule las ecuaciones del modelo paramétrico para determinar las coordenadas ($x, y$) del punto B.\n",
    "\n",
    "**Solución:**\n",
    "\n",
    "Las ecuaciones del modelo paramétrico deben parecerse a $\\hat{\\ell} = f(\\hat{x})$. Usando los pasos dados en el Ejemplo 5.2 y la relación de que el ángulo $\\theta$ es igual al rumbo de la línea AC menos el rumbo de la línea AB, se puede formular la Ecuación (5.33); se aplica el teorema de Pitágoras para obtener la Ecuación (5.34):\n",
    "\n",
    "$$ \\hat{\\theta} = atan \\left( \\frac{1500 - 1000}{500 - 900} \\right) - atan \\left( \\frac{\\hat{x} - 1000}{\\hat{y} - 900} \\right) + 180° \\tag{5.33} $$\n",
    "\n",
    "$$ \\hat{S}_{AB} = \\sqrt{(\\hat{x} - 1000)^2 + (\\hat{y} - 900)^2} \\tag{5.34} $$\n",
    "\n",
    "donde $\\hat{S}_{AB}$ es la distancia ajustada y $\\hat{x}, \\hat{y}$ son las coordenadas ajustadas (parámetros) del punto B.\n",
    "\n",
    "### Ejemplo 5.5\n",
    "\n",
    "El punto O ($x, y$) en la Figura 5.8 debe ser resecado desde dos puntos de control dados A ($x_A, y_A$) y B ($x_B, y_B$). El acimut O-A se midió como $\\ell_1 = 40°$ y las direcciones de estación total O-A y O-B se midieron como $\\ell_2 = 10°$ y $\\ell_3 = 65°$, respectivamente. Formule las ecuaciones del modelo paramétrico ($\\hat{\\ell} = f(\\hat{x})$) para este problema.\n",
    "\n",
    "**Solución:**\n",
    "\n",
    "Este ejemplo ilustra la diferencia entre el acimut y la dirección de estación total (el parámetro de orientación). Basado en el concepto de parámetros de orientación discutido en la Sección 5.1.2 y los pasos dados en el Ejemplo 5.1, las ecuaciones del modelo paramétrico ($\\hat{\\ell} = f(\\hat{x})$) se pueden formular de la siguiente manera:\n",
    "\n",
    "1. De la pregunta, se midieron el acimut O–A (o $\\ell_1$) y las direcciones de estación total O–A ($\\ell_2$) y O–B ($\\ell_3$), lo que las convierte en las observaciones ($\\ell$) para este problema. Las observaciones se representan por los símbolos $\\ell = [\\ell_1 \\ \\ell_2 \\ \\ell_3]^T$. Las coordenadas ($x, y$) del punto O son los principales parámetros a determinar. Dado que las direcciones de estación total también se miden desde la misma configuración, hay un parámetro de orientación desconocido adicional ($\\gamma_0$) necesario para que el modelo de formulación sea completo. Los parámetros totales en este problema son $x = [x \\ y \\ \\gamma_0]^T$.\n",
    "2. Al formular las ecuaciones del modelo paramétrico ($\\hat{\\ell} = f(\\hat{x})$), cada elemento del vector de observación (\\\n",
    "\n",
    "($\\ell$) debe permanecer solo como un sujeto igualado a una expresión que involucra los elementos de los parámetros $x = [x \\ y \\ \\gamma_0]^T$ y las constantes conocidas (que pueden requerir un análisis de cuadrantes). Las ecuaciones formuladas son las siguientes:\n",
    "\n",
    "Para el acimut ajustado de la línea O–A (en el primer cuadrante):\n",
    "\n",
    "$$ \\hat{\\ell}_1 = atan \\left( \\frac{x_A - \\hat{x}}{y_A - \\hat{y}} \\right) - \\gamma_0 \\tag{5.35} $$\n",
    "\n",
    "De manera similar, para la dirección de estación total ajustada de la línea O–B:\n",
    "\n",
    "$$ \\hat{\\ell}_2 = atan \\left( \\frac{x_B - \\hat{x}}{y_B - \\hat{y}} \\right) - \\gamma_0 + 180° \\tag{5.36} $$\n",
    "\n",
    "Se puede ver en la Ecuación (5.35) que, si el parámetro de orientación desconocido ($\\gamma_0$) no se aplica, la ecuación será exactamente la misma que la del acimut ajustado ($\\hat{\\ell}_1$); esto no debería ser así ya que el acimut de la línea dada es aproximadamente $\\ell_1 = 40°$ y la dirección de estación total de la misma línea es $\\ell_2 = 10°$. Se puede ver que el parámetro de orientación desconocido ($\\gamma_0$) en este caso estará cerca de 30°. Es aconsejable siempre mantener el parámetro de orientación como desconocido en el ajuste de mínimos cuadrados para que su mejor estimación se pueda determinar como parte de los parámetros desconocidos. En el problema anterior, el número de observaciones es 3 (es decir, $\\ell_1, \\ell_2, \\ell_3$) y el número de parámetros desconocidos es 3 (es decir, $x, y, \\gamma_0$). Los pasos discutidos en este ejemplo deben seguirse al formular ecuaciones (o modelos) que involucren mediciones de dirección de estación total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e304e0-7983-4a80-99d4-e2ee7482fc60",
   "metadata": {},
   "source": [
    "### Ejemplo 5.6\n",
    "Los puntos 1 y 2 en la Figura 5.9 deben ser coordinados por intersección desde dos puntos de control $A (x_A, y_A)$ y $B (x_B, y_B)$. Las direcciones de la estación total desde el punto A son $\\ell_1, \\ell_2, \\ell_3$; las direcciones de la estación total desde el punto B son $\\ell_4, \\ell_5, \\ell_6$; las distancias medidas desde el punto A son $\\ell_7, \\ell_8$; y las distancias medidas desde el punto B son $\\ell_9$ y $\\ell_{10}$ como se muestra en la figura. Formule las ecuaciones del modelo paramétrico ($\\hat{\\ell} = f(\\hat{x})$) para este problema.\n",
    "\n",
    "**Solución:**\n",
    "Este ejemplo tiene como objetivo explicar más cómo introducir parámetros de orientación desconocidos en las ecuaciones del modelo paramétrico. Usando los pasos dados en el Ejemplo 5.5, las siguientes ecuaciones del modelo paramétrico pueden formularse:\n",
    "\n",
    "1. De la pregunta, las observaciones ($\\ell$) son las direcciones de la estación total en A ($\\ell_1, \\ell_2, \\ell_3$), las direcciones de la estación total en B ($\\ell_4, \\ell_5, \\ell_6$) y las distancias ($\\ell_7, \\ell_8, \\ell_9, \\ell_{10}$), que pueden darse como $\\ell = [\\ell_1 \\ \\ell_2 \\ \\ell_3 \\ \\ell_4 \\ \\ell_5 \\ \\ell_6 \\ \\ell_7 \\ \\ell_8 \\ \\ell_9 \\ \\ell_{10}]^T$. Los parámetros principales son las coordenadas ($x_A, y_A$) y ($x_B, y_B$) a determinarse directamente. Dado que hay dos puntos de configuración de la estación total (puntos A y B) donde se toman las mediciones de dirección, habrá dos parámetros de orientación desconocidos ($\\gamma_A$ y $\\gamma_B$) correspondientes a esos puntos de configuración. Los parámetros totales en este problema pueden darse como $x^T = [x_A \\ y_A \\ x_B \\ y_B \\ \\gamma_A \\ \\gamma_B]$.\n",
    "\n",
    "2. Al formular las ecuaciones del modelo paramétrico ($\\hat{\\ell} = f(\\hat{x})$), cada elemento del vector de observación ($\\ell$) debe permanecer solo como un sujeto igualado a una expresión que involucra los elementos de los parámetros ($x$) y algunas cantidades constantes (que pueden requerir un análisis de cuadrantes). Dadas 10 observaciones, el número de ecuaciones del modelo paramétrico posibles es 10. Se formulan de la siguiente manera:\n",
    "   \n",
    "   - En el punto A, asuma que el cero del instrumento está en el lado izquierdo de la línea A-1. Use el concepto de que cada observación de una línea es igual al acimut de esa línea menos el parámetro de orientación en ese punto:\n",
    "     $$\n",
    "     \\begin{align}\n",
    "     \\hat{\\ell}_1 &= atan \\left( \\frac{\\hat{x}_1 - x_A}{\\hat{y}_1 - y_A} \\right) + 360° - \\hat{\\gamma}_A \\tag{5.38} \\\\\n",
    "     \\hat{\\ell}_2 &= atan \\left( \\frac{x_B - x_A}{y_B - y_A} \\right) + 360° - \\hat{\\gamma}_A \\tag{5.39} \\\\\n",
    "     \\hat{\\ell}_3 &= atan \\left( \\frac{\\hat{x}_2 - x_A}{\\hat{y}_2 - y_A} \\right) + 360° - \\hat{\\gamma}_A \\tag{5.40}\n",
    "     \\end{align}\n",
    "    $$\n",
    "   - En el punto B, asuma que el cero del instrumento está en el lado izquierdo de la línea B-2. Use el concepto de que cada observación de una línea es igual al acimut de esa línea menos el parámetro de orientación en ese punto:\n",
    "     $$\n",
    "     \\begin{align}\n",
    "     \\hat{\\ell}_4 &= atan \\left( \\frac{\\hat{x}_1 - x_B}{\\hat{y}_1 - y_B} \\right) + 180° - \\hat{\\gamma}_B \\tag{5.41} \\\\\n",
    "     \\hat{\\ell}_5 &= atan \\left( \\frac{x_A - x_B}{y_A - y_B} \\right) + 180° - \\hat{\\gamma}_B \\tag{5.42} \\\\\n",
    "     \\hat{\\ell}_6 &= atan \\left( \\frac{\\hat{x}_2 - x_B}{\\hat{y}_2 - y_B} \\right) + 180° - \\hat{\\gamma}_B \\tag{5.43}\n",
    "     \\end{align}\n",
    "    $$\n",
    "   - Use el teorema de Pitágoras para determinar las distancias desde las coordenadas correspondientes:\n",
    "     $$\n",
    "     \\begin{align}\n",
    "     \\hat{\\ell}_7 &= \\sqrt{(\\hat{x}_1 - x_A)^2 + (\\hat{y}_1 - y_A)^2} \\tag{5.44} \\\\\n",
    "     \\hat{\\ell}_8 &= \\sqrt{(\\hat{x}_2 - x_A)^2 + (\\hat{y}_2 - y_A)^2} \\tag{5.45} \\\\\n",
    "     \\hat{\\ell}_9 &= \\sqrt{(\\hat{x}_1 - x_B)^2 + (\\hat{y}_1 - y_B)^2} \\tag{5.46} \\\\\n",
    "     \\hat{\\ell}_{10} &= \\sqrt{(\\hat{x}_2 - x_B)^2 + (\\hat{y}_2 - y_B)^2} \\tag{5.47}\n",
    "     \\end{align}\n",
    "    $$\n",
    "\n",
    "Estos pasos y ecuaciones permiten formular el modelo paramétrico necesario para resolver el problema planteado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fafcba9-cd1f-4b80-b08d-846e37eb934f",
   "metadata": {},
   "source": [
    "### 5.3 Formulación Básica del Modelo de Ajuste\n",
    "\n",
    "Las ecuaciones del modelo paramétrico se expresan simbólicamente como $\\hat{\\ell} = f(\\hat{x})$, lo que significa que una observación ajustada en un vector ($\\hat{\\ell}$) de observaciones ajustadas es funcionalmente igual a una combinación de parámetros ajustados ($\\hat{x}$). El modelo de mínimos cuadrados paramétricos también se conoce como el modelo de Gauss–Markov o el modelo de ecuación de observación. Al derivar los pasos de ajuste del modelo paramétrico, las siguientes pautas pueden ser útiles:\n",
    "\n",
    "1. Todos los símbolos o variables utilizados en la formulación de una ecuación de modelo paramétrico particular deben ser únicos; no se deben representar dos variables con la misma cantidad en el mismo modelo. En otras palabras, dos variables diferentes en un modelo no deben tener el mismo significado. Esto es necesario para evitar confundir los significados de los símbolos o variables utilizados en el mismo modelo.\n",
    "2. Cada símbolo o variable utilizado en un modelo debe estar claramente definido (generalmente después de haber sido utilizado) para aumentar la claridad de los pasos que se están tomando.\n",
    "3. La derivación del modelo de ajuste debe fluir lógicamente de un paso a otro con una explicación breve y concisa de cada paso, incluyendo una explicación del propósito del paso y por qué es necesario.\n",
    "4. Cada ecuación derivada debe estar debidamente numerada para que pueda ser citada más tarde utilizando ese número. La convención de numeración debe ser coherente con la convención utilizada en este libro.\n",
    "\n",
    "La formulación de los modelos de ajuste paramétricos de mínimos cuadrados consiste en los siguientes pasos generales, que se desarrollan más en las siguientes secciones:\n",
    "\n",
    "i) **Formulación de las ecuaciones del modelo paramétrico** ($\\hat{\\ell} = f(\\hat{x})$) como se discute en las Secciones 5.1 y 5.2. Tenga en cuenta que las matrices de covarianza (o matrices de pesos) declaradas con el modelo formulado son relevantes para la formulación de las funciones de variación más adelante.\n",
    "\n",
    "ii) **Linealización de las ecuaciones del modelo.** Dado que las ecuaciones del modelo pueden no ser lineales, deben ser linealizadas mediante la expansión en serie de Taylor (consulte la Sección 5.4).\n",
    "\n",
    "iii) **Derivación de un nuevo conjunto de ecuaciones conocido como función de variación.** Esto se hace incorporando las ecuaciones del modelo paramétrico linealizado en el criterio de mínimos cuadrados (consulte la Sección 5.5).\n",
    "\n",
    "iv) **Derivación del sistema de ecuaciones normales.** Esto se hace determinando las derivadas parciales de la función de variación con respecto a los desconocidos en la función y estableciendo las derivadas parciales a cero para producir lo que comúnmente se conoce como un sistema de ecuaciones normales (consulte la Sección 5.6).\n",
    "\n",
    "v) **Resolución del sistema de ecuaciones normales.** La solución de las ecuaciones normales proporciona los valores ajustados para las cantidades desconocidas (consulte la Sección 5.7)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf8afaa-2bcb-429b-99b2-7c8c133c4262",
   "metadata": {},
   "source": [
    "### 5.4 Linealización de las Ecuaciones del Modelo Paramétrico\n",
    "\n",
    "La linealización de las ecuaciones del modelo paramétrico se basa en la expansión en serie de Taylor discutida en el Capítulo 2. Consulte las Ecuaciones (E.22)–(E.29) para revisar las derivadas parciales de funciones relacionadas con matrices y vectores. En esta sección, se linealizará el modelo paramétrico con y sin parámetros de molestia. Recuerde también que la estimación de mínimos cuadrados es iterativa debido a la necesidad práctica de linealizar el modelo funcional mediante la expansión en serie de Taylor. Esta solución iterativa es necesaria ya que los valores iniciales (aproximados) de los parámetros desconocidos son difíciles de obtener con un nivel de precisión suficiente para que la expansión en serie sea válida. Después de que los valores iniciales de los parámetros se ingresan en el primer ajuste, las soluciones iterativas subsiguientes se usan como nuevos valores iniciales, y el procedimiento de ajuste se repite hasta que se obtiene una solución particular que es insignificativamente diferente de la anterior; en este punto, se dice que el ajuste ha convergido a una solución final. Esta solución final se considera que contiene los valores finales de los parámetros desconocidos.\n",
    "\n",
    "#### 5.4.1 Linealización del Modelo Paramétrico sin Parámetro de Molestia\n",
    "\n",
    "Dado el siguiente modelo paramétrico, que no contiene parámetros de molestia (Ecuación (5.48)):\n",
    "\n",
    "$$\n",
    "\\hat{\\ell} = f(\\hat{x}) \\quad P \\tag{5.48}\n",
    "$$\n",
    "\n",
    "donde $f$ es un vector de modelos matemáticos, $\\hat{x}$ es un vector de parámetros desconocidos, $\\hat{\\ell}$ es un vector de observaciones, y $P$ es la matriz de pesos de las observaciones. Se debe prestar especial atención a la matriz de pesos $P$, que debe usarse explícitamente en cualquier derivación que involucre la función dada; esto es lo principal de declararla con la función. Sea la Ecuación (5.48) reescrita como:\n",
    "\n",
    "$$\n",
    "\\ell + v = f(x^0 + \\delta) \\tag{5.49}\n",
    "$$\n",
    "\n",
    "donde $v$ es el vector residual de la observación, $\\ell$ es un vector de observaciones originales, $x^0$ es un vector de valores aproximados de los parámetros, y $\\delta$ es un vector de correcciones a los parámetros aproximados. Al realizar una expansión en serie de Taylor en la Ecuación (5.49), se obtiene la siguiente forma linealizada del modelo paramétrico:\n",
    "\n",
    "$$\n",
    "v = f(x^0) + \\frac{\\partial f}{\\partial x}\\delta - \\ell \\tag{5.50}\n",
    "$$\n",
    "\n",
    "La Ecuación linealizada (5.50) se puede simplificar de la siguiente manera:\n",
    "\n",
    "$$\n",
    "v = w + A\\delta \\tag{5.51}\n",
    "$$\n",
    "\n",
    "donde $w = f(x^0) - \\ell$ es el vector de disconformidad y $A = \\partial f/\\partial x$ es la matriz Jacobiana, también conocida como la primera matriz de diseño. Debe enfatizarse que la Ecuación (5.51) se produce solo con el propósito de facilitar posibles operaciones adicionales en la Ecuación linealizada (5.50). Las derivadas parciales necesarias para la linealización de observables típicos se dan en el Apéndice D de la siguiente manera: observable de acimut (Sección D.1), observable de estación total (Sección D.2), observable de ángulo horizontal (Sección D.3), observable de distancia (Sección D.4) y observable de ángulo cenital (Sección D.5). Los ejemplos de modelos linealizados se dan a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412ecf2-ea62-4069-b825-5e41a9fe4da7",
   "metadata": {},
   "source": [
    "### Ejemplo 5.7 Linealizar las Ecuaciones (5.20)–(5.23) en el Ejemplo 5.1 y presentarlas en forma de la Ecuación (5.51).\n",
    "\n",
    "#### Solución:\n",
    "Para las Ecuaciones (5.20)–(5.23), el modelo linealizado puede darse como la Ecuación (5.51) donde el vector de parámetros es $ \\mathbf{x} = \\begin{bmatrix} a \\\\ b \\end{bmatrix} $. Dado el vector de parámetros aproximados $ \\mathbf{x}^0 = \\begin{bmatrix} a^0 \\\\ b^0 \\end{bmatrix} $, la primera matriz de diseño (evaluada en $ \\mathbf{x}^0 $) puede darse como:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left. \\frac{\\partial f}{\\partial \\mathbf{x}} \\right|_{\\mathbf{x}^0} = \\begin{bmatrix} \\frac{\\partial E_1}{\\partial a} & \\frac{\\partial E_1}{\\partial b} \\\\ \\frac{\\partial N_1}{\\partial a} & \\frac{\\partial N_1}{\\partial b} \\\\ \\frac{\\partial E_2}{\\partial a} & \\frac{\\partial E_2}{\\partial b} \\\\ \\frac{\\partial N_2}{\\partial a} & \\frac{\\partial N_2}{\\partial b} \\end{bmatrix}_{\\mathbf{x}^0} = \\begin{bmatrix} e_1 & -n_1 \\\\ n_1 & e_1 \\\\ e_2 & -n_2 \\\\ n_2 & e_2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "El vector de disconformidad ($\\mathbf{w}$) evaluado en $ \\mathbf{x}^0 $, el vector de residuos ($\\mathbf{v}$) y el vector de correcciones a los parámetros aproximados ($\\delta$) pueden darse, respectivamente, como:\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = \\begin{bmatrix} a^0 e_1 - b^0 n_1 - E_1 \\\\ a^0 n_1 + b^0 e_1 - N_1 \\\\ a^0 e_2 - b^0 n_2 - E_2 \\\\ a^0 n_2 + b^0 e_2 - N_2 \\end{bmatrix}, \\quad \\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\\\ v_4 \\end{bmatrix}, \\quad \\delta = \\begin{bmatrix} \\delta a \\\\ \\delta b \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "El modelo linealizado de las Ecuaciones (5.20)–(5.23) (evaluado en $ \\mathbf{x}^0 $) puede darse como:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\\\ v_4 \\end{bmatrix} = \\begin{bmatrix} a^0 e_1 - b^0 n_1 - E_1 \\\\ a^0 n_1 + b^0 e_1 - N_1 \\\\ a^0 e_2 - b^0 n_2 - E_2 \\\\ a^0 n_2 + b^0 e_2 - N_2 \\end{bmatrix} + \\begin{bmatrix} e_1 & -n_1 \\\\ n_1 & e_1 \\\\ e_2 & -n_2 \\\\ n_2 & e_2 \\end{bmatrix} \\begin{bmatrix} \\delta a \\\\ \\delta b \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d65797d-82a4-4dcd-9c6d-d1d96698cf74",
   "metadata": {},
   "source": [
    "### Ejemplo 5.8 Linealizar las Ecuaciones (5.24)–(5.27) en el Ejemplo 5.2 y presentarlas en forma de la Ecuación (5.51).\n",
    "\n",
    "#### Solución:\n",
    "Para las Ecuaciones (5.24)–(5.27), el modelo linealizado puede darse como la Ecuación (5.51) donde el vector de parámetros es $ \\mathbf{p} = \\begin{bmatrix} x \\\\ y \\end{bmatrix} $. Dado el vector de parámetros aproximados $ \\mathbf{p}^0 = \\begin{bmatrix} x^0 \\\\ y^0 \\end{bmatrix} $, la primera matriz de diseño (evaluada en $ \\mathbf{p}^0 $) puede darse como:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left. \\frac{\\partial f}{\\partial \\mathbf{x}} \\right|_{\\mathbf{p}^0} = \\begin{bmatrix} \\frac{\\partial \\hat{Az}}{\\partial x} & \\frac{\\partial \\hat{Az}}{\\partial y} \\\\ \\frac{\\partial \\hat{d}_1}{\\partial x} & \\frac{\\partial \\hat{d}_1}{\\partial y} \\\\ \\frac{\\partial \\hat{d}_2}{\\partial x} & \\frac{\\partial \\hat{d}_2}{\\partial y} \\\\ \\frac{\\partial \\hat{\\alpha}}{\\partial x} & \\frac{\\partial \\hat{\\alpha}}{\\partial y} \\end{bmatrix}_{\\mathbf{p}^0} = \\begin{bmatrix} \\frac{(y^0 - 1000)}{(y^0 - 1000)^2 + (x^0 - 1000)^2} & \\frac{-(x^0 - 1000)}{(y^0 - 1000)^2 + (x^0 - 1000)^2} \\\\ \\frac{(x^0 - 1000)}{\\sqrt{(y^0 - 1000)^2 + (x^0 - 1000)^2}} & \\frac{(y^0 - 1000)}{\\sqrt{(y^0 - 1000)^2 + (x^0 - 1000)^2}} \\\\ \\frac{-(2050 - x^0)}{\\sqrt{(800 - y^0)^2 + (2050 - x^0)^2}} & \\frac{-(800 - y^0)}{\\sqrt{(800 - y^0)^2 + (2050 - x^0)^2}} \\\\ \\frac{-(800 - y^0)}{(800 - y^0)^2 + (2050 - x^0)^2} - \\frac{(1000 - y^0)}{(1000 - y^0)^2 + (1000 - x^0)^2} & \\frac{(2050 - x^0)}{(800 - y^0)^2 + (2050 - x^0)^2} + \\frac{(1000 - x^0)}{(1000 - y^0)^2 + (1000 - x^0)^2} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "El vector de disconformidad ($\\mathbf{w}$) evaluado en $ \\mathbf{p}^0 $, el vector de residuos ($\\mathbf{v}$) y el vector de correcciones a los parámetros aproximados ($\\delta$) pueden darse, respectivamente, como:\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = \\begin{bmatrix} Az^0 - \\hat{Az} \\\\ d_1^0 - \\hat{d}_1 \\\\ d_2^0 - \\hat{d}_2 \\\\ \\alpha^0 - \\hat{\\alpha} \\end{bmatrix}, \\quad \\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\\\ v_4 \\end{bmatrix}, \\quad \\delta = \\begin{bmatrix} \\delta x \\\\ \\delta y \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "donde $ \\begin{bmatrix} Az^0 & d_1^0 & d_2^0 & \\alpha^0 \\end{bmatrix}^T $ es un vector de observaciones derivadas utilizando los valores aproximados de los parámetros en las Ecuaciones (5.24)–(5.27), respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aace850a-02da-40ca-964c-ba2c32ef704e",
   "metadata": {},
   "source": [
    "### Ejemplo 5.9 Linealizar las Ecuaciones (5.28)–(5.32) en el Ejemplo de nivelación 5.3 y presentarlas en la forma de la Ecuación (5.51).\n",
    "\n",
    "#### Solución:\n",
    "Para las Ecuaciones (5.28)–(5.32), el modelo linealizado puede darse como la Ecuación (5.51) donde el vector de parámetros es $ \\mathbf{x} = \\begin{bmatrix} H_1 & H_2 & H_3 \\end{bmatrix}^T $. Dado el vector de parámetros aproximados $ \\mathbf{x}^0 = \\begin{bmatrix} H_1^0 & H_2^0 & H_3^0 \\end{bmatrix}^T $, la primera matriz de diseño (evaluada en $ \\mathbf{x}^0 $) puede darse como:\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = \\left. \\frac{\\partial f}{\\partial \\mathbf{x}} \\right|_{\\mathbf{x}^0} = \\begin{bmatrix} \\frac{\\partial \\hat{h}_{1B}}{\\partial H_1} & \\frac{\\partial \\hat{h}_{1B}}{\\partial H_2} & \\frac{\\partial \\hat{h}_{1B}}{\\partial H_3} \\\\ \\frac{\\partial \\hat{h}_{13}}{\\partial H_1} & \\frac{\\partial \\hat{h}_{13}}{\\partial H_2} & \\frac{\\partial \\hat{h}_{13}}{\\partial H_3} \\\\ \\frac{\\partial \\hat{h}_{12}}{\\partial H_1} & \\frac{\\partial \\hat{h}_{12}}{\\partial H_2} & \\frac{\\partial \\hat{h}_{12}}{\\partial H_3} \\\\ \\frac{\\partial \\hat{h}_{1A}}{\\partial H_1} & \\frac{\\partial \\hat{h}_{1A}}{\\partial H_2} & \\frac{\\partial \\hat{h}_{1A}}{\\partial H_3} \\\\ \\frac{\\partial \\hat{h}_{32}}{\\partial H_1} & \\frac{\\partial \\hat{h}_{32}}{\\partial H_2} & \\frac{\\partial \\hat{h}_{32}}{\\partial H_3} \\end{bmatrix}_{\\mathbf{x}^0} = \\begin{bmatrix} -1 & 0 & 0 \\\\ -1 & 0 & 1 \\\\ -1 & 1 & 0 \\\\ -1 & 0 & 0 \\\\ 0 & 1 & -1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "El vector de disconformidad ($\\mathbf{w}$) evaluado en $ \\mathbf{x}^0 $, el vector de residuos ($\\mathbf{v}$) y el vector de correcciones a los parámetros aproximados ($\\delta$) pueden darse, respectivamente, como:\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = \\begin{bmatrix} H_B - H_1^0 - h_{1B} \\\\ H_3^0 - H_1^0 - h_{13} \\\\ H_2^0 - H_1^0 - h_{12} \\\\ H_A - H_1^0 - h_{1A} \\\\ H_2^0 - H_3^0 - h_{32} \\end{bmatrix}, \\quad \\mathbf{v} = \\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\\\ v_4 \\\\ v_5 \\end{bmatrix}, \\quad \\delta = \\begin{bmatrix} \\delta H_1 \\\\ \\delta H_2 \\\\ \\delta H_3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "El modelo linealizado de las Ecuaciones (5.28)–(5.32) (evaluado en $ \\mathbf{x}^0 $) puede darse como:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} v_1 \\\\ v_2 \\\\ v_3 \\\\ v_4 \\\\ v_5 \\end{bmatrix} = \\begin{bmatrix} H_B - H_1^0 - h_{1B} \\\\ H_3^0 - H_1^0 - h_{13} \\\\ H_2^0 - H_1^0 - h_{12} \\\\ H_A - H_1^0 - h_{1A} \\\\ H_2^0 - H_3^0 - h_{32} \\end{bmatrix} + \\begin{bmatrix} -1 & 0 & 0 \\\\ -1 & 0 & 1 \\\\ -1 & 1 & 0 \\\\ -1 & 0 & 0 \\\\ 0 & 1 & -1 \\end{bmatrix} \\begin{bmatrix} \\delta H_1 \\\\ \\delta H_2 \\\\ \\delta H_3 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957d5ac6-cf20-416b-a3dc-7b489ac3680e",
   "metadata": {},
   "source": [
    "### 5.4.2 Linealización del Modelo Paramétrico con Parámetro de Molestia\n",
    "\n",
    "Para ilustrar los conceptos de linealización mediante la expansión en series de Taylor, se puede considerar un modelo paramétrico dado por:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{\\ell}} = f(\\hat{\\mathbf{x}}_1, \\hat{\\mathbf{x}}_2)\n",
    "$$\n",
    "\n",
    "donde $\\hat{\\mathbf{\\ell}}$ es un vector de observaciones ajustadas, $\\hat{\\mathbf{x}}_1$ es un vector de coordenadas ajustadas y $\\hat{\\mathbf{x}}_2$ es un vector de parámetros de orientación ajustados (o parámetros de molestia). La expansión en series de Taylor (hasta el primer orden) del modelo puede darse como sigue:\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{\\ell}} = f(\\mathbf{x}_1, \\mathbf{x}_2) + \\frac{\\partial f}{\\partial \\mathbf{x}_1} \\delta_1 + \\frac{\\partial f}{\\partial \\mathbf{x}_2} \\delta_2\n",
    "$$\n",
    "\n",
    "donde la Ecuación (5.53) es la forma lineal aproximada de la función dada $ f(\\mathbf{x}_1, \\mathbf{x}_2) $ o $\\hat{\\ell}$ en la Ecuación (5.52). $ f(\\mathbf{x}_1, \\mathbf{x}_2) $, el término de orden cero de la serie de Taylor, es la función original evaluada en los valores numéricos iniciales dados de las coordenadas ($\\mathbf{x}_1$) y los parámetros de orientación ($\\mathbf{x}_2$); $\\delta_1$ es un vector de correcciones a aplicar a los valores iniciales de las coordenadas ($\\mathbf{x}_1$); $\\delta_2$ es un vector de correcciones a aplicar a los valores iniciales de los parámetros de orientación ($\\mathbf{x}_2$); $\\frac{\\partial f}{\\partial \\mathbf{x}_1}$ es una matriz jacobiana que contiene las derivadas parciales respecto a las coordenadas; y $\\frac{\\partial f}{\\partial \\mathbf{x}_2}$ es una matriz jacobiana de las derivadas parciales respecto a los parámetros de orientación.\n",
    "\n",
    "Una observación típica de una encuesta que se representa en la forma de la Ecuación (5.52) es la observación de dirección de la estación total ($d_{ij}$) desde la estación $i$ a $j$, reducida al sistema de coordenadas de proyección de mapa. Esta observación se expresa en forma matemática explícita en la Sección 5.1.2 como:\n",
    "\n",
    "$$\n",
    "\\hat{d}_{ij} = \\tan^{-1} \\left( \\frac{\\hat{y}_j - \\hat{y}_i}{\\hat{x}_j - \\hat{x}_i} \\right) - \\hat{\\gamma}_i\n",
    "$$\n",
    "\n",
    "donde $\\hat{\\gamma}_i$ es el parámetro de orientación ajustado en la estación $i$ y ($\\hat{x}_i, \\hat{y}_i$) y ($\\hat{x}_j, \\hat{y}_j$) son las coordenadas horizontales ajustadas de los puntos $i$ y $j$, respectivamente.\n",
    "\n",
    "Relacionando la Ecuación (5.52) con la Ecuación (5.54):\n",
    "\n",
    "$$\n",
    "\\hat{\\ell} = \\hat{d}_{ij}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{x}}_1 = (\\hat{x}_i, \\hat{y}_i, \\hat{x}_j, \\hat{y}_j)^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{x}}_2 = \\hat{\\gamma}_i\n",
    "$$\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}_1, \\mathbf{x}_2) = \\tan^{-1} \\left( \\frac{\\hat{y}_j - \\hat{y}_i}{\\hat{x}_j - \\hat{x}_i} \\right) - \\hat{\\gamma}_i\n",
    "$$\n",
    "\n",
    "La expansión en series de Taylor de la Ecuación (5.54) con respecto a la Ecuación (5.53) será:\n",
    "\n",
    "$$\n",
    "\\hat{d}_{ij} = \\tan^{-1} \\left( \\frac{y_j^0 - y_i^0}{x_j^0 - x_i^0} \\right) - \\gamma_i^0 + \\mathbf{A}_1 \\begin{bmatrix} \\delta x_i \\\\ \\delta y_i \\\\ \\delta x_j \\\\ \\delta y_j \\end{bmatrix} + \\mathbf{A}_2 [\\delta \\gamma_i]\n",
    "$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}_1, \\mathbf{x}_2) = \\tan^{-1} \\left( \\frac{y_j^0 - y_i^0}{x_j^0 - x_i^0} \\right) - \\gamma_i^0 \\text{ correspondiente al orden cero de la serie de Taylor evaluado en el vector de valores aproximados de los parámetros, }\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^0 = [x_i^0, y_i^0, x_j^0, y_j^0, \\gamma_i^0]^T, \\quad \\mathbf{A}_1 = \\left. \\frac{\\partial f}{\\partial \\mathbf{x}_1} \\right|_{\\mathbf{x}^0} = \\begin{bmatrix} \\frac{\\partial \\hat{d}_{ij}}{\\partial x_i} & \\frac{\\partial \\hat{d}_{ij}}{\\partial y_i} & \\frac{\\partial \\hat{d}_{ij}}{\\partial x_j} & \\frac{\\partial \\hat{d}_{ij}}{\\partial y_j} \\end{bmatrix}^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A}_2 = \\left. \\frac{\\partial f}{\\partial \\mathbf{x}_2} \\right|_{\\mathbf{x}^0} = \\begin{bmatrix} \\frac{\\partial \\hat{d}_{ij}}{\\partial \\gamma_i} \\end{bmatrix}^T, \\quad \\delta_1 = \\begin{bmatrix} \\delta x_i \\\\ \\delta y_i \\\\ \\delta x_j \\\\ \\delta y_j \\end{bmatrix}, \\quad \\delta_2 = [\\delta \\gamma_i]\n",
    "$$\n",
    "\n",
    "Las matrices jacobianas $\\mathbf{A}_1$ y $\\mathbf{A}_2$ son conocidas con respecto al ajuste por mínimos cuadrados paramétricos como las primeras matrices de diseño. Los elementos de las matrices $\\mathbf{A}_1$ y $\\mathbf{A}_2$ se dan en la Sección D.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb49dc7-e170-41ff-abb9-82b426ac8a6b",
   "metadata": {},
   "source": [
    "### 5.5 Derivación de la Función de Variación\n",
    "\n",
    "Se pueden seguir dos enfoques para derivar la función de variación del modelo paramétrico linealizado dado en la Ecuación (5.51): el enfoque directo y el enfoque lagrangiano. El enfoque lagrangiano parece ser más flexible al resolver problemas relacionados con el mínimo, como en el caso del criterio de mínimos cuadrados. La elección de cualquiera de los dos enfoques, sin embargo, es una cuestión de conveniencia ya que ambos terminan produciendo el mismo vector de solución.\n",
    "\n",
    "#### 5.5.1 Derivación de la Función de Variación Usando el Enfoque Directo\n",
    "\n",
    "La función de variación es la forma cuadrática del modelo paramétrico linealizado dado en la Ecuación (5.51), excepto que ahora está \"correlacionado\" con el criterio de mínimos cuadrados. En la Ecuación (5.48), la matriz de pesos $ P $ está claramente asociada con el modelo dado, lo que significa que $ P $ debe ser utilizada explícitamente en la función de variación. La función de variación basada en la Ecuación (5.51) se deriva utilizando el enfoque directo como sigue. El criterio de mínimos cuadrados para este tipo de problema (refiriéndose a la Sección 4.2.1) se puede dar como\n",
    "\n",
    "$$\n",
    "\\mathbf{v}^T P \\mathbf{v} = \\text{mínimo} \\tag{5.56}\n",
    "$$\n",
    "\n",
    "La función de variación ($ \\varphi $) en la Ecuación (5.57) se obtiene imponiendo el criterio de mínimos cuadrados (Ecuación 5.56) en el modelo linealizado (Ecuación 5.51). Esto se hace sustituyendo el modelo linealizado directamente en el criterio de mínimos cuadrados como sigue:\n",
    "\n",
    "$$\n",
    "\\varphi = \\mathbf{v}^T P \\mathbf{v} = (A \\delta + \\mathbf{w})^T P (A \\delta + \\mathbf{w}) = \\text{mínimo} \\tag{5.57}\n",
    "$$\n",
    "\n",
    "En forma expandida, la función de variación (Ecuación 5.57) se puede dar como\n",
    "\n",
    "$$\n",
    "\\varphi = \\delta^T A^T P A \\delta + \\delta^T A^T P \\mathbf{w} + \\mathbf{w}^T P A \\delta + \\mathbf{w}^T P \\mathbf{w} = \\text{mínimo} \\tag{5.58}\n",
    "$$\n",
    "\n",
    "Siguiendo las reglas de las operaciones básicas de matrices en la Sección 1.6.3, se puede mostrar que $(A \\delta + \\mathbf{w})^T = \\delta^T A^T + \\mathbf{w}^T$ (notando que $A$ y $\\delta$ ahora están intercambiados). Si la matriz de covarianza de las observaciones ($C_\\ell$) se proporciona en la Ecuación (5.48) en lugar de la matriz de pesos dada $P$, la Ecuación (5.48) se modificará para parecerse al siguiente modelo:\n",
    "\n",
    "$$\n",
    "\\hat{\\ell} = f(\\hat{x}) C_\\ell \\tag{5.59}\n",
    "$$\n",
    "\n",
    "donde $P$ ahora se reemplaza con la matriz de covarianza de las observaciones $C_\\ell$, que ahora está claramente asociada con el modelo dado. Esto significa que $C_\\ell$ debe ser utilizada explícitamente en el criterio de mínimos cuadrados y en la función de variación. Al sustituir $P = \\sigma_0^2 C_\\ell^{-1}$ (y fijando el factor de varianza a priori de peso unitario, $\\sigma_0^2 = 1$) en las Ecuaciones (5.56) y (5.58), el criterio de mínimos cuadrados correspondiente y la función de variación se obtienen como las Ecuaciones (5.60) y (5.61), respectivamente:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}^T C_\\ell^{-1} \\mathbf{v} = \\text{mínimo} \\tag{5.60}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\varphi = \\delta^T A^T C_\\ell^{-1} A \\delta + 2 \\delta^T A^T C_\\ell^{-1} \\mathbf{w} + \\mathbf{w}^T C_\\ell^{-1} \\mathbf{w} = \\text{mínimo} \\tag{5.61}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a022515d-d4c6-4083-b1a6-2e7865f648d7",
   "metadata": {},
   "source": [
    "### 5.5.2 Derivación de la Función de Variación Usando el Enfoque Lagrangiano\n",
    "\n",
    "La función de variación basada en la Ecuación (5.51) asociada con el modelo en la Ecuación (5.48) y el criterio de mínimos cuadrados en la Ecuación (5.56) se deriva como sigue usando el enfoque lagrangiano. El enfoque lagrangiano es más flexible que el enfoque directo, especialmente cuando el criterio de mínimos cuadrados debe imponerse en muchos modelos linealizados; en este caso, todo lo que uno necesita hacer es multiplicar cada modelo linealizado por un multiplicador de Lagrange diferente ($ k $) y restar cada producto del (o agregar cada producto al) criterio de función para producir una función de variación. Imponer el criterio de mínimos cuadrados (Ecuación 5.56) en el modelo linealizado (Ecuación 5.51) usando un vector de multiplicadores de Lagrange ($ k $) (también conocido como un vector de correlatos) da la función de variación por el enfoque lagrangiano como sigue:\n",
    "\n",
    "$$\n",
    "\\varphi = \\mathbf{v}^T P \\mathbf{v} - 2k^T (A \\delta + \\mathbf{w} - \\mathbf{v}) = \\text{mínimo} \\tag{5.62}\n",
    "$$\n",
    "\n",
    "Si la función de variación se basa en la Ecuación (5.51) asociada con el modelo en la Ecuación (5.59) y el criterio de mínimos cuadrados en la Ecuación (5.60), se obtendrá lo siguiente:\n",
    "\n",
    "$$\n",
    "\\varphi = \\mathbf{v}^T C_\\ell^{-1} \\mathbf{v} - 2k^T (A \\delta + \\mathbf{w} - \\mathbf{v}) = \\text{mínimo} \\tag{5.63}\n",
    "$$\n",
    "\n",
    "Las Ecuaciones (5.62) y (5.63) son las funciones de variación basadas en el enfoque lagrangiano. Como se puede ver en las dos ecuaciones, la única diferencia es el uso de $ P $ en la Ecuación (5.62) y $ C_\\ell^{-1} $ en la Ecuación (5.63)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125dfbf0-1415-4b64-b7f9-5d7805599281",
   "metadata": {},
   "source": [
    "### 5.6 Derivación del Sistema de Ecuaciones Normales\n",
    "\n",
    "El sistema de ecuaciones normales de mínimos cuadrados se deriva de la función de variación expandida dada en la Ecuación (5.58) o en la Ecuación (5.61) dependiendo de si se da $C_{\\ell}$ o $P$ en el caso del enfoque directo o la Ecuación (5.62) o la Ecuación (5.63) dependiendo de si se da $C_{\\ell}$ o $P$ en el caso del enfoque lagrangiano. Las derivadas parciales de la función de variación deben ser encontradas y establecidas igual a cero como sigue para obtener el sistema de ecuaciones normales.\n",
    "\n",
    "#### 5.6.1 Ecuaciones Normales Basadas en el Enfoque Directo de la Función de Variación\n",
    "\n",
    "El sistema de ecuaciones normales puede derivarse de las funciones de variación obtenidas con base en el enfoque directo, como sigue. Por ejemplo, considere la función de variación en la Ecuación (5.58), encuentre sus derivadas parciales (refiriéndose a las Ecuaciones (1.43)–(1.50)) con respecto a lo desconocido en la función (es decir, $\\delta$), y establezca la ecuación resultante igual a cero como sigue:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\varphi}{\\partial \\delta} = 2 \\delta^T A^T PA + 2 w^T PA = 0 \\tag{5.64}\n",
    "$$\n",
    "\n",
    "Con respecto a las derivadas parciales hechas en la Ecuación (5.58) que conducen al resultado en la Ecuación (5.64), se deben tener en cuenta las siguientes reglas de matrices, las cuales pueden confirmarse en libros básicos de álgebra de matrices:\n",
    "\n",
    "- Las derivadas parciales de $\\delta^T A^T PA \\delta$ con respecto a $\\delta$ dan $2 \\delta^T A^T PA$ (ya que hay dos $\\delta$ involucrados en el término, uno siendo la transposición del otro).\n",
    "- Los dos términos $\\delta^T A^T P w + w^T PA \\delta$ darán los mismos valores numéricos si se usan los mismos números en los vectores y matrices involucrados; sumarán hasta $2 w^T PA \\delta$ o $2 \\delta^T A^T P w$ ya que $w^T PA \\delta = \\delta^T A^T P w$. Para conveniencia, se considera la derivada parcial de $2 w^T PA \\delta$ con respecto a $\\delta$, dando $2 w^T PA$.\n",
    "\n",
    "El sistema de ecuaciones normales de mínimos cuadrados se obtiene reordenando la Ecuación (5.64) como sigue (dividiendo la ecuación por 2 y luego transponiéndola):\n",
    "\n",
    "$$\n",
    "(A^T PA) \\delta + A^T P w = 0 \\tag{5.65}\n",
    "$$\n",
    "\n",
    "Si se usa la función de variación en la Ecuación (5.61) en las derivadas parciales en la Ecuación (5.64), se obtendrá el siguiente sistema de ecuaciones normales:\n",
    "\n",
    "$$\n",
    "(A^T C_{\\ell}^{-1} A) \\delta + A^T C_{\\ell}^{-1} w = 0 \\tag{5.66}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cb4379-e5b2-417f-a610-1e174e80fe4e",
   "metadata": {},
   "source": [
    "### 5.6.2 Ecuaciones Normales Basadas en el Enfoque Lagrangiano de la Función de Variación\n",
    "\n",
    "El sistema de ecuaciones normales de mínimos cuadrados se puede derivar de las funciones de variación obtenidas con base en el enfoque Lagrangiano en la Sección 5.5.2 como sigue. Por ejemplo, al encontrar las derivadas parciales de la función de variación en la Ecuación (5.63) con respecto a lo desconocido en la función (es decir, $\\nu, \\delta$ y $k$), se obtiene lo siguiente (refiriéndose a las Ecuaciones (1.43)–(1.50) para derivadas parciales de matrices):\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\varphi}{\\partial \\nu} = 2 \\nu^T C_{\\ell}^{-1} + 2 k^T = 0 \\tag{5.67}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\varphi}{\\partial \\delta} = -2 k^T A = 0 \\tag{5.68}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\varphi}{\\partial k^T} = 2 (A \\delta + w - \\nu) = 0 \\tag{5.69}\n",
    "$$\n",
    "\n",
    "Las ecuaciones (5.67)–(5.69) se pueden reescribir (dividiendo por 2 o -2) como sigue:\n",
    "\n",
    "$$\n",
    "\\nu^T C_{\\ell}^{-1} + k^T = 0 \\tag{5.70}\n",
    "$$\n",
    "$$\n",
    "k^T A = 0 \\tag{5.71}\n",
    "$$\n",
    "$$\n",
    "A \\delta + w - \\nu = 0 \\tag{5.72}\n",
    "$$\n",
    "\n",
    "Las ecuaciones (5.70)–(5.72) son el sistema de ecuaciones normales de mínimos cuadrados (en la forma más expandida) basado en el enfoque Lagrangiano. Si la función de variación en la Ecuación (5.62) se usa en las derivadas parciales en las Ecuaciones (5.67)–(5.69), la única diferencia en el sistema de ecuaciones normales será $C_{\\ell}^{-1}$ siendo cambiada a $P$ en la Ecuación (5.70)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f069b256-1d3b-4216-9ece-7479e1407d03",
   "metadata": {},
   "source": [
    "### 5.7 Derivación de la Solución de Mínimos Cuadrados Paramétricos\n",
    "\n",
    "La solución de mínimos cuadrados se puede derivar del sistema de ecuaciones normales dado en la Sección 5.6.1 en el caso del enfoque directo o en la Sección 5.6.2 en el caso del enfoque Lagrangiano.\n",
    "\n",
    "### 5.7.1 Solución de Mínimos Cuadrados desde las Ecuaciones Normales del Enfoque Directo\n",
    "\n",
    "La solución de mínimos cuadrados se puede derivar del sistema de ecuaciones normales dado en la Ecuación (5.65) resolviendo directamente para lo desconocido ($\\delta$) como sigue:\n",
    "\n",
    "$$\n",
    "\\delta = - (A^T PA)^{-1} A^T Pw \\tag{5.73}\n",
    "$$\n",
    "\n",
    "o desde la Ecuación (5.66), dando\n",
    "\n",
    "$$\n",
    "\\delta = - (A^T C_{\\ell}^{-1} A)^{-1} A^T C_{\\ell}^{-1} w \\tag{5.74}\n",
    "$$\n",
    "\n",
    "Las Ecuaciones (5.73) y (5.74) son los vectores de solución para las correcciones desconocidas que se aplicarán a los valores aproximados de los parámetros ($x^0$). Los parámetros ajustados ($\\hat{x}$) se pueden dar como:\n",
    "\n",
    "$$\n",
    "\\hat{x} = x^0 + \\delta \\tag{5.75}\n",
    "$$\n",
    "\n",
    "Del modelo paramétrico linealizado en la Ecuación (5.51), el vector de residuales de observación ($\\nu$) se puede obtener como:\n",
    "\n",
    "$$\n",
    "\\nu = w + A\\delta \\tag{5.76}\n",
    "$$\n",
    "\n",
    "con las observaciones ajustadas dadas como sigue:\n",
    "\n",
    "$$\n",
    "\\hat{\\ell} = \\ell + \\nu \\tag{5.77}\n",
    "$$\n",
    "\n",
    "En general, el método de mínimos cuadrados oculta errores al minimizar las correcciones (residuales) a las observaciones al distribuir los errores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f6c665-d8d9-4039-ac8a-a3a7425a6d66",
   "metadata": {},
   "source": [
    "### 5.7.2 Solución de Mínimos Cuadrados desde el Enfoque de Lagrange Ecuaciones Normales\n",
    "\n",
    "La solución de mínimos cuadrados también se puede derivar resolviendo simultáneamente para $\\delta$ a partir del sistema de ecuaciones normales del enfoque de Lagrange en las Ecuaciones (5.70)-(5.72). Multiplicando posteriomente la Ecuación (5.70) por la matriz $A$ y estableciendo $K^T A = 0$ según la Ecuación (5.71), se obtiene lo siguiente:\n",
    "\n",
    "$$ v^T C_{\\ell}^{-1} A = 0 \\tag{5.78} $$\n",
    "\n",
    "Transponiendo la Ecuación (5.78) se obtiene:\n",
    "\n",
    "$$ A^T C_{\\ell}^{-1} v = 0 \\tag{5.79} $$\n",
    "\n",
    "Sustituyendo $v$ de la Ecuación (5.72) en la Ecuación (5.79) se obtiene lo siguiente:\n",
    "\n",
    "$$ A^T C_{\\ell}^{-1} A \\delta + A^T C_{\\ell}^{-1} w = 0 \\tag{5.80} $$\n",
    "\n",
    "La Ecuación (5.80) es el sistema de ecuaciones normales (en forma condensada) basado en el enfoque de Lagrange. La solución de la Ecuación (5.80) da:\n",
    "\n",
    "$$ \\delta = - (A^T C_{\\ell}^{-1} A)^{-1} A^T C_{\\ell}^{-1} w \\tag{5.81} $$\n",
    "\n",
    "Sustituyendo $P = C_{\\ell}^{-1}$ en la Ecuación (5.81) se obtiene:\n",
    "\n",
    "$$ \\delta = - (A^T P A)^{-1} A^T P w \\tag{5.82} $$\n",
    "\n",
    "Las Ecuaciones (5.81) y (5.82) son los vectores de solución para las correcciones desconocidas que deben aplicarse a los valores aproximados de los parámetros ($x^0$). Estas ecuaciones son las mismas que las derivadas del enfoque directo en las Ecuaciones (5.73) y (5.74). Esto es para decir que los resultados finales son los mismos independientemente del enfoque utilizado. En resumen, las ecuaciones útiles en las derivaciones anteriores para el procedimiento de ajuste de mínimos cuadrados paramétricos se pueden dar de la siguiente manera:\n",
    "\n",
    "$$ \\delta = - (A^T P A)^{-1} A^T P w \\tag{5.83} $$\n",
    "\n",
    "o\n",
    "\n",
    "$$ \\delta = - N^{-1} u \\tag{5.84} $$\n",
    "\n",
    "$$ N = A^T P A \\tag{5.85} $$\n",
    "\n",
    "$$ u = A^T P w \\tag{5.86} $$\n",
    "\n",
    "$$ A = \\frac{\\partial f}{\\partial x} \\tag{5.87} $$\n",
    "\n",
    "$$ w = f(x^0) - \\ell \\tag{5.88} $$\n",
    "\n",
    "$$ \\hat{x} = x^0 + \\delta \\tag{5.89} $$\n",
    "\n",
    "$$ \\hat{\\ell} = \\ell + v \\tag{5.90} $$\n",
    "\n",
    "$$ v = w + A \\delta \\tag{5.91} $$\n",
    "\n",
    "donde $\\delta$ es el vector de correcciones al vector de parámetros aproximados $x^0$, $N$ se refiere usualmente como la matriz de los coeficientes de las ecuaciones normales, $A$ es la primera matriz de diseño, $w$ es el vector de desajuste, $\\hat{x}$ es el vector de parámetros ajustados, $\\hat{\\ell}$ es el vector de observaciones ajustadas, $v$ es el vector de residuales o correcciones que deben aplicarse a las observaciones originales $\\ell$, y $P$ es la matriz de pesos de las observaciones $\\ell$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a2e504-7336-4daf-83a3-1e7108b13366",
   "metadata": {},
   "source": [
    "### 5.8 Modelos Estocásticos de Ajuste Paramétrico\n",
    "\n",
    "La relación entre la matriz de varianza-covarianza ($C_{\\ell}$) de algún vector de observación $\\ell$ y la matriz cofactor ($Q_{\\ell}$) del vector de observación se puede dar como:\n",
    "\n",
    "$$ C_{\\ell} = \\sigma_0^2 Q_{\\ell} \\tag{5.92} $$\n",
    "\n",
    "donde $\\sigma_0^2$ es el factor de varianza a priori de peso unitario (que siempre se toma como la varianza general de la población con un valor de 1). Dado que $\\sigma_0^2 = 1$ en la Ecuación (5.92), entonces, al inicio del ajuste de mínimos cuadrados, se asume que la matriz de varianza-covarianza de las observaciones es la misma que la matriz cofactor de las observaciones. Con esta suposición, la matriz de pesos ($P$) de las observaciones se toma como la inversa de la matriz de varianza-covarianza de las observaciones, dada como sigue:\n",
    "\n",
    "$$ P = C_{\\ell}^{-1} = Q_{\\ell}^{-1} \\tag{5.93} $$\n",
    "\n",
    "Dado que las observaciones $\\ell$ y su matriz de varianza-covarianza $C_{\\ell}$ se utilizan en el cálculo de las cantidades desconocidas, tales como los parámetros ajustados ($\\hat{x}$), las observaciones ajustadas ($\\hat{\\ell}$) y los residuales de observación ($v$), es obvio que los errores en esas observaciones se propagarán también en estas cantidades. Los conceptos de propagación de varianza-covarianza (Capítulo 2) se utilizarán como sigue para derivar la matriz cofactor de los parámetros ajustados ($Q_{\\hat{x}}$), la matriz cofactor de la observación ajustada ($Q_{\\hat{\\ell}}$) y la matriz cofactor de los residuales de observación ($Q_{v}$).\n",
    "\n",
    "**5.8.1 Derivación de la Matriz Cofactor de los Parámetros Ajustados**\n",
    "\n",
    "El vector de parámetros ajustados por mínimos cuadrados se puede dar a partir de las Ecuaciones (5.83), (5.88) y (5.89) como:\n",
    "\n",
    "$$ \\hat{x} = x^0 - (A^T P A)^{-1} A^T P [f(x^0) - \\ell] \\tag{5.94} $$\n",
    "\n",
    "La Ecuación (5.94) es una forma de $\\hat{x} = f(\\ell)$ con la matriz cofactor propagada usual (basada en reglas de propagación de varianza-covarianza) dada como:\n",
    "\n",
    "$$ Q_{\\hat{x}} = J Q_{\\ell} J^T \\tag{5.95} $$\n",
    "\n",
    "donde $Q_{\\ell}$ es la matriz cofactor de las observaciones y $J$ es la matriz Jacobiana dada como sigue:\n",
    "\n",
    "$$ J = \\frac{\\partial \\hat{x}}{\\partial \\ell} = (A^T P A)^{-1} A^T P \\tag{5.96} $$\n",
    "\n",
    "teniendo en cuenta que las derivadas parciales con respecto a $\\ell$ de todos los demás términos (excepto $\\ell$) serán cero. Sustituyendo la Ecuación (5.96) en la Ecuación (5.95) se obtiene lo siguiente:\n",
    "\n",
    "$$ Q_{\\hat{x}} = (A^T P A)^{-1} A^T P Q_{\\ell} P A (A^T P A)^{-1} \\tag{5.97} $$\n",
    "\n",
    "Dado que, por definición, $P = Q_{\\ell}^{-1}$, entonces $P Q_{\\ell} = I$ (una matriz identidad con todos los elementos principales diagonales como uno y todos los demás elementos como cero), por lo que la Ecuación (5.97) se puede dar como:\n",
    "\n",
    "$$ Q_{\\hat{x}} = (A^T P A)^{-1} (A^T P A) (A^T P A)^{-1} \\tag{5.98} $$\n",
    "\n",
    "De manera similar, $(A^T P A) (A^T P A)^{-1} = I$, por lo que la Ecuación (5.98) se puede reducir aún más a lo siguiente:\n",
    "\n",
    "$$ Q_{\\hat{x}} = (A^T P A)^{-1} \\tag{5.99} $$\n",
    "\n",
    "La Ecuación (5.99) es la matriz cofactor de los parámetros ajustados ($\\hat{x}$); esta matriz en realidad se puede deducir directamente, por inspección, del vector de solución de mínimos cuadrados paramétricos dado en la Ecuación (5.83)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2355e42b-9a4c-46d4-9a79-978e8d9ca0dc",
   "metadata": {},
   "source": [
    "### 5.8.2 Derivación de la Matriz Cofactor de las Observaciones Ajustadas\n",
    "\n",
    "El vector de observaciones ajustadas por mínimos cuadrados se puede dar a partir de las Ecuaciones (5.88), (5.90) y (5.91) como:\n",
    "\n",
    "$$ \\hat{\\ell} = \\ell + A \\delta + f(x^0) - \\ell \\tag{5.100} $$\n",
    "\n",
    "A partir de las Ecuaciones (5.83), (5.88) y (5.100), se obtiene la siguiente ecuación:\n",
    "\n",
    "$$ \\hat{\\ell} = - A (A^T P A)^{-1} A^T P [f(x^0) - \\ell] + f(x^0) \\tag{5.101} $$\n",
    "\n",
    "La Ecuación (5.101) es una forma de $\\hat{\\ell} = f(\\ell)$ con la usual matriz cofactor propagada (basada en reglas de propagación de varianza-covarianza) dada como:\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = J Q_{\\ell} J^T \\tag{5.102} $$\n",
    "\n",
    "donde $Q_{\\ell}$ es la matriz cofactor de las observaciones y $J$ es la matriz Jacobiana dada como sigue:\n",
    "\n",
    "$$ J = \\frac{\\partial \\hat{\\ell}}{\\partial \\ell} = A (A^T P A)^{-1} A^T P \\tag{5.103} $$\n",
    "\n",
    "teniendo en cuenta que las derivadas parciales con respecto a $\\ell$ de todos los demás términos (excepto $\\ell$) serán cero. Sustituyendo la Ecuación (5.103) en la Ecuación (5.102) se obtiene lo siguiente:\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = A (A^T P A)^{-1} A^T P Q_{\\ell} P A (A^T P A)^{-1} A^T \\tag{5.104} $$\n",
    "\n",
    "De manera similar en la Ecuación (5.104), $PQ_{\\ell} = I$, por lo que la Ecuación (5.104) se puede dar como:\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = A (A^T P A)^{-1} (A^T P A) (A^T P A)^{-1} A^T \\tag{5.105} $$\n",
    "\n",
    "De manera similar, $(A^T P A) (A^T P A)^{-1} = I$, por lo que la Ecuación (5.105) se puede reducir aún más a lo siguiente:\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = A (A^T P A)^{-1} A^T \\tag{5.106} $$\n",
    "\n",
    "La Ecuación (5.106) es la matriz cofactor de las observaciones ajustadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d1c13-117d-4c21-8d50-e4464eef8e6e",
   "metadata": {},
   "source": [
    "### 5.8.3 Derivación de la Matriz Cofactor de los Residuales de Observación\n",
    "\n",
    "El vector de los residuales de observación se puede obtener a partir de las Ecuaciones (5.83), (5.88) y (5.91) como:\n",
    "\n",
    "$$ v = -A(A^T PA)^{-1} A^T P [f(x^0) - \\ell] + f(x^0) - \\ell \\tag{5.107} $$\n",
    "\n",
    "La Ecuación (5.107) es una forma de $v = f(\\ell)$ con la matriz cofactor usual propagada (basada en reglas de propagación de varianza-covarianza) dada como:\n",
    "\n",
    "$$ Q_v = JQ_{\\ell}J^T \\tag{5.108} $$\n",
    "\n",
    "donde $Q_{\\ell}$ es la matriz cofactor de las observaciones y $J$ es la matriz Jacobiana dada como sigue:\n",
    "\n",
    "$$ J = \\frac{\\partial v}{\\partial \\ell} = A(A^T PA)^{-1} A^T P - I \\tag{5.109} $$\n",
    "\n",
    "teniendo en cuenta que la derivada parcial con respecto a $\\ell$ del último término en la Ecuación (5.107) es una matriz identidad ya que $\\ell$ es una cantidad vectorial. Sustituyendo la Ecuación (5.109) en la Ecuación (5.108) se obtiene lo siguiente:\n",
    "\n",
    "$$ Q_v = \\left[ A (A^T P A)^{-1} A^T P - I \\right] Q_{\\ell} \\left[ P A (A^T P A)^{-1} A^T - I \\right]^T \\tag{5.110} $$\n",
    "\n",
    "La Ecuación (5.110) en forma expandida se puede dar como:\n",
    "\n",
    "$$ Q_v = A (A^T P A)^{-1} A^T P Q_{\\ell} P A (A^T P A)^{-1} A^T - A (A^T P A)^{-1} A^T P Q_{\\ell} - Q_{\\ell} P A (A^T P A)^{-1} A^T + Q_{\\ell} \\tag{5.111} $$\n",
    "\n",
    "Tomando $PQ_{\\ell} = I$ y $Q_{\\ell} P = I$ en la Ecuación (5.111) reduce la ecuación a lo siguiente:\n",
    "\n",
    "$$ Q_v = A (A^T P A)^{-1} A^T - A (A^T P A)^{-1} A^T - A (A^T P A)^{-1} A^T + Q_{\\ell} \\tag{5.112} $$\n",
    "\n",
    "Tomando $(A^T P A)(A^T P A)^{-1} = I$ y simplificando la Ecuación (5.112) se obtiene lo siguiente:\n",
    "\n",
    "$$ Q_v = A (A^T P A)^{-1} A^T - A (A^T P A)^{-1} A^T + Q_{\\ell} \\tag{5.113} $$\n",
    "\n",
    "lo cual se simplifica aún más a:\n",
    "\n",
    "$$ Q_v = Q_{\\ell} - A (A^T P A)^{-1} A^T \\tag{5.114} $$\n",
    "\n",
    "La Ecuación (5.113) es la matriz cofactor de los residuales de observación ($v$). Las matrices de varianza-covarianza de las cantidades ajustadas se pueden obtener a partir de las Ecuaciones (5.99), (5.106) y (5.114), respectivamente, como sigue:\n",
    "\n",
    "$$ C_{\\hat{x}} = \\sigma_0^2 (A^T P A)^{-1} \\tag{5.115} $$\n",
    "\n",
    "$$ C_{\\hat{\\ell}} = \\sigma_0^2 \\left[ A (A^T P A)^{-1} A^T \\right] \\tag{5.116} $$\n",
    "\n",
    "$$ C_v = \\sigma_0^2 Q_{\\ell} - \\sigma_0^2 \\left[ A (A^T P A)^{-1} A^T \\right] \\tag{5.117} $$\n",
    "\n",
    "donde $C_{\\hat{x}}$ es la matriz de covarianza de los parámetros ajustados, $C_{\\hat{\\ell}}$ es la matriz de covarianza de las observaciones ajustadas, $C_v$ es la matriz de covarianza de los residuales de observación, y $\\sigma_0^2$ es el factor de varianza a posteriori (APVF) de peso unitario, que se calcula después del ajuste de mínimos cuadrados como sigue:\n",
    "\n",
    "$$ \\sigma_0^2 = \\frac{v^T P v}{n - u} \\tag{5.118} $$\n",
    "\n",
    "donde la redundancia se expresa como $n - u$, $n$ es el número de ecuaciones paramétricas, $u$ es el número de parámetros desconocidos (que no debe confundirse con el símbolo similar usado en las Ecuaciones (5.84) y (5.86) como $u = A^T P w$), $v$ es el vector de residuales de observación, y $P$ es la matriz de pesos de las observaciones.\n",
    "\n",
    "En la Ecuación (5.117), se puede ver que se ha tomado $\\sigma_0^2$ para escalar la matriz cofactor ($Q_{\\ell}$) de las observaciones originales para dar una matriz cofactor aceptable de las observaciones ajustadas; esta es una forma de calibrar indirectamente el instrumento utilizado en la toma de mediciones. El APVF ($\\sigma_0^2$) es un indicador (para el mundo entero) de la consistencia de la red ajustada basada en los errores predichos a priori. Los errores predichos están representados por las desviaciones estándar de las observaciones. En promedio, cada observación se ajusta por una cantidad mayor que su error predicho, el APVF tenderá a ser mayor que 1; si en promedio, cada observación se ajusta por una cantidad menor que su error predicho, el APVF tenderá a ser menor que 1. En cualquier caso, uno puede no estar estimando correctamente la calidad de las mediciones propias o puede tener algunas malas mediciones en el levantamiento (especialmente aquellas mediciones que reciben un gran ajuste). Se debe recordar que si el factor de varianza a priori ($\\sigma_0^2$) es bien conocido, debe usarse en las Ecuaciones (5.115)-(5.117); cuando su valor es desconocido debe establecerse en 1 antes del ajuste para determinar la matriz de pesos ($P$) de las observaciones. A partir de las Ecuaciones (5.115) a (5.117), se puede ver que la matriz cofactor de las observaciones ajustadas ($Q_{\\hat{\\ell}}$) es la misma que $N^{-1}$ con la matriz cofactor de las observaciones ajustadas ($Q_{\\hat{\\ell}}$) dada como $P^{-1}$. A partir de las Ecuaciones (5.116) y (5.117), la matriz de covarianza de los residuales de observación se puede reescribir como sigue:\n",
    "\n",
    "$$ C_v = C_{\\ell} - C_{\\hat{\\ell}} \\tag{5.119} $$\n",
    "\n",
    "donde $C_{\\ell}$ (dada en la Ecuación (5.116)) es la matriz de covarianza de las observaciones ajustadas, que no debe confundirse con la matriz de covarianza escalada de las observaciones originales ($\\hat{C}_{\\ell}$), expresada como:\n",
    "\n",
    "$$ \\hat{C}_{\\ell} = \\sigma_0^2 Q_{\\ell} \\tag{5.120} $$\n",
    "\n",
    "La Ecuación (5.120) también no debe confundirse con $C_{\\ell} = \\sigma_0^2 Q_{\\ell}$ (con $\\sigma_0^2 = 1$). De hecho, $C_{\\ell} = \\sigma_0^2 Q_{\\ell}$ será idéntico si $\\sigma_0^2 = \\sigma_0^2$. Reordenando la Ecuación (5.119), se obtiene lo siguiente:\n",
    "\n",
    "$$ C_{\\hat{\\ell}} = C_{\\ell} - C_v \\tag{5.121} $$\n",
    "\n",
    "Al interpretar la Ecuación (5.121), se puede entender que la matriz de covarianza de la observación ajustada ($C_{\\hat{\\ell}}$) siempre es menor que la matriz de covarianza escalada de las observaciones originales ($\\hat{C}_{\\ell}$) por la cantidad de la matriz de covarianza de los residuales ($C_v$). Esto significa que el ajuste de mínimos cuadrados mejora las precisiones de las observaciones originales. Por ejemplo, en un ajuste de restricción mínima (discutido en el Capítulo 4) en el cual un punto de control se mantiene fijo para un ajuste, la matriz de covarianza de los parámetros ajustados dada por la Ecuación (5.115) da la incertidumbre en las coordenadas ajustadas que se debe a las incertidumbres de las nuevas observaciones. Esta matriz de covarianza indica cuán bien se conocen las coordenadas de los nuevos puntos de levantamiento en relación con el punto de control fijo, pero no cuán bien se conocen en relación con el datum como un todo. La matriz de covarianza de las observaciones ajustadas (Ecuación (5.116)) es verdadera para todo ajuste de restricción mínima, independientemente de cómo se defina el sistema de coordenadas y sin importar la incertidumbre del punto de control fijo. Sin embargo, las coordenadas obtenidas para los puntos libres pueden verse afectadas por los errores en el punto de control fijo, aunque las observaciones ajustadas sean libres de errores. La idea de que las observaciones ajustadas de los ajustes de restricción mínima no se ven afectadas por errores en el punto de control fijo es el sentido en el cual los ajustes de restricción mínima se consideran \"ajustes libres\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9aac8c-2686-4733-b773-70c949d29dce",
   "metadata": {},
   "source": [
    "### 5.8.4 Efectos de la Variación del Factor de Varianza en los Ajustes\n",
    "\n",
    "En algunos de los paquetes de software de ajuste de mínimos cuadrados hoy en día, el factor de varianza a priori de peso unitario se puede cambiar del valor usual de uno a algunos otros números, especialmente en el proceso de detección de errores groseros. Esto se hace generalmente para hacer que el APVF de peso unitario sea igual a uno. El problema común con los usuarios de dichos paquetes de software es entender cómo el cambio del factor de varianza a priori realmente afecta las cantidades ajustadas aparte de cambiar el APVF de peso unitario ($\\sigma_0^2$). Esto es comúnmente el caso en el ajuste de mínimos cuadrados de mediciones GNSS en las que las varianzas de los vectores de base suelen ser demasiado optimistas y a veces se acercan a valores cero. Cuando esos vectores de base y sus matrices de covarianza se utilizan en el ajuste de la red subsiguiente, el APVF de peso unitario calculado para el ajuste se vuelve extremadamente grande y las matrices de covarianza de los vectores de base de entrada deben ser escaladas por un factor. Por ejemplo, considere un caso en el que el factor de varianza a priori de peso unitario ($\\sigma_0^2 = 1$) se cambia a un factor constante $1/k$ (es decir, $\\sigma_0^2 = 1/k$). Se puede demostrar matemáticamente, usando las Ecuaciones (5.81), (5.82), (5.99), (5.115) y (5.118), que el vector ajustado de parámetros $\\hat{x}$ y su matriz de covarianza $C_{\\hat{x}}$ permanecerán sin cambios. Esto es para decir que cuando la matriz de covarianza inicial ($C_{\\ell}$) de las mediciones se multiplica por un factor $k$ (es decir, $Q_{\\ell} = kC_{\\ell}$), esto no afectará a $\\hat{x}$ y $C_{\\hat{x}}$ después del ajuste; por lo tanto, la matriz de covarianza de los parámetros ajustados no se verá afectada por la elección del factor de varianza a priori. La matriz cofactor de los parámetros ajustados ($Q_{\\hat{x}}$), sin embargo, será incrementada por un factor $k$, y el APVF de peso unitario ($\\sigma_0^2$) será reducido por un factor $k$. De manera similar, usando las Ecuaciones (5.92), (5.114), (5.117) y (5.118), se puede demostrar matemáticamente que la matriz cofactor de los residuales se escalará por un factor $k$, pero los residuales y la matriz de covarianza de los residuales permanecerán sin cambios cuando $\\sigma_0^2 = 1/k$.\n",
    "\n",
    "**5.9 Formulación del Modelo de Ajuste con Restricción de Peso**\n",
    "\n",
    "Se dice que una estación de levantamiento está restringida por peso si las coordenadas de la estación están asociadas con algunas desviaciones estándar o alguna incertidumbre. Esto es para decir que las coordenadas de esta estación están abiertas al ajuste hasta el punto limitado por las desviaciones estándar asociadas de las coordenadas de la estación. En una estimación de mínimos cuadrados, estas coordenadas de la estación pueden considerarse como pseudo-mediciones y sus desviaciones estándar como factores de ponderación. Usualmente, una estimación de mínimos cuadrados basada en coordenadas previas y una matriz de covarianza a priori asociada $C_x$ (o restricciones de peso, $P_x$) dará valores ajustados que son casi idénticos a los basados en un ajuste de restricción mínima. El modelo de solución para el ajuste con restricción de peso se deriva en esta sección. El Ejemplo 5.10 proporciona la derivación del procedimiento de ajuste con restricción de peso en forma simbólica. Supongamos que una red de levantamiento está compuesta por dos conjuntos de parámetros ($x_1, x_2$) con los parámetros previamente estimados como $x_1$ con una matriz de covarianza $C_{x1}$ asociada a ellos. Si se realiza un nuevo ajuste en esta red de levantamiento, los parámetros $x_1$ se considerarán tanto como mediciones como parámetros (teniendo naturaleza dual) en el nuevo ajuste. Si $x_1$ y $x_2$ tienen $n_1$ y $n_2$ elementos, respectivamente, la matriz de peso $P_x$ a formular para los parámetros en el nuevo ajuste tendrá un tamaño de $ (n_1 + n_2) \\times (n_1 + n_2) $ con la inversa de $C_{x1}$ ocupando el espacio correspondiente a $x_1$, y todos los demás elementos de la matriz $P_x$ establecidos en cero. Este es un ejemplo típico de un problema de ajuste que involucra restricciones de peso en un subconjunto de puntos de la red. También es posible tener restricciones de peso en todos los puntos de la red dados. Esto puede ser el caso cuando toda una red previamente medida (probablemente imprecisa usando equipo de menor calidad) en un levantamiento (primer levantamiento) es nuevamente medida con equipo de mayor precisión en otro levantamiento (segundo levantamiento). Las coordenadas ajustadas de la red y sus matrices de covarianza del primer levantamiento servirán como pseudo-mediciones y restricciones de peso ($P_x$) para el ajuste de las mediciones en el segundo levantamiento.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eaf3aa-b73b-491b-9692-8d842f1302a6",
   "metadata": {},
   "source": [
    "### Ejemplo 5.10 Dado el siguiente modelo paramétrico con restricción de peso ($P_x$) en el parámetro:\n",
    "\n",
    "$$ \\hat{\\ell} = f(\\hat{x}) \\quad P \\quad P_x \\tag{5.122} $$\n",
    "\n",
    "donde $f$ es un vector del modelo matemático, $x$ es un vector de parámetros desconocidos, $\\ell$ es un vector de observaciones, y $P$ es la matriz de pesos de las observaciones.\n",
    "\n",
    "a) Formular la función de variación basada en el enfoque Lagrangiano.\n",
    "\n",
    "**Solución:**\n",
    "\n",
    "Reescribir la Ecuación (5.122) en términos de vectores residuales $v$, vector de observaciones ajustadas $\\hat{\\ell}$, vector de valores aproximados de los parámetros ($x^0$) y vector de correcciones a los parámetros aproximados $\\delta$:\n",
    "\n",
    "$$ \\ell + v = f(x^0 + \\delta) \\tag{5.123} $$\n",
    "\n",
    "Linearizar la Ecuación (5.123) mediante expansión en series de Taylor:\n",
    "\n",
    "$$ v = f(x^0) + \\frac{\\partial f}{\\partial x} \\delta - \\ell \\tag{5.124} $$\n",
    "\n",
    "o\n",
    "\n",
    "$$ v = w + A \\delta \\tag{5.125} $$\n",
    "\n",
    "donde $w = f(x^0) - \\ell$ es el vector de desajuste y $A = \\frac{\\partial f}{\\partial x}$ es la primera matriz de diseño. La Ecuación (5.124) o la Ecuación (5.125) es la forma linearizada del modelo dado en la Ecuación (5.122).\n",
    "\n",
    "Dado que la matriz de pesos de las observaciones ($P$) y la matriz de pesos de los parámetros ($P_x$) están directamente asociadas con el modelo funcional dado en la Ecuación (5.122), deben usarse directamente en la formulación del criterio de mínimos cuadrados de la siguiente manera:\n",
    "\n",
    "$$ v^T Pv + \\delta^T P_x \\delta = \\min \\tag{5.126} $$\n",
    "\n",
    "donde la matriz de pesos del parámetro es $P_x = C_x^{-1}$ y la de la observación es $P = C_{\\ell}^{-1}$ con el factor de varianza a priori de peso unitario $\\sigma_0^2 = 1$.\n",
    "\n",
    "Imponer el criterio de mínimos cuadrados en el modelo linearizado de la Ecuación (5.125), modificada como $ (w + A\\delta - v = 0) $. La siguiente función de variación se obtiene entonces:\n",
    "\n",
    "$$ \\varphi = v^T Pv + \\delta^T P_x \\delta - 2k^T (A\\delta + w - v) = \\min \\tag{5.127} $$\n",
    "\n",
    "donde $k$ es un vector de correlatos (o valores constantes desconocidos).\n",
    "\n",
    "b) Derivar la forma más expandida del sistema de ecuaciones normales de mínimos cuadrados.\n",
    "\n",
    "**Solución:**\n",
    "\n",
    "A partir de la Ecuación (5.131), transponga la ecuación y reorganice para obtener:\n",
    "\n",
    "$$ v = -P^{-1} k \\tag{5.134} $$\n",
    "\n",
    "Sustituya la Ecuación (5.134) en la Ecuación (5.133) para obtener:\n",
    "\n",
    "$$ A\\delta + w + P^{-1} k = 0 \\tag{5.135} $$\n",
    "\n",
    "Reorganice la ecuación y resuelva para $k$ de la siguiente manera:\n",
    "\n",
    "$$ k = -P(A\\delta + w) \\tag{5.136} $$\n",
    "\n",
    "Transponga la Ecuación (5.132), y luego sustituya la Ecuación (5.136) en ella, obteniendo:\n",
    "\n",
    "$$ P_x \\delta + A^T P (A\\delta + w) = 0 \\tag{5.137} $$\n",
    "\n",
    "Resuelva para el desconocido $\\delta$ en la Ecuación (5.137):\n",
    "\n",
    "$$ \\delta = - (P_x + A^T P A)^{-1} A^T P w \\tag{5.138} $$\n",
    "\n",
    "Los parámetros ajustados se pueden determinar a partir de:\n",
    "\n",
    "$$ \\hat{x} = x^0 + \\delta \\tag{5.139} $$\n",
    "\n",
    "Usando las Ecuaciones (5.138), (5.136) y (5.134), el vector residual $v$ se puede determinar, de modo que las observaciones ajustadas se pueden obtener como:\n",
    "\n",
    "$$ \\hat{\\ell} = \\ell + v \\tag{5.140} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af37c213-374b-443d-94e0-fb9ab5f8ae3f",
   "metadata": {},
   "source": [
    "### 5.9.1 Modelo Estocástico para Parámetros Ajustados con Restricción de Peso\n",
    "\n",
    "Los parámetros ajustados del ajuste con restricción de peso se pueden obtener a partir de las Ecuaciones (5.138) y (5.139) de la siguiente manera:\n",
    "\n",
    "$$ \\hat{x} = x^0 - (P_x + A^T PA)^{-1} A^T P [f(x^0) - \\ell] \\tag{5.141} $$\n",
    "\n",
    "donde el vector de desajuste es $w = [f(x^0) - \\ell]$. Se asume en la Ecuación (5.141) que la matriz de peso $P_x$ tiene un tamaño completo para todos los parámetros a ajustar (incluyendo los parámetros desconocidos) y los elementos de la matriz de peso se pueden derivar de la matriz cofactor a priori ($Q_x$) de los parámetros; a los parámetros con valores desconocidos se les pueden asignar pesos cero en lugar de derivarlos directamente de sus cofactors. Mediante las leyes de propagación de varianza-covarianza en la Ecuación (5.141), asumiendo la matriz cofactor de parámetros ($Q_x$) con \"elementos cero\" para los parámetros desconocidos, la matriz cofactor de los parámetros ajustados ($Q_{\\hat{x}}$) se puede dar como:\n",
    "\n",
    "$$ Q_{\\hat{x}} = J Q_{\\ell} J^T \\tag{5.142} $$\n",
    "\n",
    "donde $Q_{\\ell}$ es el cofactor de las mediciones y $J$ es la matriz Jacobiana de la Ecuación (5.141) con respecto al vector de parámetros ($x$) y de las mediciones ($\\ell$), dada como sigue:\n",
    "\n",
    "$$ J = \\begin{bmatrix} \\frac{\\partial \\hat{x}}{\\partial x} & \\frac{\\partial \\hat{x}}{\\partial \\ell} \\end{bmatrix} \\tag{5.143} $$\n",
    "\n",
    "con\n",
    "\n",
    "$$ \\frac{\\partial \\hat{x}}{\\partial x} = I - (P_x + A^T PA)^{-1} A^T PA \\tag{5.144} $$\n",
    "\n",
    "$$ \\frac{\\partial \\hat{x}}{\\partial \\ell} = (P_x + A^T PA)^{-1} A^T P \\tag{5.145} $$\n",
    "\n",
    "Tome nota de la Ecuación (5.144) que $\\partial f(x^0) / \\partial x = A$, la primera matriz de diseño, y $I$ es una matriz identidad con todos los elementos diagonales principales como unos y los elementos fuera de la diagonal como ceros. La forma expandida de la Ecuación (5.142) se puede dar como:\n",
    "\n",
    "$$ Q_{\\hat{x}} = Q_x - Q_x NW - WN Q_x + WN Q_x NW + WNW \\tag{5.146} $$\n",
    "\n",
    "donde\n",
    "\n",
    "$$ W = (P_x + A^T PA)^{-1} \\tag{5.147} $$\n",
    "\n",
    "$$ N = (A^T PA) \\tag{5.148} $$\n",
    "\n",
    "Se puede demostrar que la Ecuación (5.146) es equivalente a la siguiente:\n",
    "\n",
    "$$ Q_{\\hat{x}} = (P_x + A^T PA)^{-1} \\tag{5.149} $$\n",
    "\n",
    "La matriz de varianza-covarianza de los parámetros ajustados se puede dar como:\n",
    "\n",
    "$$ C_{\\hat{x}} = \\sigma_0^2 Q_{\\hat{x}} \\tag{5.150} $$\n",
    "\n",
    "donde el APVF de peso unitario $\\sigma_0^2$ se puede dar como:\n",
    "\n",
    "$$ \\sigma_0^2 = \\frac{v^T Pv + \\delta^T P_x \\delta}{n_d - u_d} \\tag{5.151} $$\n",
    "\n",
    "con $n_d$ como el número de observaciones directas (o reales) y $u_d$ como el número de parámetros directos (aquellos parámetros cuyos valores no están asociados con ninguna desviación estándar a priori)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c043479-ba48-4f9b-b07f-001e7119875a",
   "metadata": {},
   "source": [
    "### 5.9.2 Modelo Estocástico para Observaciones Ajustadas con Restricción de Peso\n",
    "\n",
    "Las observaciones ajustadas se pueden obtener a partir de las Ecuaciones (5.133), (5.138) y (5.140) con el vector de desajuste $w = f(x^0) - \\ell$ como sigue:\n",
    "\n",
    "$$ \\hat{\\ell} = \\ell - A(P_x + A^T PA)^{-1} A^T P [f(x^0) - \\ell] + [f(x^0) - \\ell] \\tag{5.152} $$\n",
    "\n",
    "o en una forma expandida como\n",
    "\n",
    "$$ \\hat{\\ell} = -A(P_x + A^T PA)^{-1} A^T P [f(x^0)] + A(P_x + A^T PA)^{-1} A^T P \\ell + f(x^0) \\tag{5.153} $$\n",
    "\n",
    "Se asume en la Ecuación (5.153) que la matriz de peso $P_x$ tiene un tamaño completo para todos los parámetros a ajustar (incluyendo los parámetros desconocidos) y los elementos de la matriz de peso se pueden derivar de la matriz cofactor a priori ($Q_x$) de los parámetros; a los parámetros con valores desconocidos se les pueden asignar pesos cero en lugar de derivarlos directamente de sus cofactors. Mediante las leyes de propagación de varianza-covarianza en la Ecuación (5.153), asumiendo la matriz cofactor de parámetros ($Q_x$) con \"elementos cero\" para los parámetros desconocidos, la matriz cofactor de los parámetros ajustados ($Q_{\\hat{x}}$) se puede dar como:\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = J \\begin{bmatrix} Q_{\\hat{x}} & 0 \\\\ 0 & Q_{\\ell} \\end{bmatrix} J^T \\tag{5.154} $$\n",
    "\n",
    "donde $Q_{\\ell}$ es el cofactor de las mediciones y $J$ es la matriz Jacobiana de la Ecuación (5.153) con respecto al vector de parámetros ($x$) y de las mediciones ($\\ell$), dada como sigue:\n",
    "\n",
    "$$ J = \\begin{bmatrix} \\frac{\\partial \\hat{\\ell}}{\\partial x} & \\frac{\\partial \\hat{\\ell}}{\\partial \\ell} \\end{bmatrix} \\tag{5.155} $$\n",
    "\n",
    "con\n",
    "\n",
    "$$ \\frac{\\partial \\hat{\\ell}}{\\partial x} = -A(P_x + A^T PA)^{-1} A^T PA + A \\tag{5.156} $$\n",
    "\n",
    "$$ \\frac{\\partial \\hat{\\ell}}{\\partial \\ell} = A(P_x + A^T PA)^{-1} A^T P \\tag{5.157} $$\n",
    "\n",
    "Tome nota de la Ecuación (5.156) que $\\partial f(x^0) / \\partial x = A$, la primera matriz de diseño, y $I$ es una matriz identidad con todos los elementos diagonales principales como unos y los elementos fuera de la diagonal como ceros. La forma expandida de la Ecuación (5.154) se puede dar como:\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = AQ_{\\hat{x}}A^T - AQ_{\\hat{x}}NWA^T - AWNQ_{\\hat{x}}A^T + AWNQ_{\\hat{x}}NWA^T + AWNWA^T \\tag{5.158} $$\n",
    "\n",
    "donde $W$ y $N$ son como se definieron previamente en las Ecuaciones (5.147) y (5.148). Se puede demostrar que la Ecuación (5.158) es equivalente a la siguiente:\n",
    "\n",
    "$$ Q_{\\hat{\\ell}} = A (P_x + A^T PA)^{-1} A^T \\tag{5.159} $$\n",
    "\n",
    "La matriz de varianza-covarianza de las observaciones ajustadas se puede dar como:\n",
    "\n",
    "$$ C_{\\hat{\\ell}} = \\sigma_0^2 Q_{\\hat{\\ell}} \\tag{5.160} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6753e5-f22f-46ac-a0e4-edc7dac1f21e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
